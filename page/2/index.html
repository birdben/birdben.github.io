<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <title>birdben</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="birdben">
<meta property="og:url" content="https://github.com/birdben/page/2/index.html">
<meta property="og:site_name" content="birdben">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="birdben">
  
    <link rel="alternative" href="/atom.xml" title="birdben" type="application/atom+xml">
  
  
    <link rel="icon" href="/images/favicon.ico">
  
  <link rel="stylesheet" href="/css/style.css">
  
<script type="text/javascript">
var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1260188951'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s4.cnzz.com/z_stat.php%3Fid%3D1260188951' type='text/javascript'%3E%3C/script%3E"));
</script>

</head>

<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="/images/logo.png" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">birdben</a></h1>
		</hgroup>

		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						<div class="icon-wrap icon-link hide" data-idx="2">
							<div class="loopback_l"></div>
							<div class="loopback_r"></div>
						</div>
						
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>Menu</li>
						<li>Tags</li>
						
						<li>Links</li>
						
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives">所有文章</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/birdben" title="github">github</a>
					        
								<a class="weibo" target="_blank" href="#" title="weibo">weibo</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/Akka/" style="font-size: 11.11px;">Akka</a> <a href="/tags/Dockerfile/" style="font-size: 20px;">Dockerfile</a> <a href="/tags/Docker命令/" style="font-size: 18.89px;">Docker命令</a> <a href="/tags/Docker环境/" style="font-size: 11.11px;">Docker环境</a> <a href="/tags/ELK/" style="font-size: 11.11px;">ELK</a> <a href="/tags/ElasticSearch/" style="font-size: 11.11px;">ElasticSearch</a> <a href="/tags/Flume/" style="font-size: 17.78px;">Flume</a> <a href="/tags/Git命令/" style="font-size: 13.33px;">Git命令</a> <a href="/tags/HBase/" style="font-size: 10px;">HBase</a> <a href="/tags/HDFS/" style="font-size: 16.67px;">HDFS</a> <a href="/tags/Hadoop/" style="font-size: 10px;">Hadoop</a> <a href="/tags/Hadoop原理架构体系/" style="font-size: 10px;">Hadoop原理架构体系</a> <a href="/tags/Hive/" style="font-size: 15.56px;">Hive</a> <a href="/tags/Kafka/" style="font-size: 12.22px;">Kafka</a> <a href="/tags/Kibana/" style="font-size: 11.11px;">Kibana</a> <a href="/tags/Linux命令/" style="font-size: 12.22px;">Linux命令</a> <a href="/tags/Maven配置/" style="font-size: 11.11px;">Maven配置</a> <a href="/tags/MongoDB/" style="font-size: 12.22px;">MongoDB</a> <a href="/tags/MySQL/" style="font-size: 10px;">MySQL</a> <a href="/tags/Nginx/" style="font-size: 10px;">Nginx</a> <a href="/tags/Redis/" style="font-size: 10px;">Redis</a> <a href="/tags/Shadowsocks/" style="font-size: 10px;">Shadowsocks</a> <a href="/tags/Shell/" style="font-size: 14.44px;">Shell</a> <a href="/tags/Spring/" style="font-size: 11.11px;">Spring</a> <a href="/tags/Zookeeper/" style="font-size: 13.33px;">Zookeeper</a> <a href="/tags/其他/" style="font-size: 10px;">其他</a>
					</div>
				</section>
				
				
				
				<section class="switch-part switch-part3">
					<div id="js-friends">
					
			          <a target="_blank" class="main-nav-link switch-friends-link" href="http://blog.csdn.net/birdben">我的CSDN的博客</a>
			        
			        </div>
				</section>
				

				
			</div>
		</div>
	</header>				
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">birdben</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
			
				<img lazy-src="/images/logo.png" class="js-avatar">
			
			</div>
			<hgroup>
			  <h1 class="header-author">birdben</h1>
			</hgroup>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives">所有文章</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/birdben" title="github">github</a>
			        
						<a class="weibo" target="_blank" href="#" title="weibo">weibo</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>

      <div class="body-wrap">
  
    <article id="post-Flume/Flume学习（九）Flume整合HDFS（一）" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/09/22/Flume/Flume学习（九）Flume整合HDFS（一）/" class="article-date">
  	<time datetime="2016-09-22T10:35:32.000Z" itemprop="datePublished">2016-09-22</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/09/22/Flume/Flume学习（九）Flume整合HDFS（一）/">Flume学习（九）Flume整合HDFS（一）</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="环境简介"><a href="#环境简介" class="headerlink" title="环境简介"></a>环境简介</h3><ul>
<li>JDK1.7.0_79</li>
<li>Flume1.6.0</li>
<li>Hadoop2.7.1</li>
</ul>
<p>之前介绍了Flume整合ES，本篇主要介绍Flume整合HDFS，将日志内容通过Flume传输给Hadoop，并且保存成文件存储在HDFS上。</p>
<h3 id="需要依赖Hadoop的jar包"><a href="#需要依赖Hadoop的jar包" class="headerlink" title="需要依赖Hadoop的jar包"></a>需要依赖Hadoop的jar包</h3><p>下面的jar包路径根据自己的实际环境情况修改。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">cp ~/Downloads/develop/hadoop-2.7.1/share/hadoop/common/hadoop-common-2.7.1.jar ~/dev/flume-1.6.0/lib</div><div class="line">cp ~/Downloads/develop/hadoop-2.7.1/share/hadoop/common/lib/commons-configuration-1.6.jar ~/dev/flume-1.6.0/lib</div><div class="line">cp ~/Downloads/develop/hadoop-2.7.1/share/hadoop/common/lib/hadoop-auth-2.7.1.jar ~/dev/flume-1.6.0/lib</div><div class="line">cp ~/Downloads/develop/hadoop-2.7.1/share/hadoop/httpfs/tomcat/webapps/webhdfs/WEB-INF/lib/hadoop-hdfs-2.7.1.jar ~/dev/flume-1.6.0/lib</div><div class="line">cp ~/Downloads/develop/hadoop-2.7.1/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar ~/dev/flume-1.6.0/lib</div><div class="line"># 覆盖已有的commons-io.jar</div><div class="line">cp ~/Downloads/develop/hadoop-2.7.1/share/hadoop/common/lib/commons-io-2.4.jar ~/dev/flume-1.6.0/lib</div></pre></td></tr></table></figure>
<h3 id="command-log日志文件"><a href="#command-log日志文件" class="headerlink" title="command.log日志文件"></a>command.log日志文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">543  &#123;&quot;TIME&quot;:&quot;2016-09-06 15:04:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;806&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ll&quot;&#125;</div><div class="line">543  &#123;&quot;TIME&quot;:&quot;2016-09-06 15:04:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;806&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ll&quot;&#125;</div><div class="line">543  &#123;&quot;TIME&quot;:&quot;2016-09-06 15:04:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;806&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ll&quot;&#125;</div><div class="line">543  &#123;&quot;TIME&quot;:&quot;2016-09-06 15:04:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;806&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ll&quot;&#125;</div><div class="line">543  &#123;&quot;TIME&quot;:&quot;2016-09-06 15:04:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;806&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ll&quot;&#125;</div><div class="line">543  &#123;&quot;TIME&quot;:&quot;2016-09-06 15:04:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;806&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ll&quot;&#125;</div><div class="line">565  &#123;&quot;TIME&quot;:&quot;2016-09-06 13:10:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;783&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ssh yunyu@10.10.1.15&quot;&#125;</div><div class="line">565  &#123;&quot;TIME&quot;:&quot;2016-09-06 13:10:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;783&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ssh yunyu@10.10.1.15&quot;&#125;</div><div class="line">565  &#123;&quot;TIME&quot;:&quot;2016-09-06 13:10:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;783&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ssh yunyu@10.10.1.15&quot;&#125;</div></pre></td></tr></table></figure>
<h3 id="Flume相关配置"><a href="#Flume相关配置" class="headerlink" title="Flume相关配置"></a>Flume相关配置</h3><h4 id="Flume-Agent端的flume-agent-file-conf配置"><a href="#Flume-Agent端的flume-agent-file-conf配置" class="headerlink" title="Flume Agent端的flume_agent_file.conf配置"></a>Flume Agent端的flume_agent_file.conf配置</h4><p>这里是采集/Users/yunyu/Downloads/command.log日志文件的内容，并且上报到127.0.0.1:41414服务器上（也就是Flume Collector端）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">agent3.sources = command-logfile-source</div><div class="line">agent3.channels = ch3</div><div class="line">agent3.sinks = flume-avro-sink</div><div class="line"></div><div class="line">agent3.sources.command-logfile-source.channels = ch3</div><div class="line">agent3.sources.command-logfile-source.type = exec</div><div class="line">agent3.sources.command-logfile-source.command = tail -F /Users/yunyu/Downloads/command.log</div><div class="line"></div><div class="line">agent3.channels.ch3.type = memory</div><div class="line">agent3.channels.ch3.capacity = 1000</div><div class="line">agent3.channels.ch3.transactionCapacity = 100</div><div class="line"></div><div class="line">agent3.sinks.flume-avro-sink.channel = ch3</div><div class="line">agent3.sinks.flume-avro-sink.type = avro</div><div class="line">agent3.sinks.flume-avro-sink.hostname = 127.0.0.1</div><div class="line">agent3.sinks.flume-avro-sink.port = 41414</div></pre></td></tr></table></figure>
<h4 id="Flume-Collector端的flume-collector-hdfs-conf配置"><a href="#Flume-Collector端的flume-collector-hdfs-conf配置" class="headerlink" title="Flume Collector端的flume_collector_hdfs.conf配置"></a>Flume Collector端的flume_collector_hdfs.conf配置</h4><p>这里监听到127.0.0.1:41414上报的内容，并且输出到HDFS中，这里需要指定HDFS的文件路径。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">agentX.sources = flume-avro-sink</div><div class="line">agentX.channels = chX</div><div class="line">agentX.sinks = flume-hdfs-sink</div><div class="line"></div><div class="line">agentX.sources.flume-avro-sink.channels = chX</div><div class="line">agentX.sources.flume-avro-sink.type = avro</div><div class="line">agentX.sources.flume-avro-sink.bind = 127.0.0.1</div><div class="line">agentX.sources.flume-avro-sink.port = 41414</div><div class="line">agentX.sources.flume-avro-sink.threads = 8</div><div class="line"></div><div class="line">agentX.channels.chX.type = memory</div><div class="line">agentX.channels.chX.capacity = 1000</div><div class="line">agentX.channels.chX.transactionCapacity = 100</div><div class="line"></div><div class="line">agentX.sinks.flume-hdfs-sink.type = hdfs</div><div class="line">agentX.sinks.flume-hdfs-sink.channel = chX</div><div class="line">#agentX.sinks.flume-hdfs-sink.hdfs.path = hdfs://10.10.1.64:8020/flume/events/%y-%m-%d/%H%M/%S</div><div class="line">agentX.sinks.flume-hdfs-sink.hdfs.path = hdfs://10.10.1.64:8020/flume/events/</div><div class="line"># HdfsEventSink中，hdfs.fileType默认为SequenceFile，将其改为DataStream就可以按照采集的文件原样输入到hdfs，加一行agentX.sinks.flume-hdfs-sink.hdfs.fileType = DataStream</div><div class="line">agentX.sinks.flume-hdfs-sink.hdfs.fileType = DataStream</div><div class="line">agentX.sinks.flume-hdfs-sink.hdfs.filePrefix = events-</div><div class="line">agentX.sinks.flume-hdfs-sink.hdfs.round = true</div><div class="line">agentX.sinks.flume-hdfs-sink.hdfs.roundValue = 10</div><div class="line">agentX.sinks.flume-hdfs-sink.hdfs.roundUnit = minute</div></pre></td></tr></table></figure>
<h4 id="启动Flume"><a href="#启动Flume" class="headerlink" title="启动Flume"></a>启动Flume</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"># 启动Flume收集端</div><div class="line">$ ./bin/flume-ng agent --conf ./conf/ -f conf/flume_collector_hdfs.conf -Dflume.root.logger=DEBUG,console -n agentX</div><div class="line"></div><div class="line"># 启动Flume采集端，发送数据到Collector测试</div><div class="line">$ ./bin/flume-ng agent --conf ./conf/ -f conf/flume_agent_file.conf -Dflume.root.logger=DEBUG,console -n agent3</div></pre></td></tr></table></figure>
<p>这里遇到个小问题，就是Flume收集的日志文件到HDFS上查看有乱码，具体查看HDFS文件内容如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ hdfs dfs -cat /flume/events/events-.1474337184903</div><div class="line">SEQ!org.apache.hadoop.io.LongWritable&quot;org.apache.hadoop.io.BytesWritable�w�x0�\����WEX&quot;Ds &#123;&quot;TIME&quot;:&quot;2016-09-20 10:05:30&quot;,&quot;HOSTNAME&quot;:&quot;hadoop1&quot;,&quot;LI&quot;:&quot;:0&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;tailf command.log &quot;&#125;WEX&quot;Fs &#123;&quot;TIME&quot;:&quot;2016-09-20 10:05:30&quot;,&quot;HOSTNAME&quot;:&quot;hadoop1&quot;,&quot;LI&quot;:&quot;:0&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;tailf command.log &quot;&#125;WEX&quot;Gs &#123;&quot;TIME&quot;:&quot;2016-09-20 10:05:30&quot;,&quot;HOSTNAME&quot;:&quot;hadoop1&quot;,&quot;LI&quot;:&quot;:0&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;tailf command.log &quot;&#125;WEX&quot;Gs &#123;&quot;TIME&quot;:&quot;2016-09-20 10:05:30&quot;,&quot;HOSTNAME&quot;:&quot;hadoop1&quot;,&quot;LI&quot;:&quot;:0&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;tailf command.log &quot;&#125;WEX&quot;Hs &#123;&quot;TIME&quot;:&quot;2016-09-20 10:05:30&quot;,&quot;HOSTNAME&quot;:&quot;hadoop1&quot;,&quot;LI&quot;:&quot;:0&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;tailf command.log &quot;&#125;WEX&quot;Hs &#123;&quot;TIME&quot;:&quot;2016-09-20 10:05:30&quot;,&quot;HOSTNAME&quot;:&quot;hadoop1&quot;,&quot;LI&quot;:&quot;:0&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;tailf command.log &quot;&#125;WEX&quot;Hs &#123;&quot;TIME&quot;:&quot;2016-09-20 10:05:30&quot;,&quot;HOSTNAME&quot;:&quot;hadoop1&quot;,&quot;LI&quot;:&quot;:0&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;tailf command.log &quot;&#125;WEX&quot;Is &#123;&quot;TIME&quot;:&quot;2016-09-20 10:05:30&quot;,&quot;HOSTNAME&quot;:&quot;hadoop1&quot;,&quot;LI&quot;:&quot;:0&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;tailf command.log &quot;&#125;WEX&quot;Is &#123;&quot;TIME&quot;:&quot;2016-09-20 10:05:30&quot;,&quot;HOSTNAME&quot;:&quot;hadoop1&quot;,&quot;LI&quot;:&quot;:0&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;tailf command.log &quot;&#125;</div></pre></td></tr></table></figure>
<p>解决方式：HdfsEventSink中，hdfs.fileType默认为SequenceFile，将其改为DataStream就可以按照采集的文件原样输入到hdfs，加一行agentX.sinks.flume-hdfs-sink.hdfs.fileType = DataStream，如果不改就会出现HDFS文件乱码问题。</p>
<h4 id="在HDFS中查看日志文件"><a href="#在HDFS中查看日志文件" class="headerlink" title="在HDFS中查看日志文件"></a>在HDFS中查看日志文件</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"># 之前我们在Flume中配置了采集到的日志输出到HDFS的保存路径是hdfs://10.10.1.64:8020/flume/events/</div><div class="line"></div><div class="line"># 查看HDFS文件存储路径</div><div class="line">$ hdfs dfs -ls /flume/events/</div><div class="line">Found 2 items-rw-r--r--   3 yunyu supergroup       1134 2016-09-19 23:43 /flume/events/events-.1474353822776-rw-r--r--   3 yunyu supergroup        126 2016-09-19 23:44 /flume/events/events-.1474353822777</div><div class="line"></div><div class="line"># 查看HDFS文件内容</div><div class="line">$ hdfs dfs -cat /flume/events/events-.1474353822776</div><div class="line">  543  &#123;&quot;TIME&quot;:&quot;2016-09-06 15:04:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;806&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ll&quot;&#125;</div><div class="line">  543  &#123;&quot;TIME&quot;:&quot;2016-09-06 15:04:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;806&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ll&quot;&#125;</div><div class="line">  543  &#123;&quot;TIME&quot;:&quot;2016-09-06 15:04:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;806&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ll&quot;&#125;</div><div class="line">  543  &#123;&quot;TIME&quot;:&quot;2016-09-06 15:04:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;806&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ll&quot;&#125;</div><div class="line">  543  &#123;&quot;TIME&quot;:&quot;2016-09-06 15:04:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;806&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ll&quot;&#125;</div><div class="line">  543  &#123;&quot;TIME&quot;:&quot;2016-09-06 15:04:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;806&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ll&quot;&#125;</div><div class="line">  565  &#123;&quot;TIME&quot;:&quot;2016-09-06 13:10:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;783&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ssh yunyu@10.10.1.15&quot;&#125;</div><div class="line">  565  &#123;&quot;TIME&quot;:&quot;2016-09-06 13:10:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;783&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ssh yunyu@10.10.1.15&quot;&#125;</div><div class="line">  565  &#123;&quot;TIME&quot;:&quot;2016-09-06 13:10:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;783&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ssh yunyu@10.10.1.15&quot;&#125;</div></pre></td></tr></table></figure>
<p>参考文章：</p>
<ul>
<li><a href="http://blog.csdn.net/cnbird2008/article/details/18967449" target="_blank" rel="external">http://blog.csdn.net/cnbird2008/article/details/18967449</a></li>
<li><a href="http://blog.csdn.net/lifuxiangcaohui/article/details/49949865" target="_blank" rel="external">http://blog.csdn.net/lifuxiangcaohui/article/details/49949865</a></li>
</ul>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Flume/">Flume</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/HDFS/">HDFS</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Log/">Log</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Hive/Hive学习（二）使用Hive进行离线分析日志" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/09/20/Hive/Hive学习（二）使用Hive进行离线分析日志/" class="article-date">
  	<time datetime="2016-09-20T07:28:15.000Z" itemprop="datePublished">2016-09-20</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/09/20/Hive/Hive学习（二）使用Hive进行离线分析日志/">Hive学习（二）使用Hive进行离线分析日志</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>继上一篇把Hive环境安装好之后，我们要做具体的日志分析处理，这里我们的架构是使用Flume + HDFS + Hive离线分析日志。通过Flume收集日志文件中的日志，然后存储到HDFS中，在通过Hive在HDFS之上建立数据库表，进行SQL的查询分析（其实底层是mapreduce任务）。</p>
<p>这里我们还是处理之前一直使用的command.log命令行日志，先来看一下具体的日志文件格式</p>
<h3 id="command-log日志文件"><a href="#command-log日志文件" class="headerlink" title="command.log日志文件"></a>command.log日志文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">543  &#123;&quot;TIME&quot;:&quot;2016-09-06 15:04:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;806&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ll&quot;&#125;</div><div class="line">543  &#123;&quot;TIME&quot;:&quot;2016-09-06 15:04:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;806&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ll&quot;&#125;</div><div class="line">543  &#123;&quot;TIME&quot;:&quot;2016-09-06 15:04:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;806&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ll&quot;&#125;</div><div class="line">543  &#123;&quot;TIME&quot;:&quot;2016-09-06 15:04:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;806&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ll&quot;&#125;</div><div class="line">543  &#123;&quot;TIME&quot;:&quot;2016-09-06 15:04:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;806&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ll&quot;&#125;</div><div class="line">543  &#123;&quot;TIME&quot;:&quot;2016-09-06 15:04:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;806&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ll&quot;&#125;</div><div class="line">565  &#123;&quot;TIME&quot;:&quot;2016-09-06 13:10:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;783&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ssh yunyu@10.10.1.15&quot;&#125;</div><div class="line">565  &#123;&quot;TIME&quot;:&quot;2016-09-06 13:10:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;783&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ssh yunyu@10.10.1.15&quot;&#125;</div><div class="line">565  &#123;&quot;TIME&quot;:&quot;2016-09-06 13:10:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;783&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ssh yunyu@10.10.1.15&quot;&#125;</div></pre></td></tr></table></figure>
<h3 id="Flume相关配置"><a href="#Flume相关配置" class="headerlink" title="Flume相关配置"></a>Flume相关配置</h3><h4 id="Flume-Agent端的flume-agent-file-conf配置"><a href="#Flume-Agent端的flume-agent-file-conf配置" class="headerlink" title="Flume Agent端的flume_agent_file.conf配置"></a>Flume Agent端的flume_agent_file.conf配置</h4><p>这里是采集/Users/yunyu/Downloads/command.log日志文件的内容，并且上报到127.0.0.1:41414服务器上（也就是Flume Collector端）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">agent3.sources = command-logfile-source</div><div class="line">agent3.channels = ch3</div><div class="line">agent3.sinks = flume-avro-sink</div><div class="line"></div><div class="line">agent3.sources.command-logfile-source.channels = ch3</div><div class="line">agent3.sources.command-logfile-source.type = exec</div><div class="line">agent3.sources.command-logfile-source.command = tail -F /Users/yunyu/Downloads/command.log</div><div class="line"></div><div class="line">agent3.channels.ch3.type = memory</div><div class="line">agent3.channels.ch3.capacity = 1000</div><div class="line">agent3.channels.ch3.transactionCapacity = 100</div><div class="line"></div><div class="line">agent3.sinks.flume-avro-sink.channel = ch3</div><div class="line">agent3.sinks.flume-avro-sink.type = avro</div><div class="line">agent3.sinks.flume-avro-sink.hostname = 127.0.0.1</div><div class="line">agent3.sinks.flume-avro-sink.port = 41414</div></pre></td></tr></table></figure>
<h4 id="Flume-Collector端的flume-collector-hdfs-conf配置"><a href="#Flume-Collector端的flume-collector-hdfs-conf配置" class="headerlink" title="Flume Collector端的flume_collector_hdfs.conf配置"></a>Flume Collector端的flume_collector_hdfs.conf配置</h4><p>这里监听到127.0.0.1:41414上报的内容，并且输出到HDFS中，这里需要指定HDFS的文件路径。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">agentX.sources = flume-avro-sink</div><div class="line">agentX.channels = chX</div><div class="line">agentX.sinks = flume-hdfs-sink</div><div class="line"></div><div class="line">agentX.sources.flume-avro-sink.channels = chX</div><div class="line">agentX.sources.flume-avro-sink.type = avro</div><div class="line">agentX.sources.flume-avro-sink.bind = 127.0.0.1</div><div class="line">agentX.sources.flume-avro-sink.port = 41414</div><div class="line">agentX.sources.flume-avro-sink.threads = 8</div><div class="line"></div><div class="line">agentX.channels.chX.type = memory</div><div class="line">agentX.channels.chX.capacity = 1000</div><div class="line">agentX.channels.chX.transactionCapacity = 100</div><div class="line"></div><div class="line">agentX.sinks.flume-hdfs-sink.type = hdfs</div><div class="line">agentX.sinks.flume-hdfs-sink.channel = chX</div><div class="line">#agentX.sinks.flume-hdfs-sink.hdfs.path = hdfs://10.10.1.64:8020/flume/events/%y-%m-%d/%H%M/%S</div><div class="line">agentX.sinks.flume-hdfs-sink.hdfs.path = hdfs://10.10.1.64:8020/flume/events/</div><div class="line"># HdfsEventSink中，hdfs.fileType默认为SequenceFile，将其改为DataStream就可以按照采集的文件原样输入到hdfs，加一行agentX.sinks.flume-hdfs-sink.hdfs.fileType = DataStream</div><div class="line">agentX.sinks.flume-hdfs-sink.hdfs.fileType = DataStream</div><div class="line">agentX.sinks.flume-hdfs-sink.hdfs.filePrefix = events-</div><div class="line">agentX.sinks.flume-hdfs-sink.hdfs.round = true</div><div class="line">agentX.sinks.flume-hdfs-sink.hdfs.roundValue = 10</div><div class="line">agentX.sinks.flume-hdfs-sink.hdfs.roundUnit = minute</div></pre></td></tr></table></figure>
<h4 id="启动Flume"><a href="#启动Flume" class="headerlink" title="启动Flume"></a>启动Flume</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"># 启动Flume收集端</div><div class="line">$ ./bin/flume-ng agent --conf ./conf/ -f conf/flume_collector_hdfs.conf -Dflume.root.logger=DEBUG,console -n agentX</div><div class="line"></div><div class="line"># 启动Flume采集端，发送数据到Collector测试</div><div class="line">$ ./bin/flume-ng agent --conf ./conf/ -f conf/flume_agent_file.conf -Dflume.root.logger=DEBUG,console -n agent3</div></pre></td></tr></table></figure>
<p>这里遇到个小问题，就是Flume收集的日志文件到HDFS上查看有乱码，具体查看HDFS文件内容如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ hdfs dfs -cat /flume/events/events-.1474337184903</div><div class="line">SEQ!org.apache.hadoop.io.LongWritable&quot;org.apache.hadoop.io.BytesWritable�w�x0�\����WEX&quot;Ds &#123;&quot;TIME&quot;:&quot;2016-09-20 10:05:30&quot;,&quot;HOSTNAME&quot;:&quot;hadoop1&quot;,&quot;LI&quot;:&quot;:0&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;tailf command.log &quot;&#125;WEX&quot;Fs &#123;&quot;TIME&quot;:&quot;2016-09-20 10:05:30&quot;,&quot;HOSTNAME&quot;:&quot;hadoop1&quot;,&quot;LI&quot;:&quot;:0&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;tailf command.log &quot;&#125;WEX&quot;Gs &#123;&quot;TIME&quot;:&quot;2016-09-20 10:05:30&quot;,&quot;HOSTNAME&quot;:&quot;hadoop1&quot;,&quot;LI&quot;:&quot;:0&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;tailf command.log &quot;&#125;WEX&quot;Gs &#123;&quot;TIME&quot;:&quot;2016-09-20 10:05:30&quot;,&quot;HOSTNAME&quot;:&quot;hadoop1&quot;,&quot;LI&quot;:&quot;:0&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;tailf command.log &quot;&#125;WEX&quot;Hs &#123;&quot;TIME&quot;:&quot;2016-09-20 10:05:30&quot;,&quot;HOSTNAME&quot;:&quot;hadoop1&quot;,&quot;LI&quot;:&quot;:0&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;tailf command.log &quot;&#125;WEX&quot;Hs &#123;&quot;TIME&quot;:&quot;2016-09-20 10:05:30&quot;,&quot;HOSTNAME&quot;:&quot;hadoop1&quot;,&quot;LI&quot;:&quot;:0&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;tailf command.log &quot;&#125;WEX&quot;Hs &#123;&quot;TIME&quot;:&quot;2016-09-20 10:05:30&quot;,&quot;HOSTNAME&quot;:&quot;hadoop1&quot;,&quot;LI&quot;:&quot;:0&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;tailf command.log &quot;&#125;WEX&quot;Is &#123;&quot;TIME&quot;:&quot;2016-09-20 10:05:30&quot;,&quot;HOSTNAME&quot;:&quot;hadoop1&quot;,&quot;LI&quot;:&quot;:0&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;tailf command.log &quot;&#125;WEX&quot;Is &#123;&quot;TIME&quot;:&quot;2016-09-20 10:05:30&quot;,&quot;HOSTNAME&quot;:&quot;hadoop1&quot;,&quot;LI&quot;:&quot;:0&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;tailf command.log &quot;&#125;</div></pre></td></tr></table></figure>
<p>解决方式：HdfsEventSink中，hdfs.fileType默认为SequenceFile，将其改为DataStream就可以按照采集的文件原样输入到hdfs，加一行agentX.sinks.flume-hdfs-sink.hdfs.fileType = DataStream，如果不改就会出现HDFS文件乱码问题。</p>
<p>参考文章：</p>
<ul>
<li><a href="http://blog.csdn.net/cnbird2008/article/details/18967449" target="_blank" rel="external">http://blog.csdn.net/cnbird2008/article/details/18967449</a></li>
<li><a href="http://blog.csdn.net/lifuxiangcaohui/article/details/49949865" target="_blank" rel="external">http://blog.csdn.net/lifuxiangcaohui/article/details/49949865</a></li>
</ul>
<h3 id="Hive中创建表"><a href="#Hive中创建表" class="headerlink" title="Hive中创建表"></a>Hive中创建表</h3><p>下面是具体如何在Hive中基于HDFS文件创建表的</p>
<h4 id="启动相关服务"><a href="#启动相关服务" class="headerlink" title="启动相关服务"></a>启动相关服务</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"># 启动hdfs服务</div><div class="line">$ ./sbin/start-dfs.sh</div><div class="line"></div><div class="line"># 启动yarn服务</div><div class="line">$ ./sbin/start-yarn.sh</div><div class="line"></div><div class="line"># 进入hive安装目录</div><div class="line">$ cd /data/hive-1.2.1</div><div class="line"></div><div class="line"># 启动metastore</div><div class="line">$ ./bin/hive --service metastore &amp;</div><div class="line"></div><div class="line"># 启动hiveserver2</div><div class="line">$ ./bin/hive --service hiveserver2 &amp;</div><div class="line"></div><div class="line"># 启动hive shell</div><div class="line">$ ./bin/hive shell</div><div class="line">hive&gt;</div><div class="line">hive&gt; show databases;</div><div class="line">OK</div><div class="line">default</div><div class="line">Time taken: 1.323 seconds, Fetched: 1 row(s)</div></pre></td></tr></table></figure>
<p>如果看过上一篇Hive环境搭建的同学，到这里应该是一切正常的。如果启动metastore或者hiveserver2服务的时候遇到’MySQL: ERROR 1071 (42000): Specified key was too long; max key length is 767 bytes’错误，将MySQL元数据的hive数据库编码方式改成latin1就好了。</p>
<p>参考文章</p>
<ul>
<li><a href="http://blog.csdn.net/cindy9902/article/details/6215769" target="_blank" rel="external">http://blog.csdn.net/cindy9902/article/details/6215769</a></li>
</ul>
<h4 id="在HDFS中查看日志文件"><a href="#在HDFS中查看日志文件" class="headerlink" title="在HDFS中查看日志文件"></a>在HDFS中查看日志文件</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"># 之前我们在Flume中配置了采集到的日志输出到HDFS的保存路径是hdfs://10.10.1.64:8020/flume/events/</div><div class="line"></div><div class="line"># 查看HDFS文件存储路径</div><div class="line">$ hdfs dfs -ls /flume/events/</div><div class="line">Found 2 items-rw-r--r--   3 yunyu supergroup       1134 2016-09-19 23:43 /flume/events/events-.1474353822776-rw-r--r--   3 yunyu supergroup        126 2016-09-19 23:44 /flume/events/events-.1474353822777</div><div class="line"></div><div class="line"># 查看HDFS文件内容</div><div class="line">$ hdfs dfs -cat /flume/events/events-.1474353822776</div><div class="line">  543  &#123;&quot;TIME&quot;:&quot;2016-09-06 15:04:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;806&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ll&quot;&#125;</div><div class="line">  543  &#123;&quot;TIME&quot;:&quot;2016-09-06 15:04:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;806&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ll&quot;&#125;</div><div class="line">  543  &#123;&quot;TIME&quot;:&quot;2016-09-06 15:04:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;806&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ll&quot;&#125;</div><div class="line">  543  &#123;&quot;TIME&quot;:&quot;2016-09-06 15:04:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;806&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ll&quot;&#125;</div><div class="line">  543  &#123;&quot;TIME&quot;:&quot;2016-09-06 15:04:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;806&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ll&quot;&#125;</div><div class="line">  543  &#123;&quot;TIME&quot;:&quot;2016-09-06 15:04:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;806&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ll&quot;&#125;</div><div class="line">  565  &#123;&quot;TIME&quot;:&quot;2016-09-06 13:10:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;783&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ssh yunyu@10.10.1.15&quot;&#125;</div><div class="line">  565  &#123;&quot;TIME&quot;:&quot;2016-09-06 13:10:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;783&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ssh yunyu@10.10.1.15&quot;&#125;</div><div class="line">  565  &#123;&quot;TIME&quot;:&quot;2016-09-06 13:10:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;783&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ssh yunyu@10.10.1.15&quot;&#125;</div></pre></td></tr></table></figure>
<h4 id="使用org-apache-hadoop-hive-contrib-serde2-RegexSerDe解析日志"><a href="#使用org-apache-hadoop-hive-contrib-serde2-RegexSerDe解析日志" class="headerlink" title="使用org.apache.hadoop.hive.contrib.serde2.RegexSerDe解析日志"></a>使用org.apache.hadoop.hive.contrib.serde2.RegexSerDe解析日志</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"># 确认日志写入HDFS成功之后，我们需要在Hive中创建table</div><div class="line"># 启动hive shell</div><div class="line">$ ./bin/hive shell</div><div class="line"></div><div class="line"># 创建新的数据库test_hdfs</div><div class="line">hive&gt; create database test_hdfs;</div><div class="line">OKTime taken: 0.205 seconds</div><div class="line"></div><div class="line"># 使用数据库test_hdfs</div><div class="line">hive&gt; use test_hdfs;</div><div class="line"></div><div class="line"># 新建表command_test_table并且使用正则表达式提取日志文件中的字段信息</div><div class="line"># ROW FORMAT SERDE：这里使用的是正则表达式匹配</div><div class="line"># input.regex：指定配置日志的正则表达式</div><div class="line"># output.format.string：指定提取匹配正则表达式的字段</div><div class="line"># LOCATION：指定HDFS文件的存储路径</div><div class="line">hive&gt; CREATE EXTERNAL TABLE IF NOT EXISTS command_test_table(time STRING, hostname STRING, li STRING, lu STRING, nu STRING, cmd STRING)</div><div class="line">ROW FORMAT SERDE &apos;org.apache.hadoop.hive.contrib.serde2.RegexSerDe&apos;</div><div class="line">WITH SERDEPROPERTIES (</div><div class="line">&quot;input.regex&quot; = &apos;&quot;TIME&quot;:(.*),&quot;HOSTNAME&quot;:(.*),&quot;LI&quot;:(.*),&quot;LU&quot;:(.*),&quot;NU&quot;:(.*),&quot;CMD&quot;:(.*)&apos;,</div><div class="line">&quot;output.format.string&quot; = &quot;%1$s %2$s %3$s %4$s %5$s %6$s&quot;</div><div class="line">)</div><div class="line">STORED AS TEXTFILE</div><div class="line">LOCATION &apos;/flume/events&apos;;</div><div class="line"></div><div class="line"># 创建成功之后，查看表中的数据发现全都是NULL，说明正则表达式没有提取到对应的字段信息</div><div class="line">hive&gt; select * from command_test_table;OKNULL	NULL	NULL	NULL	NULL	NULLNULL	NULL	NULL	NULL	NULL	NULLNULL	NULL	NULL	NULL	NULL	NULLNULL	NULL	NULL	NULL	NULL	NULLNULL	NULL	NULL	NULL	NULL	NULLNULL	NULL	NULL	NULL	NULL	NULLNULL	NULL	NULL	NULL	NULL	NULLNULL	NULL	NULL	NULL	NULL	NULLNULL	NULL	NULL	NULL	NULL	NULLNULL	NULL	NULL	NULL	NULL	NULLTime taken: 0.087 seconds, Fetched: 10 row(s)</div></pre></td></tr></table></figure>
<p>这里因为我们的日志是字符串内含有json，想要通过正则表达式提取json的字段属性，通过Flume的Interceptors或者Logstash的Grok表达式很容易做到，可能是我对于Hive这块研究的还不够深入，所以没有深入去研究org.apache.hadoop.hive.contrib.serde2.RegexSerDe是否支持这种正则表达式的匹配，我又尝试了一下只用空格拆分的普通字符串日志格式。</p>
<p>日志格式如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">1 2 3</div><div class="line">4 5 6</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">hive&gt; CREATE EXTERNAL TABLE IF NOT EXISTS test_table(aa STRING, bb STRING, cc STRING)</div><div class="line">ROW FORMAT SERDE &apos;org.apache.hadoop.hive.contrib.serde2.RegexSerDe&apos;</div><div class="line">WITH SERDEPROPERTIES (</div><div class="line">&quot;input.regex&quot; = &apos;([^ ]*) ([^ ]*) ([^ ]*)&apos;,</div><div class="line">&quot;output.format.string&quot; = &quot;%1$s %2$s %3$s&quot;</div><div class="line">)</div><div class="line">STORED AS TEXTFILE</div><div class="line">LOCATION &apos;/flume/events&apos;;</div><div class="line"></div><div class="line">hive&gt; select * from test_table;</div><div class="line">OK</div><div class="line">1	2	3</div><div class="line">4	5	6Time taken: 0.035 seconds, Fetched: 2 row(s)</div></pre></td></tr></table></figure>
<p>发现用这种方式能够用正则表达式解析出来我们需要提取的字段信息。不知道是不是org.apache.hadoop.hive.contrib.serde2.RegexSerDe不支持这种带有json字符串的正则表达式匹配方式。这里我换了另一种做法，修改我们的日志格式尝试一下，我把command.log的日志内容修改成纯json字符串，然后使用org.apache.hive.hcatalog.data.JsonSerDe解析json字符串的匹配。下面是修改后的command.log日志文件内容。</p>
<h4 id="command-log日志文件-1"><a href="#command-log日志文件-1" class="headerlink" title="command.log日志文件"></a>command.log日志文件</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">&#123;&quot;TIME&quot;:&quot;2016-09-06 15:04:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;806&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ll&quot;&#125;</div><div class="line">&#123;&quot;TIME&quot;:&quot;2016-09-06 15:04:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;806&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ll&quot;&#125;</div><div class="line">&#123;&quot;TIME&quot;:&quot;2016-09-06 15:04:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;806&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ll&quot;&#125;</div><div class="line">&#123;&quot;TIME&quot;:&quot;2016-09-06 15:04:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;806&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ll&quot;&#125;</div><div class="line">&#123;&quot;TIME&quot;:&quot;2016-09-06 15:04:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;806&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ll&quot;&#125;</div><div class="line">&#123;&quot;TIME&quot;:&quot;2016-09-06 15:04:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;806&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ll&quot;&#125;</div><div class="line">&#123;&quot;TIME&quot;:&quot;2016-09-06 13:10:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;783&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ssh yunyu@10.10.1.15&quot;&#125;</div><div class="line">&#123;&quot;TIME&quot;:&quot;2016-09-06 13:10:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;783&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ssh yunyu@10.10.1.15&quot;&#125;</div><div class="line">&#123;&quot;TIME&quot;:&quot;2016-09-06 13:10:43&quot;,&quot;HOSTNAME&quot;:&quot;localhost&quot;,&quot;LI&quot;:&quot;783&quot;,&quot;LU&quot;:&quot;yunyu&quot;,&quot;NU&quot;:&quot;yunyu&quot;,&quot;CMD&quot;:&quot;ssh yunyu@10.10.1.15&quot;&#125;</div></pre></td></tr></table></figure>
<h4 id="使用org-apache-hive-hcatalog-data-JsonSerDe解析日志"><a href="#使用org-apache-hive-hcatalog-data-JsonSerDe解析日志" class="headerlink" title="使用org.apache.hive.hcatalog.data.JsonSerDe解析日志"></a>使用org.apache.hive.hcatalog.data.JsonSerDe解析日志</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"># Flume重新写入新的command.log日志到HDFS中</div><div class="line"># 启动hive shell</div><div class="line">$ ./bin/hive shell</div><div class="line"></div><div class="line"># 使用数据库test_hdfs</div><div class="line">hive&gt; use test_hdfs;</div><div class="line"></div><div class="line"># 新建表command_json_table并且使用json解析器提取日志文件中的字段信息</div><div class="line"># ROW FORMAT SERDE：这里使用的是json解析器匹配</div><div class="line"># LOCATION：指定HDFS文件的存储路径</div><div class="line">hive&gt; CREATE EXTERNAL TABLE IF NOT EXISTS command_json_table(time STRING, hostname STRING, li STRING, lu STRING, nu STRING, cmd STRING)</div><div class="line">ROW FORMAT SERDE &apos;org.apache.hive.hcatalog.data.JsonSerDe&apos;</div><div class="line">STORED AS TEXTFILE</div><div class="line">LOCATION &apos;/flume/events&apos;;</div><div class="line"></div><div class="line"># 这创建还是会报错，查看hive.log日志文件的错误信息，发现是缺少org.apache.hive.hcatalog.data.JsonSerDe类所在的jar包</div><div class="line">Caused by: java.lang.ClassNotFoundException: Class org.apache.hive.hcatalog.data.JsonSerDe not found</div><div class="line"></div><div class="line"># 查了下Hive的官网wiki，发现需要先执行add jar操作，将hive-hcatalog-core.jar添加到classpath（具体的jar包地址根据自己实际的Hive安装路径修改）</div><div class="line">add jar /usr/local/hive/hcatalog/share/hcatalog/hive-hcatalog-core-1.2.1.jar;</div><div class="line"></div><div class="line"># 为了避免每次启动hive shell都重新执行一下add jar操作，我们这里在$&#123;HIVE_HOME&#125;/conf/hive-env.sh启动脚本中添加如下信息</div><div class="line">export HIVE_AUX_JARS_PATH=/usr/local/hive/hcatalog/share/hcatalog</div><div class="line"></div><div class="line"># 重启Hive服务之后，再次创建command_json_table表成功</div><div class="line">hive&gt; CREATE EXTERNAL TABLE IF NOT EXISTS command_json_table(time STRING, hostname STRING, li STRING, lu STRING, nu STRING, cmd STRING)</div><div class="line">ROW FORMAT SERDE &apos;org.apache.hive.hcatalog.data.JsonSerDe&apos;</div><div class="line">STORED AS TEXTFILE</div><div class="line">LOCATION &apos;/flume/events&apos;;</div><div class="line"></div><div class="line"># 查看command_json_table表中的内容，json字段成功的解析出我们要的字段</div><div class="line">hive&gt; select * from command_json_table;</div><div class="line">OK2016-09-06 15:04:43	localhost	806	yunyu	yunyu	ll2016-09-06 15:04:43	localhost	806	yunyu	yunyu	ll2016-09-06 15:04:43	localhost	806	yunyu	yunyu	ll2016-09-06 15:04:43	localhost	806	yunyu	yunyu	ll2016-09-06 15:04:43	localhost	806	yunyu	yunyu	ll2016-09-06 15:04:43	localhost	806	yunyu	yunyu	ll2016-09-06 15:04:43	localhost	806	yunyu	yunyu	ll2016-09-06 13:10:43	localhost	783	yunyu	yunyu	ssh yunyu@10.10.1.152016-09-06 13:10:43	localhost	783	yunyu	yunyu	ssh yunyu@10.10.1.152016-09-06 13:10:43	localhost	783	yunyu	yunyu	ssh yunyu@10.10.1.15Time taken: 0.09 seconds, Fetched: 10 row(s)</div></pre></td></tr></table></figure>
<p>参考文章：</p>
<ul>
<li><a href="https://cwiki.apache.org/confluence/display/Hive/Json+SerDe" target="_blank" rel="external">https://cwiki.apache.org/confluence/display/Hive/Json+SerDe</a></li>
<li><a href="https://my.oschina.net/cjun/blog/494692" target="_blank" rel="external">https://my.oschina.net/cjun/blog/494692</a></li>
<li><a href="http://blog.csdn.net/bluishglc/article/details/46005269" target="_blank" rel="external">http://blog.csdn.net/bluishglc/article/details/46005269</a></li>
<li><a href="http://blog.sina.com.cn/s/blog_604c7cdd0102wbzz.html" target="_blank" rel="external">http://blog.sina.com.cn/s/blog_604c7cdd0102wbzz.html</a></li>
<li><a href="http://blog.csdn.net/xiao_jun_0820/article/details/38119123" target="_blank" rel="external">http://blog.csdn.net/xiao_jun_0820/article/details/38119123</a></li>
</ul>
<h4 id="使用select-count-验证Hive可以调用MapReduce进行离线任务处理"><a href="#使用select-count-验证Hive可以调用MapReduce进行离线任务处理" class="headerlink" title="使用select count(*)验证Hive可以调用MapReduce进行离线任务处理"></a>使用select count(*)验证Hive可以调用MapReduce进行离线任务处理</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"># 使用数据库test_hdfs</div><div class="line">hive&gt; use test_hdfs;</div><div class="line"></div><div class="line"># 统计command_json_table表的行数，执行失败</div><div class="line">hive&gt; select count(*) from command_json_table;</div><div class="line"></div><div class="line"># 查看yarn的log发现执行对应的mapreduce提示Connection Refused</div><div class="line"># 因为Hive最终是调用Hadoop的MapReduce来执行任务的，所以需要查看的是yarn的log日志</div><div class="line">appattempt_1474251946149_0003_000002. Got exception: java.net.ConnectException: Call From ubuntu/127.0.1.1 to ubuntu:50060 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</div></pre></td></tr></table></figure>
<p>这里我自己分析了一下原因，我们之前搭建的Hadoop集群配置是</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Hadoop1节点是namenode</div><div class="line">Hadoop2和Hadoop3这两个节点是datanode</div></pre></td></tr></table></figure>
<p>仔细看了一下报错的信息，我们现在在Hadoop1上安装的Hive，ubuntu:50060这个发现是连接的Hadoop1节点的50060端口，但是50060端口是NodeManager服务的端口，但这里Hadoop1不是datanode所以没有启动NodeManager服务，需要在slaves文件中把Hadoop1节点添加上</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"># 修改好之后重启dfs和yarn服务，再次执行sql语句</div><div class="line">hive&gt; select count(*) from command_json_table;</div><div class="line"></div><div class="line"># 又报如下的错误</div><div class="line">Application application_1474265561006_0002 failed 2 times due to Error launching appattempt_1474265561006_0002_000002. Got exception: java.net.ConnectException: Call From ubuntu/127.0.1.1 to ubuntu:52990 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused</div></pre></td></tr></table></figure>
<p>这个问题可把我坑惨了，后来自己分析了一下，原因一定是哪里的配置是我配置错了hostname是ubuntu了，但是找了一圈的配置文件也没找到，后来看网上说在namenode节点上用yarn node -list -all查看不健康的节点，发现没有问题。又尝试hdfs dfsadmin -report语句检查 DataNode 是否正常启动，让我查出来我的/etc/hosts默认配置带有’127.0.0.1 ubuntu’，这样Hadoop可能会用ubuntu这个hostname</p>
<p>重试之后还是不对，使用hostname命令查看ubuntu系统的hostname果然是’ubuntu’，ubuntu系统永久修改hostname是在/etc/hostname文件中修改，我这里对应修改成Hadoop1,hadoop2,hadoop3</p>
<p>修改/etc/hostname文件后，重新检查Hadoop集群的所有主机的hostname都已经不再是ubuntu了，都改成对应的hadoop1，hadoop2，hadoop3</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hdfs dfsadmin -report Configured Capacity: 198290427904 (184.67 GB)Present Capacity: 159338950656 (148.40 GB)DFS Remaining: 159084933120 (148.16 GB)DFS Used: 254017536 (242.25 MB)DFS Used%: 0.16%Under replicated blocks: 8Blocks with corrupt replicas: 0Missing blocks: 0Missing blocks (with replication factor 1): 0-------------------------------------------------Live datanodes (3):Name: 10.10.1.94:50010 (hadoop2)Hostname: hadoop2Decommission Status : NormalConfigured Capacity: 66449108992 (61.89 GB)DFS Used: 84217856 (80.32 MB)Non DFS Used: 8056225792 (7.50 GB)DFS Remaining: 58308665344 (54.30 GB)DFS Used%: 0.13%DFS Remaining%: 87.75%Configured Cache Capacity: 0 (0 B)Cache Used: 0 (0 B)Cache Remaining: 0 (0 B)Cache Used%: 100.00%Cache Remaining%: 0.00%Xceivers: 1Last contact: Tue Sep 20 02:23:19 PDT 2016Name: 10.10.1.64:50010 (hadoop1)Hostname: hadoop1Decommission Status : NormalConfigured Capacity: 65392209920 (60.90 GB)DFS Used: 84488192 (80.57 MB)Non DFS Used: 22853742592 (21.28 GB)DFS Remaining: 42453979136 (39.54 GB)DFS Used%: 0.13%DFS Remaining%: 64.92%Configured Cache Capacity: 0 (0 B)Cache Used: 0 (0 B)Cache Remaining: 0 (0 B)Cache Used%: 100.00%Cache Remaining%: 0.00%Xceivers: 1Last contact: Tue Sep 20 02:23:18 PDT 2016Name: 10.10.1.95:50010 (hadoop3)Hostname: hadoop3Decommission Status : NormalConfigured Capacity: 66449108992 (61.89 GB)DFS Used: 85311488 (81.36 MB)Non DFS Used: 8041508864 (7.49 GB)DFS Remaining: 58322288640 (54.32 GB)DFS Used%: 0.13%DFS Remaining%: 87.77%Configured Cache Capacity: 0 (0 B)Cache Used: 0 (0 B)Cache Remaining: 0 (0 B)Cache Used%: 100.00%Cache Remaining%: 0.00%Xceivers: 1Last contact: Tue Sep 20 02:23:20 PDT 2016</div></pre></td></tr></table></figure>
<p>重启系统之后，检查hostname都已经修改正确，再次启动dfs，yarn，hive服务，重试执行select count(*) from command_json_table;终于正确了。。。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hive&gt; select count(*) from command_json_table;</div><div class="line">Query ID = yunyu_20160920020204_544583fc-b872-44c8-95a6-a7b0c9611da7Total jobs = 1Launching Job 1 out of 1Number of reduce tasks determined at compile time: 1In order to change the average load for a reducer (in bytes):  set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;In order to limit the maximum number of reducers:  set hive.exec.reducers.max=&lt;number&gt;In order to set a constant number of reducers:  set mapreduce.job.reduces=&lt;number&gt;Starting Job = job_1474274066864_0003, Tracking URL = http://hadoop1:8088/proxy/application_1474274066864_0003/Kill Command = /data/hadoop-2.7.1/bin/hadoop job  -kill job_1474274066864_0003Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 12016-09-20 02:02:13,090 Stage-1 map = 0%,  reduce = 0%2016-09-20 02:02:19,318 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.14 sec2016-09-20 02:02:26,575 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 2.51 secMapReduce Total cumulative CPU time: 2 seconds 510 msecEnded Job = job_1474274066864_0003MapReduce Jobs Launched: Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 2.51 sec   HDFS Read: 8187 HDFS Write: 3 SUCCESSTotal MapReduce CPU Time Spent: 2 seconds 510 msecOK10Time taken: 23.155 seconds, Fetched: 1 row(s)</div></pre></td></tr></table></figure>
<p>参考文章：</p>
<ul>
<li><a href="http://www.powerxing.com/install-hadoop-cluster/" target="_blank" rel="external">http://www.powerxing.com/install-hadoop-cluster/</a></li>
<li><a href="http://www.th7.cn/Program/java/201609/968295.shtml" target="_blank" rel="external">http://www.th7.cn/Program/java/201609/968295.shtml</a></li>
<li><a href="http://blog.csdn.net/ruglcc/article/details/7802077" target="_blank" rel="external">http://blog.csdn.net/ruglcc/article/details/7802077</a></li>
</ul>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/HDFS/">HDFS</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hive/">Hive</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Hive/Hive学习（一）Hive环境搭建" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/09/18/Hive/Hive学习（一）Hive环境搭建/" class="article-date">
  	<time datetime="2016-09-18T08:48:04.000Z" itemprop="datePublished">2016-09-18</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/09/18/Hive/Hive学习（一）Hive环境搭建/">Hive学习（一）Hive环境搭建</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Hive必须运行在Hadoop之上，则需要先安装Hadoop环境，而且还需要MySQL数据库，具体Hadoop安装请参考Hadoop系列文章</p>
<h3 id="Hive环境安装"><a href="#Hive环境安装" class="headerlink" title="Hive环境安装"></a>Hive环境安装</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"># 下载Hive</div><div class="line">$ wget http://apache.mirrors.ionfish.org/hive/hive-1.2.1/apache-hive-1.2.1-bin.tar.gz</div><div class="line"></div><div class="line"># 解压Hive压缩包</div><div class="line">$ tar -zxvf apache-hive-1.2.1-bin.tar.gz</div><div class="line"></div><div class="line"># 下载MySQL驱动包</div><div class="line">$ wget http://cdn.mysql.com//Downloads/Connector-J/mysql-connector-java-5.1.38.tar.gz</div><div class="line"></div><div class="line"># 解压MySQL驱动压缩包</div><div class="line">$ tar -zxvf mysql-connector-java-5.1.38.tar.gz</div></pre></td></tr></table></figure>
<h3 id="Hive相关的配置文件"><a href="#Hive相关的配置文件" class="headerlink" title="Hive相关的配置文件"></a>Hive相关的配置文件</h3><p>注意：以下配置请根据自己的实际环境修改</p>
<h5 id="配置环境变量-etc-profile"><a href="#配置环境变量-etc-profile" class="headerlink" title="配置环境变量/etc/profile"></a>配置环境变量/etc/profile</h5><pre><code>HIVE_HOME=/usr/local/hive
export HIVE_HOME
HIVE_JARS=$HIVE_HOME/lib
export HIVE_JARS
PATH=$JAVA_HOME/bin:$HIVE_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$MAVEN_HOME/bin:$PATH
export PATH
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">##### 配置HIVE_HOME/conf/hive-env.sh（默认不存在，将hive-env.sh.template复制并改名为hive-env.sh）</div></pre></td></tr></table></figure>

# 这里使用此路径是因为安装Hadoop环境的时候，设置了环境变量PATH
HADOOP_HOME=/usr/local/hadoop
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">##### 配置HIVE_HOME/conf/hive-log4j.properties（默认不存在，将hive-log4j.properties.template复制并改名为hive-log4j.properties）</div><div class="line"></div><div class="line">这里使用默认配置即可，不需要修改</div><div class="line"></div><div class="line">##### 配置HIVE_HOME/conf/hdfs-site.xml（默认不存在，将hive-default.xml.template复制并改名为hive-site.xml）</div><div class="line"></div><div class="line">这里的Hadoop1是我们Hadoop集群的namenode主机的hostname，mysql安装在另外一台机器10.10.1.46上</div></pre></td></tr></table></figure>

&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;no&quot;?&gt;
&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;

&lt;configuration&gt;
   &lt;property&gt;
       &lt;!-- metastore我的mysql不是在该server上，是在另一台Docker镜像中 --&gt;
        &lt;name&gt;hive.metastore.local&lt;/name&gt;
        &lt;value&gt;false&lt;/value&gt;
   &lt;/property&gt;
   &lt;property&gt;
        &lt;!-- mysql服务的ip和端口号 --&gt;
        &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;
        &lt;value&gt;jdbc:mysql://10.10.1.46:3306/hive&lt;/value&gt;
   &lt;/property&gt;
   &lt;property&gt;
        &lt;name&gt;javax.jdo.option.ConnectionDriveName&lt;/name&gt;
        &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;
   &lt;/property&gt;
   &lt;property&gt;
        &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;
        &lt;value&gt;root&lt;/value&gt;
   &lt;/property&gt;
   &lt;property&gt;
        &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;
        &lt;value&gt;root&lt;/value&gt;
   &lt;/property&gt;
   &lt;property&gt;
        &lt;!-- hive的仓库目录，需要在HDFS上创建，并修改权限 --&gt;
        &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt;
        &lt;value&gt;/hive/warehouse&lt;/value&gt;
   &lt;/property&gt;
   &lt;property&gt;
        &lt;!-- 运行hive得主机地址及端口，即本机ip和端口号，启动metastore服务 --&gt;
        &lt;name&gt;hive.metastore.uris&lt;/name&gt;
        &lt;value&gt;thrift://Hadoop1:9083&lt;/value&gt;
   &lt;/property&gt;
&lt;/configuration&gt;
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">##### 控制台终端</div></pre></td></tr></table></figure>

# 初始化namenode
#（这一步根据自己的实际情况选择是否初始化，如果初始化过了就不需要再初始化了）
$ ./bin/hdfs namenode -format

# 启动hdfs服务
$ ./sbin/start-dfs.sh
Starting namenodes on [hadoop1]
hadoop1: starting namenode, logging to /data/hadoop-2.7.1/logs/hadoop-yunyu-namenode-ubuntu.out
hadoop2: starting datanode, logging to /data/hadoop-2.7.1/logs/hadoop-yunyu-datanode-ubuntu.out
hadoop3: starting datanode, logging to /data/hadoop-2.7.1/logs/hadoop-yunyu-datanode-ubuntu.out
Starting secondary namenodes [hadoop1]
hadoop1: starting secondarynamenode, logging to /data/hadoop-2.7.1/logs/hadoop-yunyu-secondarynamenode-ubuntu.out

# 启动yarn服务
$ ./sbin/start-yarn.sh
starting yarn daemons
starting resourcemanager, logging to /data/hadoop-2.7.1/logs/yarn-yunyu-resourcemanager-ubuntu.out
hadoop3: starting nodemanager, logging to /data/hadoop-2.7.1/logs/yarn-yunyu-nodemanager-ubuntu.out
hadoop2: starting nodemanager, logging to /data/hadoop-2.7.1/logs/yarn-yunyu-nodemanager-ubuntu.out

# 进入hive安装目录
$ cd /data/hive-1.2.1

# 启动metastore
# 注意：启动metastore之前一定要检查hive-site.xml配置文件中配置的mysql数据库地址10.10.1.46中是否有配置的hive数据库，如果没有启动会报错，需要事先创建好空的数据库，启动metastore后会自动初始化hive的元数据表
$ ./bin/hive --service metastore &amp;

# 启动的时候可能会遇到下面的错误，是因为没有找到mysql驱动包
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://10.10.1.46:3306/hive
    at java.sql.DriverManager.getConnection(DriverManager.java:596)
    at java.sql.DriverManager.getConnection(DriverManager.java:187)
    at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
    at com.jolbox.bonecp.BoneCP.&lt;init&gt;(BoneCP.java:416)
    ... 48 more

# 把下载的mysql驱动包copy到hive/lib目录下重启即可
$ cp mysql-connector-java-5.1.38-bin.jar /data/hive-1.2.1/lib/

# 启动hiveserver2
$ ./bin/hive --service hiveserver2 &amp;

# 此时重新启动hive shell，就可以成功登录hive了
$ ./bin/hive shell
hive&gt;
hive&gt; show databases;
OK
default
Time taken: 1.323 seconds, Fetched: 1 row(s)

# 注意：这里使用的MySQL的root账号需要处理更改密码和远程登录授权问题，所以这里没有涉及这些问题，具体设置可以参考之前的Docker安装MySQL镜像的文章

# 我们需要预先在mysql中创建一个hive的数据库，因为hive-site.xml是连接到这个hive数据库的，所有的hive元数据都是存在这个hive数据库中的
# 我们在hive中创建新的数据库和表来验证hive的元数据都存储在mysql了

# 在hive中创建一个新的数据库test_hive，test_hive这个数据库会对应mysql中的hive数据库中的DBS表中的一条记录
hive&gt; CREATE DATABASE test_hive;

# 在hive中创建一个新的表test_person，test_person这个表会对应mysql中的hive数据库中的TBLS表中的一条记录
hive&gt; USE test_hive;
hive&gt; CREATE TABLE test_person (id INT,name string) ROW FORMAT DELIMITED FIELDS TERMINATED BY &apos;\t&apos;;


# 在hive创建表的时候可能会遇到如下问题，是因为MySQL数据库字符集设置的utf-8导致的
# Specified key was too long; max key length is 767 bytes
# 修改MySQL的hive数据库的字符集为latin1就好用了
$ alter database hive character set latin1;
# 参考：http://blog.163.com/zhangjie_0303/blog/static/990827062013112623615941/

# test_person.txt
1    John
2    Ben
3    Allen
4    Jimmy
5    Will
6    Jackson

# 导入数据到test_person.txt到test_person表
hive&gt; LOAD DATA LOCAL INPATH &apos;/data/test_person.txt&apos; OVERWRITE INTO TABLE test_person;
Loading data to table test_hive.test_person
Table test_hive.test_person stats: [numFiles=1, numRows=0, totalSize=45, rawDataSize=0]
OK
Time taken: 2.885 seconds

# 查看test_person表数据
hive&gt; select * from test_person;
OK
1    John
2    Ben
3    Allen
4    Jimmy
5    Will
6    Jackson
Time taken: 0.7 seconds, Fetched: 6 row(s)

# 查看test_hive数据库在HDFS中存储的目录
$ cd /data/hadoop-2.7.1/bin

# 查看HDFS中/hive/warehouse目录下的所有文件，此目录是在hive-site.xml中hive.metastore.warehouse.dir参数配置的路径/hive/warehouse
$ ./bin/hdfs dfs -ls /hive/warehouse/
Found 1 items
drwxr-xr-x   - admin supergroup          0 2016-06-25 11:39 /hive/warehouse/test_hive.db

# 查看test_person表在HDFS中存储的目录
$ ./bin/hdfs dfs -ls /hive/warehouse/test_hive.db/
Found 1 items
drwxr-xr-x   - admin supergroup          0 2016-06-25 11:52 /hive/warehouse/test_hive.db/test_person

# 在深入一层就能看到我们导入的文件test_person.txt了
$ ./bin/hdfs dfs -ls /hive/warehouse/test_hive.db/test_person/
Found 1 items
-rwxr-xr-x   3 admin supergroup         45 2016-06-25 11:52 /hive/warehouse/test_hive.db/test_person/test_person.txt

# 查看test_person.txt文件里的内容，就是我们导入的内容
$ ./bin/hdfs dfs -cat /hive/warehouse/test_hive.db/test_person/test_person.txt
1    John
2    Ben
3    Allen
4    Jimmy
5    Will
6    Jackson
</code></pre><p>参考文章：</p>
<ul>
<li><a href="http://my.oschina.net/u/204498/blog/522772" target="_blank" rel="external">http://my.oschina.net/u/204498/blog/522772</a></li>
<li><a href="http://blog.fens.me/hadoop-hive-intro/" target="_blank" rel="external">http://blog.fens.me/hadoop-hive-intro/</a></li>
<li><a href="http://www.mincoder.com/article/5809.shtml" target="_blank" rel="external">http://www.mincoder.com/article/5809.shtml</a></li>
<li><a href="http://blog.163.com/zhangjie_0303/blog/static/990827062013112623615941/" target="_blank" rel="external">http://blog.163.com/zhangjie_0303/blog/static/990827062013112623615941/</a></li>
</ul>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/HDFS/">HDFS</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hive/">Hive</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Git/Git的SSH-Key用法" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/09/11/Git/Git的SSH-Key用法/" class="article-date">
  	<time datetime="2016-09-11T08:51:32.000Z" itemprop="datePublished">2016-09-11</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/09/11/Git/Git的SSH-Key用法/">Git的SSH-Key用法</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>之前GitHub提交代码的时候总是不知道该使用SSH方式还是Https方式，后来看了GitHub官网上建议使用Https方式，但Https方式有些麻烦，因为每次使用Https方式提交代码的时候都需要输入用户名和密码，而用SSH方式就有免密码登录的方式，只是需要在GitHub服务器添加我们本地的公钥就可以了。但是之前有一点令我一直都不解，虽然我用Https方式提交代码但是并没有让我输入用户名密码，后来找了好久原因才发现是因为我用的Mac笔记本，Mac系统有个钥匙串记录的功能，会将GitHub的用户名密码保存下来。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"># 首先在本地生成公钥/私钥的键值对</div><div class="line">$ ssh-keygen -t rsa -b 4096 -C &quot;your_email@example.com&quot;</div><div class="line"># 输入公钥/私钥的文件路径</div><div class="line">Enter a file in which to save the key (/Users/you/.ssh/id_rsa): [Press enter]</div><div class="line">Enter passphrase (empty for no passphrase): [Type a passphrase]</div><div class="line">Enter same passphrase again: [Type passphrase again]</div><div class="line"># 复制公钥文件中的内容，并且添加到GitHub上即可</div><div class="line">$ cat ~/.ssh/id_dsa.pub</div></pre></td></tr></table></figure>
<p>同样的道理，如果我们想在本地免密码登录测试服务器，那么我们也可以用这样的方式来设置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"># 首先在本地生成公钥/私钥的键值对</div><div class="line">$ ssh-keygen -t dsa -P &apos;&apos; -f ~/.ssh/id_dsa</div><div class="line">$ cat ~/.ssh/id_dsa.pub</div><div class="line"></div><div class="line"># 将本地的公钥上传到测试服务器</div><div class="line">$ scp root@LocalServer:~/.ssh/id_dsa.pub  ~/.ssh/master_dsa.pub</div><div class="line"># 将上传的本地公钥添加到authorized_keys中</div><div class="line">$ cat ~/.ssh/master_dsa.pub &gt;&gt; ~/.ssh/authorized_keys</div></pre></td></tr></table></figure>
<p>参考文章：</p>
<ul>
<li><a href="https://help.github.com/articles/which-remote-url-should-i-use/" target="_blank" rel="external">https://help.github.com/articles/which-remote-url-should-i-use/</a></li>
<li><a href="http://www.jianshu.com/p/1ac06bcd8ab5" target="_blank" rel="external">http://www.jianshu.com/p/1ac06bcd8ab5</a></li>
</ul>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Git命令/">Git命令</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Git/">Git</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Hadoop/Hadoop学习（一）Hadoop完全分布式环境搭建" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/09/10/Hadoop/Hadoop学习（一）Hadoop完全分布式环境搭建/" class="article-date">
  	<time datetime="2016-09-10T08:09:30.000Z" itemprop="datePublished">2016-09-10</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/09/10/Hadoop/Hadoop学习（一）Hadoop完全分布式环境搭建/">Hadoop学习（一）Hadoop完全分布式环境搭建</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>今天学习的信息量有点大收获不少，一时之间不知道从哪里开始写，希望尽量把我今天学习到的东西记录下来，因为内容太多可能会分几篇记录。其实之前有写过一篇用Docker搭建Hadoop环境的文章，当时其实搭建的是单机伪分布式的环境，今天这里搭建的是Hadoop完全分布式环境。今天又看了许多文章，对于Hadoop的体系架构又有了一定新的理解，包括1.x版本和2.x版本的不同。</p>
<h3 id="Hadoop集群环境"><a href="#Hadoop集群环境" class="headerlink" title="Hadoop集群环境"></a>Hadoop集群环境</h3><p>我这里使用的三台虚拟机，每台虚拟机有自己的独立IP</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">192.168.1.119   hadoop1192.168.1.150   hadoop2192.168.1.149   hadoop3</div></pre></td></tr></table></figure>
<p>相关环境信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">操作系统: Ubuntu 14.04.5 LTS</div><div class="line">JDK版本: 1.7.0_79</div><div class="line">Hadoop版本: 2.7.1</div></pre></td></tr></table></figure>
<h3 id="JDK安装"><a href="#JDK安装" class="headerlink" title="JDK安装"></a>JDK安装</h3><p>省略</p>
<h3 id="Hadoop安装"><a href="#Hadoop安装" class="headerlink" title="Hadoop安装"></a>Hadoop安装</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"># 下载Hadoop安装包</div><div class="line">$ curl -O http://mirrors.cnnic.cn/apache/hadoop/common/hadoop-2.7.1/hadoop-2.7.1.tar.gz</div><div class="line"></div><div class="line"># 解压Hadoop压缩包</div><div class="line">$ tar -zxvf hadoop-2.7.1.tar.gz</div></pre></td></tr></table></figure>
<h3 id="Hadoop集群配置"><a href="#Hadoop集群配置" class="headerlink" title="Hadoop集群配置"></a>Hadoop集群配置</h3><p>注意：以下配置请根据自己的实际环境修改</p>
<h5 id="配置环境变量-etc-profile"><a href="#配置环境变量-etc-profile" class="headerlink" title="配置环境变量/etc/profile"></a>配置环境变量/etc/profile</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">JAVA_HOME=/usr/local/javaexport JAVA_HOMEHADOOP_HOME=/usr/local/hadoopexport HADOOP_HOMEPATH=$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATHexport PATH</div></pre></td></tr></table></figure>
<h5 id="配置HADOOP-HOME-etc-hadoop-hadoop-env-sh，添加以下内容"><a href="#配置HADOOP-HOME-etc-hadoop-hadoop-env-sh，添加以下内容" class="headerlink" title="配置HADOOP_HOME/etc/hadoop/hadoop-env.sh，添加以下内容"></a>配置HADOOP_HOME/etc/hadoop/hadoop-env.sh，添加以下内容</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">export JAVA_HOME=/usr/local/java</div><div class="line">export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</div></pre></td></tr></table></figure>
<h5 id="配置HADOOP-HOME-etc-hadoop-yarn-env-sh，添加以下内容"><a href="#配置HADOOP-HOME-etc-hadoop-yarn-env-sh，添加以下内容" class="headerlink" title="配置HADOOP_HOME/etc/hadoop/yarn-env.sh，添加以下内容"></a>配置HADOOP_HOME/etc/hadoop/yarn-env.sh，添加以下内容</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">export JAVA_HOME=/usr/local/java</div></pre></td></tr></table></figure>
<h5 id="配置HADOOP-HOME-etc-hadoop-core-site-xml"><a href="#配置HADOOP-HOME-etc-hadoop-core-site-xml" class="headerlink" title="配置HADOOP_HOME/etc/hadoop/core-site.xml"></a>配置HADOOP_HOME/etc/hadoop/core-site.xml</h5><p>这里我使用Hadoop1这台虚拟机作为NameNode节点</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">    &lt;name&gt;fs.defaultFS&lt;/name&gt;</div><div class="line">    &lt;value&gt;hdfs://Hadoop1:9000&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
<h5 id="配置HADOOP-HOME-etc-hadoop-hdfs-site-xml"><a href="#配置HADOOP-HOME-etc-hadoop-hdfs-site-xml" class="headerlink" title="配置HADOOP_HOME/etc/hadoop/hdfs-site.xml"></a>配置HADOOP_HOME/etc/hadoop/hdfs-site.xml</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">  &lt;!-- 分布式文件系统数据块复制数，我们这里是Hadoop2和Hadoop3两个节点 --&gt;  &lt;property&gt;    &lt;name&gt;dfs.replication&lt;/name&gt;    &lt;value&gt;2&lt;/value&gt;  &lt;/property&gt;</div><div class="line">  &lt;!-- DFS namenode存放name table的目录 --&gt;  &lt;property&gt;    &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;    &lt;value&gt;file:/data/hdfs/name&lt;/value&gt;  &lt;/property&gt;</div><div class="line">  &lt;!-- DFS datanode存放数据block的目录 --&gt;  &lt;property&gt;    &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;    &lt;value&gt;file:/data/hdfs/data&lt;/value&gt;  &lt;/property&gt;</div><div class="line">  &lt;!-- SecondaryNameNode的端口号，默认端口号是50090 --&gt;  &lt;property&gt;    &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;    &lt;value&gt;hadoop1:50090&lt;/value&gt;  &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
<h5 id="配置HADOOP-HOME-etc-hadoop-mapred-site-xml-默认不存在，需要自建"><a href="#配置HADOOP-HOME-etc-hadoop-mapred-site-xml-默认不存在，需要自建" class="headerlink" title="配置HADOOP_HOME/etc/hadoop/mapred-site.xml,默认不存在，需要自建"></a>配置HADOOP_HOME/etc/hadoop/mapred-site.xml,默认不存在，需要自建</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">  &lt;!-- 第三方MapReduce框架，我们这里使用的yarn --&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</div><div class="line">    &lt;value&gt;yarn&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">  &lt;!-- MapReduce JobHistory Server的IPC通信地址，默认端口号是10020 --&gt;</div><div class="line">  &lt;property&gt;     &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;     &lt;value&gt;hadoop1:10020&lt;/value&gt;  &lt;/property&gt;</div><div class="line">  &lt;!-- MapReduce JobHistory Server的Web服务器访问地址，默认端口号是19888 --&gt;  &lt;property&gt;     &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;     &lt;value&gt;hadoop1:19888&lt;/value&gt;  &lt;/property&gt;</div><div class="line">  &lt;!-- MapReduce已完成作业信息 --&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">    &lt;name&gt;mapreduce.jobhistory.done-dir&lt;/name&gt;</div><div class="line">    &lt;value&gt;/data/history/done&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">  &lt;!-- MapReduce正在运行作业信息 --&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">    &lt;name&gt;mapreduce.jobhistory.intermediate-done-dir&lt;/name&gt;</div><div class="line">    &lt;value&gt;/data/history/done_intermediate&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
<h5 id="配置HADOOP-HOME-etc-hadoop-yarn-site-xml"><a href="#配置HADOOP-HOME-etc-hadoop-yarn-site-xml" class="headerlink" title="配置HADOOP_HOME/etc/hadoop/yarn-site.xml"></a>配置HADOOP_HOME/etc/hadoop/yarn-site.xml</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">  &lt;!-- 为MapReduce设置洗牌服务 --&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</div><div class="line">    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">  &lt;property&gt;    &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;    &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;  &lt;/property&gt;</div><div class="line">  &lt;!-- NodeManager与ResourceManager通信的接口地址，默认端口是8032 --&gt;</div><div class="line">  &lt;property&gt;    &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;    &lt;value&gt;hadoop1:8032&lt;/value&gt;  &lt;/property&gt;</div><div class="line">  &lt;!-- NodeManger需要知道ResourceManager主机的scheduler调度服务接口地址，默认端口是8030 --&gt;  &lt;property&gt;    &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;    &lt;value&gt;hadoop1:8030&lt;/value&gt;  &lt;/property&gt;</div><div class="line">  &lt;!-- NodeManager需要向ResourceManager报告任务运行状态供Resouce跟踪，因此NodeManager节点主机需要知道ResourceManager主机的tracker接口地址，默认端口是8031 --&gt;  &lt;property&gt;    &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;    &lt;value&gt;hadoop1:8031&lt;/value&gt;  &lt;/property&gt;</div><div class="line">  &lt;!-- resourcemanager.admin，默认端口是8033 --&gt;  &lt;property&gt;    &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;    &lt;value&gt;hadoop1:8033&lt;/value&gt;  &lt;/property&gt;</div><div class="line">  &lt;!-- 各个task的资源调度及运行状况通过通过该web界面访问，默认端口是8088 --&gt;  &lt;property&gt;    &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;    &lt;value&gt;hadoop1:8088&lt;/value&gt;  &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
<h5 id="配置slaves节点，修改HADOOP-HOME-etc-hadoop-slaves"><a href="#配置slaves节点，修改HADOOP-HOME-etc-hadoop-slaves" class="headerlink" title="配置slaves节点，修改HADOOP_HOME/etc/hadoop/slaves"></a>配置slaves节点，修改HADOOP_HOME/etc/hadoop/slaves</h5><p>如果slaves配置中也添加Hadoop1节点，那么Hadoop1节点就既是namenode，又是datanode，这里没有这么配置，所以Hadoop1节点只是namenode，所以下面启动Hadoop1的服务之后，jps查看只有namenode服务器而没有datanode服务</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Hadoop2</div><div class="line">Hadoop3</div></pre></td></tr></table></figure>
<h5 id="配置-etc-hostname"><a href="#配置-etc-hostname" class="headerlink" title="配置/etc/hostname"></a>配置/etc/hostname</h5><p>Hadoop1,2,3分别修改自己的/etc/hostname文件，如果这里不修改的话，后面使用Hive做离线查询会遇到问题，具体问题请参考《Hive学习（二）使用Hive进行离线分析日志》</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hadoop1</div></pre></td></tr></table></figure>
<h5 id="配置主机名-etc-hosts"><a href="#配置主机名-etc-hosts" class="headerlink" title="配置主机名/etc/hosts"></a>配置主机名/etc/hosts</h5><p>这里Hadoop1是namenode，Hadoop2和Hadoop3是datanode</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">192.168.1.119   hadoop1192.168.1.150   hadoop2192.168.1.149   hadoop3</div></pre></td></tr></table></figure>
<h5 id="配置SSH免密码登录"><a href="#配置SSH免密码登录" class="headerlink" title="配置SSH免密码登录"></a>配置SSH免密码登录</h5><p>在Hadoop1节点中生成新的SSH Key，并且将新生成的SSH Key添加到Hadoop1，2，3的authorized_keys免密码访问的配置中</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"># 创建authorized_keys文件</div><div class="line">$ vi ~/.ssh/authorized_keys</div><div class="line"></div><div class="line"># 注意：这里authorized_keys文件的权限设置为600。（这点很重要，网没有设置600权限会导致登录失败）因为我这里用的root账户没有这个问题，但是如果用自己创建的其他hadoop账户，不设置600权限就会导致登录失败</div><div class="line"></div><div class="line"># Hadoop1中执行</div><div class="line">$ ssh-keygen -t dsa -P &apos;&apos; -f ~/.ssh/id_dsa</div><div class="line"># 将Hadoop1中的公钥复制进去</div><div class="line">$ cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys</div><div class="line"></div><div class="line"># Hadoop2，3中执行</div><div class="line">$ scp root@Hadoop1:~/.ssh/id_dsa.pub  ~/.ssh/master_dsa.pub</div><div class="line"># 将Hadoop2，3中的公钥复制进去</div><div class="line">$ cat ~/.ssh/master_dsa.pub &gt;&gt; ~/.ssh/authorized_keys</div><div class="line"></div><div class="line"># 在Hadoop1中测试是否可以免密码登录Hadoop1，2，3（第一次应该只需要输入yes）</div><div class="line">$ ssh root@Hadoop1</div><div class="line">$ ssh root@Hadoop2</div><div class="line">$ ssh root@Hadoop3</div></pre></td></tr></table></figure>
<h5 id="配置好Hadoop1之后，将Hadoop1的配置copy到Hadoop2和Hadoop3"><a href="#配置好Hadoop1之后，将Hadoop1的配置copy到Hadoop2和Hadoop3" class="headerlink" title="配置好Hadoop1之后，将Hadoop1的配置copy到Hadoop2和Hadoop3"></a>配置好Hadoop1之后，将Hadoop1的配置copy到Hadoop2和Hadoop3</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"># 在Hadoop1中执行</div><div class="line">$ scp -r /data/hadoop-2.7.1 root@Hadoop2:/data/</div><div class="line">$ scp -r /data/hadoop-2.7.1 root@Hadoop3:/data/</div></pre></td></tr></table></figure>
<h5 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"># 初始化namenode</div><div class="line">$ ./bin/hdfs namenode -format</div><div class="line"></div><div class="line"># 初始化好namenode后，hadoop会自动建好对应hdfs-site.xml的namenode配置的文件路径</div><div class="line">$ ll /data/hdfs/name/current/total 24drwxrwxr-x 2 yunyu yunyu 4096 Sep 10 18:07 ./drwxrwxr-x 3 yunyu yunyu 4096 Sep 10 18:07 ../-rw-rw-r-- 1 yunyu yunyu  352 Sep 10 18:07 fsimage_0000000000000000000-rw-rw-r-- 1 yunyu yunyu   62 Sep 10 18:07 fsimage_0000000000000000000.md5-rw-rw-r-- 1 yunyu yunyu    2 Sep 10 18:07 seen_txid-rw-rw-r-- 1 yunyu yunyu  202 Sep 10 18:07 VERSION</div><div class="line"></div><div class="line"># 启动hdfs服务</div><div class="line">$ ./sbin/start-dfs.sh</div><div class="line">Starting namenodes on [hadoop1]hadoop1: starting namenode, logging to /data/hadoop-2.7.1/logs/hadoop-yunyu-namenode-ubuntu.outhadoop2: starting datanode, logging to /data/hadoop-2.7.1/logs/hadoop-yunyu-datanode-ubuntu.outhadoop3: starting datanode, logging to /data/hadoop-2.7.1/logs/hadoop-yunyu-datanode-ubuntu.outStarting secondary namenodes [hadoop1]hadoop1: starting secondarynamenode, logging to /data/hadoop-2.7.1/logs/hadoop-yunyu-secondarynamenode-ubuntu.out</div><div class="line"></div><div class="line"># 使用jps检查启动的服务，可以看到NameNode和SecondaryNameNode已经启动</div><div class="line">$ jps20379 SecondaryNameNode20570 Jps20106 NameNode</div><div class="line"></div><div class="line"># 这时候在Hadoop2和Hadoop3节点上使用jps查看，DataNode已经启动</div><div class="line">$ jps16392 Jps16024 DataNode</div><div class="line"></div><div class="line"># 在Hadoop2和Hadoop3节点上，也会自动建好对应hdfs-site.xml的datanode配置的文件路径</div><div class="line">$ ll /data/hdfs/data/current/total 16drwxrwxr-x 3 yunyu yunyu 4096 Sep 10 18:10 ./drwx------ 3 yunyu yunyu 4096 Sep 10 18:10 ../drwx------ 4 yunyu yunyu 4096 Sep 10 18:10 BP-1965589257-127.0.1.1-1473502067891/-rw-rw-r-- 1 yunyu yunyu  229 Sep 10 18:10 VERSION</div><div class="line"></div><div class="line"># 启动yarn服务</div><div class="line">$ ./sbin/start-yarn.sh</div><div class="line">starting yarn daemonsstarting resourcemanager, logging to /data/hadoop-2.7.1/logs/yarn-yunyu-resourcemanager-ubuntu.outhadoop3: starting nodemanager, logging to /data/hadoop-2.7.1/logs/yarn-yunyu-nodemanager-ubuntu.outhadoop2: starting nodemanager, logging to /data/hadoop-2.7.1/logs/yarn-yunyu-nodemanager-ubuntu.out</div><div class="line"></div><div class="line"># 使用jps检查启动的服务，可以看到ResourceManager已经启动</div><div class="line">$ jps21653 Jps20379 SecondaryNameNode20106 NameNode21310 ResourceManager</div><div class="line"></div><div class="line"># 这时候在Hadoop2和Hadoop3节点上使用jps查看，NodeManager已经启动</div><div class="line">$ jps16946 NodeManager17235 Jps16024 DataNode</div><div class="line"></div><div class="line"># 启动jobhistory服务，默认jobhistory在使用start-all.sh是不启动的，所以即使使用start-all.sh也要手动启动jobhistory服务</div><div class="line">$ ./sbin/mr-jobhistory-daemon.sh start historyserver</div><div class="line">starting historyserver, logging to /data/hadoop-2.7.1/logs/mapred-yunyu-historyserver-ubuntu.out</div><div class="line"></div><div class="line"># 使用jps检查启动的服务，可以看到JobHistoryServer已经启动</div><div class="line">$ jps21937 Jps20379 SecondaryNameNode20106 NameNode21863 JobHistoryServer21310 ResourceManager</div></pre></td></tr></table></figure>
<p>注意：使用start-all.sh启动已经不再被推荐使用，所以这里使用的是Hadoop推荐的分开启动，分别启动start-dfs.sh和start-yarn.sh，所以看一些比较就的Hadoop版本安装的文章可能会用start-all.sh启动</p>
<h5 id="停止服务"><a href="#停止服务" class="headerlink" title="停止服务"></a>停止服务</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"># 停止hdfs服务</div><div class="line">$ ./sbin/stop-dfs.sh</div><div class="line"></div><div class="line"># 停止yarn服务</div><div class="line">$ ./sbin/stop-yarn.sh</div><div class="line"></div><div class="line"># 停止jobhistory服务</div><div class="line">$ ./sbin/mr-jobhistory-daemon.sh stop historyserver</div></pre></td></tr></table></figure>
<h5 id="验证Hadoop集群的Web服务"><a href="#验证Hadoop集群的Web服务" class="headerlink" title="验证Hadoop集群的Web服务"></a>验证Hadoop集群的Web服务</h5><ul>
<li><p>验证NameNode的Web服务能访问，浏览器访问<a href="http://192.168.1.119:50070" target="_blank" rel="external">http://192.168.1.119:50070</a><br><img src="http://img.blog.csdn.net/20160910184234348?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""></p>
</li>
<li><p>验证ResourceManager的Web服务能访问，浏览器访问<a href="http://192.168.1.119:8088" target="_blank" rel="external">http://192.168.1.119:8088</a><br><img src="http://img.blog.csdn.net/20160910184156566?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""></p>
</li>
<li><p>验证MapReduce JobHistory Server的Web服务能访问，浏览器访问<a href="http://192.168.1.119:19888" target="_blank" rel="external">http://192.168.1.119:19888</a><br><img src="http://img.blog.csdn.net/20160910184251708?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""></p>
</li>
</ul>
<h5 id="验证HDFS文件系统"><a href="#验证HDFS文件系统" class="headerlink" title="验证HDFS文件系统"></a>验证HDFS文件系统</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"># 查看根目录下的文件</div><div class="line">$ hdfs dfs -ls /Found 1 itemsdrwxrwx---   - yunyu supergroup          0 2016-09-10 03:15 /data</div><div class="line"></div><div class="line"># 创建temp目录</div><div class="line">$ hdfs dfs -mkdir /temp</div><div class="line"></div><div class="line"># 再次查看根目录下的文件，可以看到temp目录</div><div class="line">$ hdfs dfs -ls /Found 2 itemsdrwxrwx---   - yunyu supergroup          0 2016-09-10 03:15 /datadrwxr-xr-x   - yunyu supergroup          0 2016-09-10 03:45 /temp</div><div class="line"></div><div class="line"># 可以查看之前mapred-site.xml中配置的mapreduce作业执行中的目录和作业已完成的目录</div><div class="line">$ hdfs dfs -ls /data/history/Found 2 itemsdrwxrwx---   - yunyu supergroup          0 2016-09-10 03:15 /data/history/donedrwxrwxrwt   - yunyu supergroup          0 2016-09-10 03:15 /data/history/done_intermediate</div></pre></td></tr></table></figure>
<h3 id="需要注意的地方"><a href="#需要注意的地方" class="headerlink" title="需要注意的地方"></a>需要注意的地方</h3><p>网上一些Hadoop集群安装相关文章中，有一部分还是Hadoop老版本的配置，所以有些迷惑，像JobTracker，TaskTracker这些概念是Hadoop老版本才有的，新版本中使用ResourceManager和NodeManager替代了他们。后续的章节会详细的介绍Hadoop的相关原理以及新老版本的区别。</p>
<h3 id="使用HDFS默认端口号8020配置"><a href="#使用HDFS默认端口号8020配置" class="headerlink" title="使用HDFS默认端口号8020配置"></a>使用HDFS默认端口号8020配置</h3><p>修改core-site.xml配置文件如下（即把端口号去掉）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;  &lt;property&gt;    &lt;name&gt;fs.defaultFS&lt;/name&gt;    &lt;value&gt;hdfs://hadoop1&lt;/value&gt;  &lt;/property&gt;&lt;/configuration&gt;</div></pre></td></tr></table></figure>
<p>启动HDFS服务之后，分别在Hadoop1，2，3三台服务器上查看8020端口，发现HDFS默认使用的是8020端口</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"># 启动HDFS服务</div><div class="line">$ ./sbin/start-dfs.sh</div><div class="line"></div><div class="line"># Hadoop1中查看8020端口</div><div class="line">$ lsof -i:8020COMMAND  PID  USER   FD   TYPE DEVICE SIZE/OFF NODE NAMEjava    5112 yunyu  197u  IPv4  26041      0t0  TCP hadoop1:8020 (LISTEN)java    5112 yunyu  207u  IPv4  27568      0t0  TCP hadoop1:8020-&gt;hadoop2:34867 (ESTABLISHED)java    5112 yunyu  208u  IPv4  26096      0t0  TCP hadoop1:8020-&gt;hadoop3:59852 (ESTABLISHED)java    5112 yunyu  209u  IPv4  29792      0t0  TCP hadoop1:8020-&gt;hadoop1:45542 (ESTABLISHED)java    5383 yunyu  196u  IPv4  28826      0t0  TCP hadoop1:45542-&gt;hadoop1:8020 (ESTABLISHED)</div><div class="line"></div><div class="line"># Hadoop2中查看8020端口</div><div class="line">$ lsof -i:8020COMMAND  PID  USER   FD   TYPE DEVICE SIZE/OFF NODE NAMEjava    4609 yunyu  234u  IPv4  24013      0t0  TCP hadoop2:34867-&gt;hadoop1:8020 (ESTABLISHED)</div><div class="line"></div><div class="line"># Hadoop3中查看8020端口</div><div class="line">$ lsof -i:8020COMMAND  PID  USER   FD   TYPE DEVICE SIZE/OFF NODE NAMEjava    4452 yunyu  234u  IPv4  23413      0t0  TCP hadoop3:59852-&gt;hadoop1:8020 (ESTABLISHED)</div></pre></td></tr></table></figure>
<p>访问HDFS集群的方式</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"># 访问本机的HDFS集群</div><div class="line">hdfs dfs -ls /</div><div class="line"></div><div class="line"># 可以指定host和port访问远程的HDFS集群（这里使用hostname和port访问本地集群）</div><div class="line">hdfs dfs -ls hdfs://Hadoop1:8020/</div><div class="line"></div><div class="line"># 如果使用的默认端口号8020，也可以不指定端口号访问</div><div class="line">hdfs dfs -ls hdfs://Hadoop1/</div></pre></td></tr></table></figure>
<p>参考文章：</p>
<ul>
<li><a href="http://hadoop.apache.org/docs/r2.7.1/hadoop-project-dist/hadoop-common/ClusterSetup.html" target="_blank" rel="external">http://hadoop.apache.org/docs/r2.7.1/hadoop-project-dist/hadoop-common/ClusterSetup.html</a></li>
<li><a href="http://hadoop.apache.org/docs/r2.7.1/hadoop-project-dist/hadoop-common/core-default.xml" target="_blank" rel="external">http://hadoop.apache.org/docs/r2.7.1/hadoop-project-dist/hadoop-common/core-default.xml</a></li>
<li><a href="http://hadoop.apache.org/docs/r2.7.1/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml" target="_blank" rel="external">http://hadoop.apache.org/docs/r2.7.1/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml</a></li>
<li><a href="http://hadoop.apache.org/docs/r2.7.1/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml" target="_blank" rel="external">http://hadoop.apache.org/docs/r2.7.1/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml</a></li>
<li><a href="http://hadoop.apache.org/docs/r2.7.1/hadoop-yarn/hadoop-yarn-common/yarn-default.xml" target="_blank" rel="external">http://hadoop.apache.org/docs/r2.7.1/hadoop-yarn/hadoop-yarn-common/yarn-default.xml</a></li>
<li><a href="http://hadoop.apache.org/docs/r2.7.1/hadoop-project-dist/hadoop-hdfs/HDFSCommands.html#secondarynamenode" target="_blank" rel="external">http://hadoop.apache.org/docs/r2.7.1/hadoop-project-dist/hadoop-hdfs/HDFSCommands.html#secondarynamenode</a></li>
<li><a href="http://www.cnblogs.com/luogankun/p/4019303.html" target="_blank" rel="external">http://www.cnblogs.com/luogankun/p/4019303.html</a></li>
<li><a href="http://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-yarn/#_3.1_hadoop_0.23.0" target="_blank" rel="external">http://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-yarn/#_3.1_hadoop_0.23.0</a></li>
<li><a href="http://blog.chinaunix.net/uid-25266990-id-3900239.html" target="_blank" rel="external">http://blog.chinaunix.net/uid-25266990-id-3900239.html</a></li>
<li><a href="http://blog.csdn.net/jxnu_xiaobing/article/details/46931693" target="_blank" rel="external">http://blog.csdn.net/jxnu_xiaobing/article/details/46931693</a></li>
<li><a href="http://www.cnblogs.com/liuling/archive/2013/06/16/2013-6-16-01.html" target="_blank" rel="external">http://www.cnblogs.com/liuling/archive/2013/06/16/2013-6-16-01.html</a></li>
<li><a href="http://www.cnblogs.com/luogankun/p/4019303.html" target="_blank" rel="external">http://www.cnblogs.com/luogankun/p/4019303.html</a></li>
<li><a href="http://jacoxu.com/?p=961" target="_blank" rel="external">http://jacoxu.com/?p=961</a></li>
</ul>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/HDFS/">HDFS</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop原理架构体系/">Hadoop原理架构体系</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Docker/Docker实战（二十）Docker镜像的导入导出" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/09/04/Docker/Docker实战（二十）Docker镜像的导入导出/" class="article-date">
  	<time datetime="2016-09-04T03:30:19.000Z" itemprop="datePublished">2016-09-04</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/09/04/Docker/Docker实战（二十）Docker镜像的导入导出/">Docker实战（二十）Docker镜像的导入导出</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Docker镜像导入导出方式"><a href="#Docker镜像导入导出方式" class="headerlink" title="Docker镜像导入导出方式"></a>Docker镜像导入导出方式</h2><p>最近公司需要做Docker私有化部署，需要将本地安装好的Docker容器部署到客户的环境，这里遇到了一些问题客户的服务器不能连接外网，无法在线做Docker镜像的构建，所以需要只能通过导入导出镜像的方式来做。下面是我总结的Docker镜像导入导出方式。</p>
<p>Docker提供了两种方式的导入导出：</p>
<ul>
<li>load/save方式导入导出镜像<ul>
<li>docker save：来导出本地镜像库中指定的镜像存储成文件</li>
<li>docker load：来导入镜像存储文件到本地镜像库</li>
</ul>
</li>
<li>import/export方式导入导出容器<ul>
<li>docker export：来导出一个容器快照到本地文件</li>
<li>docker import：来导入一个容器快照文件到本地镜像库</li>
</ul>
</li>
<li>区别：容器快照文件将丢弃所有的历史记录和元数据信息（即仅保存容器当时的快照状态），而镜像存储文件将保存完整记录，体积也要大。此外，从容器快照文件导入时可以重新指定标签等元数据信息。我个人比较推荐用load/save方式，这样所有之前的镜像都会存在，只是比较占用空间。</li>
</ul>
<h3 id="Docker镜像save-load方式"><a href="#Docker镜像save-load方式" class="headerlink" title="Docker镜像save/load方式"></a>Docker镜像save/load方式</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">$ sudo docker imagesREPOSITORY                  TAG                 IMAGE ID            CREATED             VIRTUAL SIZEbirdben/zookeeper           v1                  20e4011b9286        2 minutes ago       1.658 GBubuntu                      latest              37b164bb431e        7 days ago          126.6 MBcentos                      7                   d83a55af4e75        5 weeks ago         196.7 MBcentos                      latest              d83a55af4e75        5 weeks ago         196.7 MBbirdben/jdk7                v1                  25c2f0e69206        8 months ago        583.4 MB</div><div class="line"></div><div class="line"># 导出birdben/zookeeper:v1镜像到zookeeper_image.tar文件</div><div class="line">$ sudo docker save birdben/zookeeper:v1 &gt; zookeeper_image.tar</div><div class="line"></div><div class="line"># 删除之前的birdben/zookeeper:v1镜像</div><div class="line">$ sudo docker rmi &quot;birdben/zookeeper:v1&quot;</div><div class="line"></div><div class="line"># 导入zookeeper_image.tar镜像文件</div><div class="line">$ sudo docker load &lt; zookeeper_image.tar</div><div class="line"></div><div class="line"># 再次查看所有的镜像，可以看到birdben/zookeeper:v1又回来了</div><div class="line"># 注意：这里import回来的ImageID也和原来是一样的</div><div class="line">$ sudo docker imagesREPOSITORY                  TAG                 IMAGE ID            CREATED             VIRTUAL SIZEbirdben/zookeeper           v1                  20e4011b9286        6 minutes ago       1.658 GBubuntu                      latest              37b164bb431e        7 days ago          126.6 MBcentos                      7                   d83a55af4e75        5 weeks ago         196.7 MBcentos                      latest              d83a55af4e75        5 weeks ago         196.7 MBbirdben/jdk7                v1                  25c2f0e69206        8 months ago        583.4 MB</div><div class="line"></div><div class="line"># 这时候在查看birdben/zookeeper:v1镜像的tree结构，发现之前所有的镜像历史都在</div><div class="line">$ sudo docker images --tree</div><div class="line">├─3690474eb5b4 Virtual Size: 0 B│ └─b200b2d33d98 Virtual Size: 196.7 MB│   └─3fbd5972aaac Virtual Size: 196.7 MB│     └─d83a55af4e75 Virtual Size: 196.7 MB Tags: centos:7, centos:latest│       └─1df8e9ff4de7 Virtual Size: 196.7 MB│         └─b37af9ce019a Virtual Size: 196.7 MB│           └─7858b8d134c6 Virtual Size: 403.3 MB│             └─c872974343d2 Virtual Size: 403.3 MB│               └─d4c0e59dc712 Virtual Size: 403.3 MB│                 └─30c3076be68f Virtual Size: 556.8 MB│                   └─0e66c066e1de Virtual Size: 571 MB│                     └─69f8ec0b7932 Virtual Size: 889.1 MB│                       └─7cfcd6d4c6e7 Virtual Size: 911.4 MB│                         └─c2bc26e11781 Virtual Size: 911.4 MB│                           └─31d728531f9a Virtual Size: 911.4 MB│                             └─6434457046ec Virtual Size: 911.4 MB│                               └─651290e3ddef Virtual Size: 911.4 MB│                                 └─d99d028fca92 Virtual Size: 911.6 MB│                                   └─5d4d89731a7d Virtual Size: 911.6 MB│                                     └─a530df3b220c Virtual Size: 925.6 MB│                                       └─39381e27bf53 Virtual Size: 1.232 GB│                                         └─cda80cbe8e7f Virtual Size: 1.276 GB│                                           └─287a8cf1090c Virtual Size: 1.289 GB│                                             └─d5672fcec9a4 Virtual Size: 1.289 GB│                                               └─e63cb61422e1 Virtual Size: 1.289 GB│                                                 └─aa8f6ecc78ca Virtual Size: 1.303 GB│                                                   └─b44f1969877f Virtual Size: 1.303 GB│                                                     └─d17184db904f Virtual Size: 1.303 GB│                                                       └─7df628e7fd36 Virtual Size: 1.303 GB│                                                         └─dfe01b409095 Virtual Size: 1.303 GB│                                                           └─238718f45aa6 Virtual Size: 1.303 GB│                                                             └─a678149d4c34 Virtual Size: 1.303 GB│                                                               └─d3f7fb8e3bc2 Virtual Size: 1.658 GB│                                                                 └─ff152402a43c Virtual Size: 1.658 GB│                                                                   └─fdf82aa49b89 Virtual Size: 1.658 GB│                                                                     └─0dbfccd66315 Virtual Size: 1.658 GB│                                                                       └─4cae49ef2ecb Virtual Size: 1.658 GB Tags: birdben/zookeeper:v1</div></pre></td></tr></table></figure>
<h3 id="Docker镜像import-export方式"><a href="#Docker镜像import-export方式" class="headerlink" title="Docker镜像import/export方式"></a>Docker镜像import/export方式</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">$ sudo docker images</div><div class="line">REPOSITORY                  TAG                 IMAGE ID            CREATED             VIRTUAL SIZEbirdben/zookeeper           v1       	        20e4011b9286        11 seconds ago      1.658 GBubuntu                      latest              37b164bb431e        7 days ago          126.6 MBcentos                      7                   d83a55af4e75        5 weeks ago         196.7 MBcentos                      latest              d83a55af4e75        5 weeks ago         196.7 MBbirdben/jdk7                v1                  25c2f0e69206        8 months ago        583.4 MB</div><div class="line"></div><div class="line">$ sudo docker ps -aCONTAINER ID        IMAGE                 COMMAND             CREATED             STATUS              PORTS                                            NAMESf99771de17b0        20e4011b9286:latest   &quot;/bin/bash&quot;         6 seconds ago       Up 5 seconds        0.0.0.0:3306-&gt;3306/tcp, 0.0.0.0:8080-&gt;8080/tcp   birdben/zookeeper:v1</div><div class="line"></div><div class="line"># 导出容器ID为f99771de17b0的Docker容器</div><div class="line">$ sudo docker export f99771de17b0 &gt; container.tar.gz</div><div class="line"></div><div class="line"># 删除之前的镜像birdben/zookeeper:v1</div><div class="line">$ sudo docker rmi &quot;birdben/zookeeper:v1&quot;</div><div class="line"></div><div class="line"># 导入容器文件container.tar.gz</div><div class="line">$ cat container.tar.gz | sudo docker import - birdben/zookeeper:v1</div><div class="line"></div><div class="line"># 注意：这里import回来的ImageID也和原来不一样了</div><div class="line">$ sudo docker imagesREPOSITORY                  TAG                 IMAGE ID            CREATED             VIRTUAL SIZEbirdben/zookeeper           v1                  e80c1046dc12        9 minutes ago       1.119 GBubuntu                      latest              37b164bb431e        7 days ago          126.6 MBcentos                      7                   d83a55af4e75        5 weeks ago         196.7 MBcentos                      latest              d83a55af4e75        5 weeks ago         196.7 MBbirdben/jdk7                v1                  25c2f0e69206        8 months ago        583.4 MB</div><div class="line"></div><div class="line"># 这时候在查看birdben/zookeeper:v1镜像的tree结构，发现只有最有的镜像，没有以前的历史镜像</div><div class="line">$ sudo docker images --treeWarning: &apos;--tree&apos; is deprecated, it will be removed soon. See usage.├─e80c1046dc12 Virtual Size: 1.119 GB Tags: birdben/zookeeper:v1├─f1b49dd0c243 Virtual Size: 126.6 MB│ └─008ecf8686ec Virtual Size: 126.6 MB│   └─fd74137ff5ae Virtual Size: 126.6 MB│     └─35371c8124e2 Virtual Size: 126.6 MB│       └─99dc4d8f603d Virtual Size: 126.6 MB│         └─37b164bb431e Virtual Size: 126.6 MB Tags: ubuntu:latest</div></pre></td></tr></table></figure>
<p>参考文章：</p>
<ul>
<li><a href="https://segmentfault.com/a/1190000000586840" target="_blank" rel="external">https://segmentfault.com/a/1190000000586840</a></li>
<li><a href="http://www.sxt.cn/u/756/blog/5339" target="_blank" rel="external">http://www.sxt.cn/u/756/blog/5339</a></li>
</ul>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Dockerfile/">Dockerfile</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Docker命令/">Docker命令</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Docker/">Docker</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Flume/Flume学习（八）Flume解析自定义日志" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/09/03/Flume/Flume学习（八）Flume解析自定义日志/" class="article-date">
  	<time datetime="2016-09-03T08:11:01.000Z" itemprop="datePublished">2016-09-03</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/09/03/Flume/Flume学习（八）Flume解析自定义日志/">Flume学习（八）Flume解析自定义日志</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="环境简介"><a href="#环境简介" class="headerlink" title="环境简介"></a>环境简介</h3><ul>
<li>JDK1.7.0_79</li>
<li>Flume1.6.0</li>
<li>Elasticsearch2.0.0</li>
</ul>
<p>这里是基于上一篇《Flume学习（七）Flume整合Elasticsearch2.x》解析自定义的日志格式</p>
<h3 id="解析的日志格式"><a href="#解析的日志格式" class="headerlink" title="解析的日志格式"></a>解析的日志格式</h3><p>这里由于篇幅原因，我简单列举了两条典型的日志格式</p>
<h4 id="日志文件格式"><a href="#日志文件格式" class="headerlink" title="日志文件格式"></a>日志文件格式</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[&#123;&quot;name&quot;:&quot;rp.api.call&quot;,&quot;request&quot;:&quot;GET /api/test/settings&quot;,&quot;status&quot;:&quot;succeeded&quot;,&quot;uid&quot;:889,&quot;did&quot;:13,&quot;duid&quot;:&quot;app001&quot;,&quot;ua&quot;:&quot;Dalvik/2.1.0 (Linux; U; Android 6.0.1; MI NOTE LTE MIUI/6.5.12)&quot;,&quot;device_id&quot;:&quot;65768768252343&quot;,&quot;ip&quot;:&quot;10.190.1.67&quot;,&quot;server_timestamp&quot;:1463713488740&#125;]</div><div class="line">[&#123;&quot;name&quot;:&quot;rp.api.call&quot;,&quot;request&quot;:&quot;GET /api/test/search&quot;,&quot;errorStatus&quot;:200,&quot;errorCode&quot;:&quot;0000&quot;,&quot;errorMsg&quot;:&quot;操作成功&quot;,&quot;status&quot;:&quot;failed&quot;,&quot;uid&quot;:889,&quot;did&quot;:13,&quot;duid&quot;:&quot;app002&quot;,&quot;ua&quot;:&quot;Dalvik/2.1.0 (Linux; U; Android 6.0.1; MI NOTE LTE MIUI/6.5.12)&quot;,&quot;device_id&quot;:&quot;4543657687878989&quot;,&quot;ip&quot;:&quot;10.190.1.66&quot;,&quot;server_timestamp&quot;:1463650301701&#125;]</div></pre></td></tr></table></figure>
<p>上一篇已经讲过了Flume解析日志格式主要使用interceptors，interceptors本身又支持多种type，这里我们主要介绍regex_extractor，即正则表达式匹配方式。下面的正则表达式可以匹配上面的两种格式的日志，上面两种日志格式的主要区别就是errorStatus，errorCode，errorMsg这三个字段有可能不存在，当没有报错的时候，这三个字段是不需要的。</p>
<h4 id="日志解析正则表达式"><a href="#日志解析正则表达式" class="headerlink" title="日志解析正则表达式"></a>日志解析正则表达式</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&quot;name&quot;:(.*),&quot;request&quot;:(.*),(&quot;errorStatus&quot;:(.*),)?(&quot;errorCode&quot;:(.*),)?(&quot;errorMsg&quot;:(.*),)?&quot;status&quot;:(.*),&quot;uid&quot;:(.*),&quot;did&quot;:(.*),&quot;duid&quot;:(.*),&quot;ua&quot;:(.*),&quot;device_id&quot;:(.*),&quot;ip&quot;:(.*),&quot;server_timestamp&quot;:([0-9]*)</div></pre></td></tr></table></figure>
<p>但是在Flume的interceptors的regex表达式中配置上面的正则表达式会报错，我自己分析的原因是Flume的interceptor.serializers需要指定正则表达式拆分后的对应的字段和值，没有办法做到根据正则表达式动态处理。（这里我的分析可能不一定对，如果有疑问我们可以私下交流）</p>
<p>下面是我的解决办法，我根据上面两种日志格式写了两个interceptor，分别是es_interceptor和es_error_interceptor，每个interceptor对应不同的正则表达式，分别用来处理上面两种不同的日志格式。这样interceptor.serializers就能根据对应的正则表达式格式解析出来日志中对应的字段和值，再插入到ES索引中。</p>
<h4 id="flume-conf配置文件"><a href="#flume-conf配置文件" class="headerlink" title="flume.conf配置文件"></a>flume.conf配置文件</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"># 原始的正则表达式：&quot;name&quot;:(.*),&quot;request&quot;:(.*),(&quot;errorStatus&quot;:(.*),)?(&quot;errorCode&quot;:(.*),)?(&quot;errorMsg&quot;:(.*),)?&quot;status&quot;:(.*),&quot;uid&quot;:(.*),&quot;did&quot;:(.*),&quot;duid&quot;:(.*),&quot;ua&quot;:(.*),&quot;device_id&quot;:(.*),&quot;ip&quot;:(.*),&quot;server_timestamp&quot;:([0-9]*)</div><div class="line">agentX.sources.flume-avro-sink.interceptors = es_interceptor es_error_interceptor</div><div class="line"></div><div class="line">agentX.sources.flume-avro-sink.interceptors.es_interceptor.type = regex_extractor</div><div class="line">agentX.sources.flume-avro-sink.interceptors.es_interceptor.regex = &quot;name&quot;:(.*),&quot;request&quot;:(.*),&quot;status&quot;:(.*),&quot;uid&quot;:(.*),&quot;did&quot;:(.*),&quot;duid&quot;:(.*),&quot;ua&quot;:(.*),&quot;device_id&quot;:(.*),&quot;ip&quot;:(.*),&quot;server_timestamp&quot;:([0-9]*)</div><div class="line"></div><div class="line">agentX.sources.flume-avro-sink.interceptors.es_interceptor.serializers = s1 s2 s3 s4 s5 s6 s7 s8 s9 s10</div><div class="line">agentX.sources.flume-avro-sink.interceptors.es_interceptor.serializers.s1.name = name</div><div class="line">agentX.sources.flume-avro-sink.interceptors.es_interceptor.serializers.s2.name = request</div><div class="line">agentX.sources.flume-avro-sink.interceptors.es_interceptor.serializers.s3.name = status</div><div class="line">agentX.sources.flume-avro-sink.interceptors.es_interceptor.serializers.s4.name = uid</div><div class="line">agentX.sources.flume-avro-sink.interceptors.es_interceptor.serializers.s5.name = did</div><div class="line">agentX.sources.flume-avro-sink.interceptors.es_interceptor.serializers.s6.name = duid</div><div class="line">agentX.sources.flume-avro-sink.interceptors.es_interceptor.serializers.s7.name = ua</div><div class="line">agentX.sources.flume-avro-sink.interceptors.es_interceptor.serializers.s8.name = device_id</div><div class="line">agentX.sources.flume-avro-sink.interceptors.es_interceptor.serializers.s9.name = ip</div><div class="line">agentX.sources.flume-avro-sink.interceptors.es_interceptor.serializers.s10.name = server_timestamp</div><div class="line"></div><div class="line">agentX.sources.flume-avro-sink.interceptors.es_error_interceptor.type = regex_extractor</div><div class="line">agentX.sources.flume-avro-sink.interceptors.es_error_interceptor.regex = &quot;name&quot;:(.*),&quot;request&quot;:(.*),&quot;errorStatus&quot;:(.*),&quot;errorCode&quot;:(.*),&quot;errorMsg&quot;:(.*),&quot;status&quot;:(.*),&quot;uid&quot;:(.*),&quot;did&quot;:(.*),&quot;duid&quot;:(.*),&quot;ua&quot;:(.*),&quot;device_id&quot;:(.*),&quot;ip&quot;:(.*),&quot;server_timestamp&quot;:([0-9]*)</div><div class="line"></div><div class="line">agentX.sources.flume-avro-sink.interceptors.es_error_interceptor.serializers = s1 s2 s3 s4 s5 s6 s7 s8 s9 s10 s11 s12 s13</div><div class="line">agentX.sources.flume-avro-sink.interceptors.es_error_interceptor.serializers.s1.name = name</div><div class="line">agentX.sources.flume-avro-sink.interceptors.es_error_interceptor.serializers.s2.name = request</div><div class="line">agentX.sources.flume-avro-sink.interceptors.es_error_interceptor.serializers.s3.name = errorStatus</div><div class="line">agentX.sources.flume-avro-sink.interceptors.es_error_interceptor.serializers.s4.name = errorCode</div><div class="line">agentX.sources.flume-avro-sink.interceptors.es_error_interceptor.serializers.s5.name = errorMsg</div><div class="line">agentX.sources.flume-avro-sink.interceptors.es_error_interceptor.serializers.s6.name = status</div><div class="line">agentX.sources.flume-avro-sink.interceptors.es_error_interceptor.serializers.s7.name = uid</div><div class="line">agentX.sources.flume-avro-sink.interceptors.es_error_interceptor.serializers.s8.name = did</div><div class="line">agentX.sources.flume-avro-sink.interceptors.es_error_interceptor.serializers.s9.name = duid</div><div class="line">agentX.sources.flume-avro-sink.interceptors.es_error_interceptor.serializers.s10.name = ua</div><div class="line">agentX.sources.flume-avro-sink.interceptors.es_error_interceptor.serializers.s11.name = device_id</div><div class="line">agentX.sources.flume-avro-sink.interceptors.es_error_interceptor.serializers.s12.name = ip</div><div class="line">agentX.sources.flume-avro-sink.interceptors.es_error_interceptor.serializers.s13.name = server_timestamp</div></pre></td></tr></table></figure>
<h4 id="ES的mapping如下"><a href="#ES的mapping如下" class="headerlink" title="ES的mapping如下"></a>ES的mapping如下</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">  &quot;mappings&quot;: &#123;</div><div class="line">    &quot;hb&quot;: &#123;</div><div class="line">      &quot;properties&quot;: &#123;</div><div class="line">        &quot;@fields&quot;: &#123;</div><div class="line">          &quot;properties&quot;: &#123;</div><div class="line">            &quot;uid&quot;: &#123;</div><div class="line">              &quot;type&quot;: &quot;string&quot;</div><div class="line">            &#125;,</div><div class="line">            &quot;duid&quot;: &#123;</div><div class="line">              &quot;type&quot;: &quot;string&quot;</div><div class="line">            &#125;,</div><div class="line">            &quot;status&quot;: &#123;</div><div class="line">              &quot;type&quot;: &quot;string&quot;</div><div class="line">            &#125;,</div><div class="line">            &quot;request&quot;: &#123;</div><div class="line">              &quot;type&quot;: &quot;string&quot;</div><div class="line">            &#125;,</div><div class="line">            &quot;name&quot;: &#123;</div><div class="line">              &quot;type&quot;: &quot;string&quot;</div><div class="line">            &#125;,</div><div class="line">            &quot;errorCode&quot;: &#123;</div><div class="line">              &quot;type&quot;: &quot;string&quot;</div><div class="line">            &#125;,</div><div class="line">            &quot;ua&quot;: &#123;</div><div class="line">              &quot;type&quot;: &quot;string&quot;</div><div class="line">            &#125;,</div><div class="line">            &quot;did&quot;: &#123;</div><div class="line">              &quot;type&quot;: &quot;string&quot;</div><div class="line">            &#125;,</div><div class="line">            &quot;errorMsg&quot;: &#123;</div><div class="line">              &quot;type&quot;: &quot;string&quot;</div><div class="line">            &#125;,</div><div class="line">            &quot;device_id&quot;: &#123;</div><div class="line">              &quot;type&quot;: &quot;string&quot;</div><div class="line">            &#125;,</div><div class="line">            &quot;server_timestamp&quot;: &#123;</div><div class="line">              &quot;type&quot;: &quot;string&quot;</div><div class="line">            &#125;,</div><div class="line">            &quot;ip&quot;: &#123;</div><div class="line">              &quot;type&quot;: &quot;string&quot;</div><div class="line">            &#125;,</div><div class="line">            &quot;errorStatus&quot;: &#123;</div><div class="line">              &quot;type&quot;: &quot;string&quot;</div><div class="line">            &#125;</div><div class="line">          &#125;</div><div class="line">        &#125;,</div><div class="line">        &quot;@message&quot;: &#123;</div><div class="line">          &quot;type&quot;: &quot;string&quot;</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="ES索引中的日志信息"><a href="#ES索引中的日志信息" class="headerlink" title="ES索引中的日志信息"></a>ES索引中的日志信息</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">	&quot;_index&quot;: &quot;test_log_index-2016-09-03&quot;,</div><div class="line">	&quot;_type&quot;: &quot;test&quot;,</div><div class="line">	&quot;_id&quot;: &quot;AVbvrWIPe8IcP1cQoXS2&quot;,</div><div class="line">	&quot;_version&quot;: 1,</div><div class="line">	&quot;_score&quot;: 1,</div><div class="line">	&quot;_source&quot;: &#123;</div><div class="line">		&quot;@message&quot;: &quot;[</div><div class="line">			&#123;&quot;name&quot;:&quot;1&quot;,&quot;request&quot;:&quot;GET /api/test/settings&quot;,&quot;status&quot;:&quot;succeeded&quot;,&quot;uid&quot;:889,&quot;did&quot;:13,&quot;duid&quot;:&quot;app001&quot;,&quot;ua&quot;:&quot;Dalvik/2.1.0 (Linux; U; Android 6.0.1; MI NOTE LTE MIUI/6.5.12)&quot;,&quot;device_id&quot;:,&quot;ip&quot;:&quot;10.190.1.67&quot;,&quot;server_timestamp&quot;:1463713488740&#125;</div><div class="line">		]&quot;,</div><div class="line">		&quot;@fields&quot;: &#123;</div><div class="line">			&quot;uid&quot;: &quot;889&quot;,</div><div class="line">			&quot;duid&quot;: &quot;&quot;app001&quot;&quot;,</div><div class="line">			&quot;status&quot;: &quot;&quot;succeeded&quot;&quot;,</div><div class="line">			&quot;name&quot;: &quot;&quot;1&quot;&quot;,</div><div class="line">			&quot;request&quot;: &quot;&quot;GET /api/test/settings&quot;&quot;,</div><div class="line">			&quot;did&quot;: &quot;13&quot;,</div><div class="line">			&quot;ua&quot;: &quot;&quot;Dalvik/2.1.0 (Linux; U; Android 6.0.1; MI NOTE LTE MIUI/6.5.12)&quot;&quot;,</div><div class="line">			&quot;device_id&quot;: &quot;&quot;,</div><div class="line">			&quot;server_timestamp&quot;: &quot;1463713488740&quot;,</div><div class="line">			&quot;ip&quot;: &quot;&quot;10.190.1.67&quot;&quot;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">&#123;</div><div class="line">	&quot;_index&quot;: &quot;test_log_index-2016-09-03&quot;,</div><div class="line">	&quot;_type&quot;: &quot;test&quot;,</div><div class="line">	&quot;_id&quot;: &quot;AVbvrWIPe8IcP1cQoXS3&quot;,</div><div class="line">	&quot;_version&quot;: 1,</div><div class="line">	&quot;_score&quot;: 1,</div><div class="line">	&quot;_source&quot;: &#123;</div><div class="line">		&quot;@message&quot;: &quot;[</div><div class="line">			&#123;&quot;name&quot;:&quot;rp.api.call&quot;,&quot;request&quot;:&quot;GET /api/test/search&quot;,&quot;errorStatus&quot;:200,&quot;errorCode&quot;:&quot;0000&quot;,&quot;errorMsg&quot;:&quot;操作成功&quot;,&quot;status&quot;:&quot;failed&quot;,&quot;uid&quot;:889,&quot;did&quot;:13,&quot;duid&quot;:&quot;app001&quot;,&quot;ua&quot;:&quot;Dalvik/2.1.0 (Linux; U; Android 6.0.1; MI NOTE LTE MIUI/6.5.12)&quot;,&quot;device_id&quot;:&quot;4543657687878989&quot;,&quot;ip&quot;:&quot;10.190.1.66&quot;,&quot;server_timestamp&quot;:1463650301701&#125;</div><div class="line">		]&quot;,</div><div class="line">		&quot;@fields&quot;: &#123;</div><div class="line">			&quot;uid&quot;: &quot;889&quot;,</div><div class="line">			&quot;status&quot;: &quot;&quot;failed&quot;&quot;,</div><div class="line">			&quot;did&quot;: &quot;13&quot;,</div><div class="line">			&quot;device_id&quot;: &quot;&quot;4543657687878989&quot;&quot;,</div><div class="line">			&quot;errorMsg&quot;: &quot;&quot;操作成功&quot;&quot;,</div><div class="line">			&quot;errorStatus&quot;: &quot;200&quot;,</div><div class="line">			&quot;ip&quot;: &quot;&quot;10.190.1.66&quot;&quot;,</div><div class="line">			&quot;duid&quot;: &quot;&quot;app001&quot;&quot;,</div><div class="line">			&quot;request&quot;: &quot;&quot;GET /api/test/search&quot;&quot;,</div><div class="line">			&quot;name&quot;: &quot;&quot;rp.api.call&quot;&quot;,</div><div class="line">			&quot;errorCode&quot;: &quot;&quot;0000&quot;&quot;,</div><div class="line">			&quot;ua&quot;: &quot;&quot;Dalvik/2.1.0 (Linux; U; Android 6.0.1; MI NOTE LTE MIUI/6.5.12)&quot;&quot;,</div><div class="line">			&quot;server_timestamp&quot;: &quot;1463650301701&quot;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>个人觉得这样的做法并不理想，因为日志格式肯定会多种多样，如果每种日志格式都需要不同的正则表达式来处理，显得太过笨重和冗余，因为刚接触Flume暂时没有发现有更好的做法，日后发现有更好的处理方式会重新更新上来。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Flume/">Flume</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Log/">Log</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Docker/Docker实战（十九）Docker环境安装问题" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/09/03/Docker/Docker实战（十九）Docker环境安装问题/" class="article-date">
  	<time datetime="2016-09-03T02:50:49.000Z" itemprop="datePublished">2016-09-03</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/09/03/Docker/Docker实战（十九）Docker环境安装问题/">Docker实战（十九）Docker环境安装问题</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="环境描述"><a href="#环境描述" class="headerlink" title="环境描述"></a>环境描述</h2><h3 id="本地环境"><a href="#本地环境" class="headerlink" title="本地环境"></a>本地环境</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">Ubuntu14.04</div><div class="line"></div><div class="line">Client version: 1.6.2Client API version: 1.18Go version (client): go1.2.1Git commit (client): 7c8fca2OS/Arch (client): linux/amd64</div><div class="line">Server version: 1.6.2Server API version: 1.18Go version (server): go1.2.1Git commit (server): 7c8fca2OS/Arch (server): linux/amd64</div></pre></td></tr></table></figure>
<h3 id="10-10-1-15测试环境"><a href="#10-10-1-15测试环境" class="headerlink" title="10.10.1.15测试环境"></a>10.10.1.15测试环境</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">Ubuntu15.04</div><div class="line"></div><div class="line">Client:</div><div class="line"> Version:      1.10.3</div><div class="line"> API version:  1.21</div><div class="line"> Go version:   go1.5.3</div><div class="line"> Git commit:   20f81dd</div><div class="line"> Built:        Thu Mar 10 21:49:11 2016</div><div class="line"> OS/Arch:      linux/amd64</div><div class="line"></div><div class="line">Server:</div><div class="line"> Version:      1.9.1</div><div class="line"> API version:  1.21</div><div class="line"> Go version:   go1.4.2</div><div class="line"> Git commit:   a34a1d5</div><div class="line"> Built:        Fri Nov 20 13:16:54 UTC 2015</div><div class="line"> OS/Arch:      linux/amd64</div></pre></td></tr></table></figure>
<h2 id="Docker的安装和使用"><a href="#Docker的安装和使用" class="headerlink" title="Docker的安装和使用"></a>Docker的安装和使用</h2><h3 id="本地环境安装"><a href="#本地环境安装" class="headerlink" title="本地环境安装"></a>本地环境安装</h3><p>直接使用apt方式安装</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ apt-get update</div><div class="line">$ apt-get install docker</div><div class="line">$ apt-get install docker.io</div></pre></td></tr></table></figure>
<h3 id="10-10-1-15测试环境-1"><a href="#10-10-1-15测试环境-1" class="headerlink" title="10.10.1.15测试环境"></a>10.10.1.15测试环境</h3><p>使用apt方式安装报错E: Sub-process /usr/bin/dpkg returned an error code (1)，之后尝试了一些解决方式，但都没有解决成功，最后决定将docker卸载掉重新按照官网的步骤安装成功</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line"># 安装前先查看Linux内核版本，内核版本需要高于3.10</div><div class="line">$ uname -r</div><div class="line">3.19.0-68-generic</div><div class="line"></div><div class="line"># Update your apt sources</div><div class="line">$ sudo apt-get update</div><div class="line">$ sudo apt-get install apt-transport-https ca-certificates</div><div class="line">$ sudo apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D</div><div class="line"></div><div class="line"># 创建并保存docker.list更新源文件</div><div class="line">$ /etc/apt/sources.list.d/docker.list</div><div class="line"></div><div class="line"># 根据自己的系统版本选择不同的数据源</div><div class="line">- On Ubuntu Precise 12.04 (LTS)</div><div class="line">deb https://apt.dockerproject.org/repo ubuntu-precise main</div><div class="line">- On Ubuntu Trusty 14.04 (LTS)</div><div class="line">deb https://apt.dockerproject.org/repo ubuntu-trusty main</div><div class="line">- Ubuntu Wily 15.10</div><div class="line">deb https://apt.dockerproject.org/repo ubuntu-wily main</div><div class="line">- Ubuntu Xenial 16.04 (LTS)</div><div class="line">deb https://apt.dockerproject.org/repo ubuntu-xenial main</div><div class="line"></div><div class="line"># 再次更新源</div><div class="line">$ sudo apt-get update</div><div class="line"># 删除旧的资源文件</div><div class="line">$ sudo apt-get purge lxc-docker</div><div class="line"># 验证apt的更新源是从正确的仓库获取</div><div class="line">$ apt-cache policy docker-engine</div><div class="line"></div><div class="line"># 安装Ubuntu必备的安装包linux-image-extra-*</div><div class="line">$ sudo apt-get update</div><div class="line">$ sudo apt-get install linux-image-extra-$(uname -r) linux-image-extra-virtual</div><div class="line"></div><div class="line"># 安装Docker</div><div class="line">$ sudo apt-get update</div><div class="line">$ sudo apt-get install docker-engine</div><div class="line"># 启动Docker服务</div><div class="line">$ sudo service docker start</div><div class="line"># 检查Docker版本</div><div class="line">$ sudo docker version</div></pre></td></tr></table></figure>
<h3 id="遇到的问题和解决方法"><a href="#遇到的问题和解决方法" class="headerlink" title="遇到的问题和解决方法"></a>遇到的问题和解决方法</h3><h4 id="Depends-libdevmapper1-02-1-gt-2-1-02-99-but-2-1-02-90-2ubuntu1-is-to-be-installed"><a href="#Depends-libdevmapper1-02-1-gt-2-1-02-99-but-2-1-02-90-2ubuntu1-is-to-be-installed" class="headerlink" title="Depends: libdevmapper1.02.1 (&gt;= 2:1.02.99) but 2:1.02.90-2ubuntu1 is to be installed"></a>Depends: libdevmapper1.02.1 (&gt;= 2:1.02.99) but 2:1.02.90-2ubuntu1 is to be installed</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">$ sudo apt install docker-engine</div><div class="line">Reading package lists... Done</div><div class="line">Building dependency tree</div><div class="line">Reading state information... Done</div><div class="line">Some packages could not be installed. This may mean that you have</div><div class="line">requested an impossible situation or if you are using the unstable</div><div class="line">distribution that some required packages have not yet been created</div><div class="line">or been moved out of Incoming.</div><div class="line">The following information may help to resolve the situation:</div><div class="line"></div><div class="line">The following packages have unmet dependencies:</div><div class="line"> docker-engine : Depends: libdevmapper1.02.1 (&gt;= 2:1.02.99) but 2:1.02.90-2ubuntu1 is to be installed</div><div class="line">E: Unable to correct problems, you have held broken packages.</div><div class="line"></div><div class="line"># 遇到这个问题是因为更新源不正确的原因，因为我们用的Ubuntu15.04版本，所以上面官网提供的数据源中并不包含我们的版本</div><div class="line">$ sudo lsb_release -a</div><div class="line">No LSB modules are available.</div><div class="line">Distributor ID:	Ubuntu</div><div class="line">Description:	Ubuntu 15.04</div><div class="line">Release:	15.04</div><div class="line">Codename:	vivid</div><div class="line"></div><div class="line"># 这里在github上找到了解决方法，依次执行下面的命令可以修复正确的数据源</div><div class="line">$ sudo sed -i &apos;/wily/d&apos; /etc/apt/sources.list.d/docker.list</div><div class="line">$ sudo sed -i &apos;/trusty/d&apos; /etc/apt/sources.list.d/docker.list</div><div class="line">$ sudo sed -i &apos;/precise/d&apos; /etc/apt/sources.list.d/docker.list</div><div class="line">$ sudo apt-get update</div><div class="line">$ sudo apt-get install docker-engine</div></pre></td></tr></table></figure>
<h4 id="Error-response-from-daemon-client-is-newer-than-server-client-API-version-1-22-server-API-version-1-21"><a href="#Error-response-from-daemon-client-is-newer-than-server-client-API-version-1-22-server-API-version-1-21" class="headerlink" title="Error response from daemon: client is newer than server (client API version: 1.22, server API version: 1.21)"></a>Error response from daemon: client is newer than server (client API version: 1.22, server API version: 1.21)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">$ docker version</div><div class="line">Client:</div><div class="line"> Version:      1.10.3</div><div class="line"> API version:  1.22</div><div class="line"> Go version:   go1.5.3</div><div class="line"> Git commit:   20f81dd</div><div class="line"> Built:        Thu Mar 10 21:49:11 2016</div><div class="line"> OS/Arch:      linux/amd64</div><div class="line">Error response from daemon: client is newer than server (client API version: 1.22, server API version: 1.21)</div><div class="line"></div><div class="line"># 遇到这个问题的原因是Docker API version的版本号不一致导致的，这个我们需要添加一个环境变量来指定Docker API version的版本号</div><div class="line"></div><div class="line"># 这里建议更改/etc/profile文件，而不是临时更改环境变量，修改/etc/profile之后需要source /etc/profile，如果要在sudo也生效，需要切换到root账号也source /etc/profile</div><div class="line">$ export DOCKER_API_VERSION=1.21</div></pre></td></tr></table></figure>
<p>参考文章：</p>
<ul>
<li><a href="http://docs.docker.com.s3-website-us-east-1.amazonaws.com/engine/installation/linux/ubuntulinux/" target="_blank" rel="external">http://docs.docker.com.s3-website-us-east-1.amazonaws.com/engine/installation/linux/ubuntulinux/</a></li>
<li><a href="http://askubuntu.com/questions/686698/docker-installation-error-libdevmapper1-02-1-21-02-99" target="_blank" rel="external">http://askubuntu.com/questions/686698/docker-installation-error-libdevmapper1-02-1-21-02-99</a></li>
<li><a href="https://github.com/docker/machine/issues/2147">https://github.com/docker/machine/issues/2147</a></li>
</ul>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Dockerfile/">Dockerfile</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Docker命令/">Docker命令</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Docker/">Docker</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Zookeeper/Zookeeper学习（二）Zookeeper集群环境搭建" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/09/02/Zookeeper/Zookeeper学习（二）Zookeeper集群环境搭建/" class="article-date">
  	<time datetime="2016-09-02T15:54:31.000Z" itemprop="datePublished">2016-09-02</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/09/02/Zookeeper/Zookeeper学习（二）Zookeeper集群环境搭建/">Zookeeper学习（二）Zookeeper集群环境搭建</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="ZooKeeper-Cluster模式"><a href="#ZooKeeper-Cluster模式" class="headerlink" title="ZooKeeper Cluster模式"></a>ZooKeeper Cluster模式</h3><h4 id="etc-hosts文件配置"><a href="#etc-hosts文件配置" class="headerlink" title="/etc/hosts文件配置"></a>/etc/hosts文件配置</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">172.17.0.51     zoo1</div><div class="line">172.17.0.52     zoo2</div><div class="line">172.17.0.53     zoo3</div></pre></td></tr></table></figure>
<h4 id="var-zookeeper-myid文件配置"><a href="#var-zookeeper-myid文件配置" class="headerlink" title="/var/zookeeper/myid文件配置"></a>/var/zookeeper/myid文件配置</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"># zoo1的myid配置文件</div><div class="line">1</div><div class="line"></div><div class="line"># zoo2的myid配置文件</div><div class="line">2</div><div class="line"></div><div class="line"># zoo3的myid配置文件</div><div class="line">3</div></pre></td></tr></table></figure>
<h4 id="Zookeeper配置文件"><a href="#Zookeeper配置文件" class="headerlink" title="Zookeeper配置文件"></a>Zookeeper配置文件</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"># the basic time unit in milliseconds used by ZooKeeper. It is used to do heartbeats and the minimum session timeout will be twice the tickTime.</div><div class="line"># tickTime 这个时间是作为 Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个tickTime时间就会发送一个心跳。</div><div class="line">tickTime=2000</div><div class="line"></div><div class="line"># the location to store the in-memory database snapshots and, unless specified otherwise, the transaction log of updates to the database.</div><div class="line"># dataDir 顾名思义就是Zookeeper保存数据的目录,默认情况下Zookeeper将写数据的日志文件也保存在这个目录里。</div><div class="line">dataDir=/var/lib/zookeeper</div><div class="line"></div><div class="line"># the port to listen for client connections</div><div class="line"># clientPort 这个端口就是客户端（应用程序）连接Zookeeper服务器的端口，Zookeeper会监听这个端口接受客户端的访问请求。</div><div class="line">clientPort=2181</div><div class="line"></div><div class="line"># initLimit 这个配置项是用来配置Zookeeper接受客户端（这里所说的客户端不是用户连接Zookeeper 服务器的客户端，而是Zookeeper服务器集群中连接到Leader的Follower服务器）初始化连接时最长能忍受多少个心跳时间间隔数。当已经超过10个心跳的时间（也就是tickTime）长度后Zookeeper服务器还没有收到客户端的返回信息，那么表明这个客户端连接失败。总的时间长度就是 10*2000=20 秒。</div><div class="line">initLimit=10</div><div class="line"></div><div class="line"># syncLimit 这个配置项标识Leader与Follower之间发送消息，请求和应答时间长度，最长不能超过多少个tickTime的时间长度，总的时间长度就是 5*2000=10 秒。</div><div class="line">syncLimit=5</div><div class="line"></div><div class="line"># 第一个port是从机器（follower）连接到主机器（leader）的端口号，第二个port是进行leadership选举的端口号。</div><div class="line"># 值得重点注意的一点是，所有三个机器都应该打开端口 2181、2888 和 3888。在本例中，端口 2181 由 ZooKeeper 客户端使用，用于连接到 ZooKeeper 服务器；端口 2888 由对等 ZooKeeper 服务器使用，用于互相通信；而端口 3888 用于领导者选举。您可以选择自己喜欢的任何端口。通常建议在所有 ZooKeeper 服务器上使用相同的端口。</div><div class="line">server.1=zoo1:2888:3888</div><div class="line">server.2=zoo2:2888:3888</div><div class="line">server.3=zoo3:2888:3888</div></pre></td></tr></table></figure>
<h4 id="启动Zookeeper服务端"><a href="#启动Zookeeper服务端" class="headerlink" title="启动Zookeeper服务端"></a>启动Zookeeper服务端</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"># 分别启动Hadoop1，Hadoop2，Hadoop3的Zookeeper服务</div><div class="line">$ ./bin/zkServer.sh start</div><div class="line"></div><div class="line">ZooKeeper JMX enabled by defaultUsing config: /software/zookeeper-3.4.8/bin/../conf/zoo.cfgStarting zookeeper ... STARTED</div><div class="line"></div><div class="line"># 检查Hadoop1的Zookeeper服务状态（这里Hadoop1节点的zk是leader，Hadoop2和Hadoop3节点的zk是follower）</div><div class="line">$ ./bin/zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /data/zookeeper-3.4.8/bin/../conf/zoo.cfgMode: leader</div><div class="line"></div><div class="line"># 检查Hadoop2的Zookeeper服务状态</div><div class="line">$ ./bin/zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /data/zookeeper-3.4.8/bin/../conf/zoo.cfgMode: follower</div><div class="line"></div><div class="line"># 检查Hadoop3的Zookeeper服务状态</div><div class="line">$ ./bin/zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /data/zookeeper-3.4.8/bin/../conf/zoo.cfgMode: follower</div></pre></td></tr></table></figure>
<h4 id="需要注意的地方"><a href="#需要注意的地方" class="headerlink" title="需要注意的地方"></a>需要注意的地方</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">JMX enabled by default</div><div class="line">Using config: /root/zookeeper-3.4.6/bin/../conf/zoo.cfg</div><div class="line">Error contacting service. It is probably not running.</div></pre></td></tr></table></figure>
<p>确认下面两点，应该就能排查出问题，我就遇到过重启Docker容器IP<br>地址变化，导致/etc/hosts中的IP地址配置不正确</p>
<ul>
<li>确认/etc/hosts中是否有各个节点域名解析</li>
<li>是否/var/zookeeper/myid有重复值</li>
<li>集群模式只启动一台也会遇到该问题，最好等把其他集群的机器启动好在查看状态</li>
</ul>
<h4 id="启动Zookeeper-Client端"><a href="#启动Zookeeper-Client端" class="headerlink" title="启动Zookeeper Client端"></a>启动Zookeeper Client端</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line"># -server：client端连接的IP和端口号</div><div class="line">$ ./bin/zkCli.sh -server 127.0.0.1:2181Connecting to 127.0.0.1:21812016-09-30 01:51:22,268 [myid:] - INFO  [main:Environment@100] - Client environment:zookeeper.version=3.4.8--1, built on 02/06/2016 03:18 GMT2016-09-30 01:51:22,271 [myid:] - INFO  [main:Environment@100] - Client environment:host.name=hadoop12016-09-30 01:51:22,271 [myid:] - INFO  [main:Environment@100] - Client environment:java.version=1.7.0_792016-09-30 01:51:22,272 [myid:] - INFO  [main:Environment@100] - Client environment:java.vendor=Oracle Corporation2016-09-30 01:51:22,272 [myid:] - INFO  [main:Environment@100] - Client environment:java.home=/data/jdk1.7.0_79/jre2016-09-30 01:51:22,272 [myid:] - INFO  [main:Environment@100] - Client environment:java.class.path=/data/zookeeper-3.4.8/bin/../build/classes:/data/zookeeper-3.4.8/bin/../build/lib/*.jar:/data/zookeeper-3.4.8/bin/../lib/slf4j-log4j12-1.6.1.jar:/data/zookeeper-3.4.8/bin/../lib/slf4j-api-1.6.1.jar:/data/zookeeper-3.4.8/bin/../lib/netty-3.7.0.Final.jar:/data/zookeeper-3.4.8/bin/../lib/log4j-1.2.16.jar:/data/zookeeper-3.4.8/bin/../lib/jline-0.9.94.jar:/data/zookeeper-3.4.8/bin/../zookeeper-3.4.8.jar:/data/zookeeper-3.4.8/bin/../src/java/lib/*.jar:/data/zookeeper-3.4.8/bin/../conf:2016-09-30 01:51:22,273 [myid:] - INFO  [main:Environment@100] - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib2016-09-30 01:51:22,273 [myid:] - INFO  [main:Environment@100] - Client environment:java.io.tmpdir=/tmp2016-09-30 01:51:22,273 [myid:] - INFO  [main:Environment@100] - Client environment:java.compiler=&lt;NA&gt;2016-09-30 01:51:22,273 [myid:] - INFO  [main:Environment@100] - Client environment:os.name=Linux2016-09-30 01:51:22,273 [myid:] - INFO  [main:Environment@100] - Client environment:os.arch=amd642016-09-30 01:51:22,273 [myid:] - INFO  [main:Environment@100] - Client environment:os.version=3.16.0-77-generic2016-09-30 01:51:22,273 [myid:] - INFO  [main:Environment@100] - Client environment:user.name=yunyu2016-09-30 01:51:22,273 [myid:] - INFO  [main:Environment@100] - Client environment:user.home=/home/yunyu2016-09-30 01:51:22,273 [myid:] - INFO  [main:Environment@100] - Client environment:user.dir=/data/zookeeper-3.4.82016-09-30 01:51:22,275 [myid:] - INFO  [main:ZooKeeper@438] - Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=30000 watcher=org.apache.zookeeper.ZooKeeperMain$MyWatcher@71adff7cWelcome to ZooKeeper!2016-09-30 01:51:22,299 [myid:] - INFO  [main-SendThread(127.0.0.1:2181):ClientCnxn$SendThread@1032] - Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)2016-09-30 01:51:22,303 [myid:] - INFO  [main-SendThread(127.0.0.1:2181):ClientCnxn$SendThread@876] - Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating sessionJLine support is enabled2016-09-30 01:51:22,337 [myid:] - INFO  [main-SendThread(127.0.0.1:2181):ClientCnxn$SendThread@1299] - Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x1577a41e9b90000, negotiated timeout = 30000WATCHER::WatchedEvent state:SyncConnected type:None path:null[zk: 127.0.0.1:2181(CONNECTED) 0]</div><div class="line"></div><div class="line"></div><div class="line"># zkShell中输入help会提示出所有的命令参数[zk: 127.0.0.1:2181(CONNECTED) 0] help</div><div class="line">ZooKeeper host:port cmd args</div><div class="line">        get path [watch]</div><div class="line">        ls path [watch]</div><div class="line">        set path data [version]</div><div class="line">        delquota [-n|-b] path</div><div class="line">        quit</div><div class="line">        printwatches on|off</div><div class="line">        create path data acl</div><div class="line">        stat path [watch]</div><div class="line">        listquota path</div><div class="line">        history</div><div class="line">        setAcl path acl</div><div class="line">        getAcl path</div><div class="line">        sync path</div><div class="line">        redo cmdno</div><div class="line">        addauth scheme auth</div><div class="line">        delete path [version]</div><div class="line">        deleteall path</div><div class="line">        setquota -n|-b val path</div><div class="line">        </div><div class="line"># 查看znode节点[zk: 127.0.0.1:2181(CONNECTED) 0] ls</div><div class="line">[zookeeper]</div><div class="line"></div><div class="line"># 创建新的znode节点，关联到&quot;my_data&quot;</div><div class="line">[zk: 127.0.0.1:2181(CONNECTED) 3] create /zk_test my_dataCreated /zk_test[zk: 127.0.0.1:2181(CONNECTED) 4] ls /</div><div class="line">[zookeeper, zk_test]</div><div class="line"></div><div class="line"># 验证/zk_test节点已经关联到&quot;my_data&quot;</div><div class="line">[zk: 127.0.0.1:2181(CONNECTED) 5] get /zk_testmy_datacZxid = 0x6ctime = Mon Aug 29 20:42:40 PDT 2016mZxid = 0x6mtime = Mon Aug 29 20:42:40 PDT 2016pZxid = 0x6cversion = 0dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 7numChildren = 0</div><div class="line"></div><div class="line"># 修改/zk_test节点的数据关联</div><div class="line">[zk: 127.0.0.1:2181(CONNECTED) 6] set /zk_test junkcZxid = 0x6ctime = Mon Aug 29 20:42:40 PDT 2016mZxid = 0x7mtime = Mon Aug 29 20:47:08 PDT 2016pZxid = 0x6cversion = 0dataVersion = 1aclVersion = 0ephemeralOwner = 0x0dataLength = 4numChildren = 0</div><div class="line"></div><div class="line">[zk: 127.0.0.1:2181(CONNECTED) 7] get /zk_testjunkcZxid = 0x6ctime = Mon Aug 29 20:42:40 PDT 2016mZxid = 0x7mtime = Mon Aug 29 20:47:08 PDT 2016pZxid = 0x6cversion = 0dataVersion = 1aclVersion = 0ephemeralOwner = 0x0dataLength = 4numChildren = 0</div><div class="line"></div><div class="line"># 删除/zk_test节点</div><div class="line">[zk: 127.0.0.1:2181(CONNECTED) 8] delete /zk_test[zk: 127.0.0.1:2181(CONNECTED) 9] ls /[zookeeper]</div></pre></td></tr></table></figure>
<p>OK，Zookeeper的cluster模式的配置就大功告成了 ^_^</p>
<p>参考文章：</p>
<ul>
<li><a href="http://zookeeper.apache.org/doc/trunk/zookeeperStarted.html" target="_blank" rel="external">http://zookeeper.apache.org/doc/trunk/zookeeperStarted.html</a></li>
<li><a href="http://www.ibm.com/developerworks/cn/data/library/bd-zookeeper/" target="_blank" rel="external">http://www.ibm.com/developerworks/cn/data/library/bd-zookeeper/</a></li>
<li><a href="https://segmentfault.com/a/1190000003994382" target="_blank" rel="external">https://segmentfault.com/a/1190000003994382</a></li>
<li><a href="http://blog.csdn.net/cruise_h/article/details/19046357" target="_blank" rel="external">http://blog.csdn.net/cruise_h/article/details/19046357</a></li>
</ul>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Zookeeper/">Zookeeper</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Docker/Docker实战（十八）Docker安装Zookeeper集群环境" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/09/02/Docker/Docker实战（十八）Docker安装Zookeeper集群环境/" class="article-date">
  	<time datetime="2016-09-02T02:50:49.000Z" itemprop="datePublished">2016-09-02</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/09/02/Docker/Docker实战（十八）Docker安装Zookeeper集群环境/">Docker实战（十八）Docker安装Zookeeper集群环境</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h5 id="Dockerfile文件"><a href="#Dockerfile文件" class="headerlink" title="Dockerfile文件"></a>Dockerfile文件</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line">############################################</div><div class="line"># version : birdben/zookeeper_cluster:v1</div><div class="line"># desc : 当前版本安装的zookeeper_cluster</div><div class="line">############################################</div><div class="line"># 设置继承自我们创建的 jdk7 镜像</div><div class="line">FROM birdben/jdk7:v1</div><div class="line"></div><div class="line"># 下面是一些创建者的基本信息</div><div class="line">MAINTAINER birdben (191654006@163.com)</div><div class="line"></div><div class="line"># 设置环境变量，所有操作都是非交互式的</div><div class="line">ENV DEBIAN_FRONTEND noninteractive</div><div class="line"></div><div class="line"># 添加 supervisord 的配置文件，并复制配置文件到对应目录下面。（supervisord.conf文件和Dockerfile文件在同一路径）</div><div class="line">COPY supervisord.conf /etc/supervisor/conf.d/supervisord.conf</div><div class="line"></div><div class="line"># 设置 zookeeper 的环境变量，若读者有其他的环境变量需要设置，也可以在这里添加。</div><div class="line">ENV ZOOKEEPER_HOME /software/zookeeper-3.4.8</div><div class="line">ENV PATH $&#123;ZOOKEEPER_HOME&#125;/bin:$PATH</div><div class="line"></div><div class="line"># 复制 zookeeper-3.4.8 文件到镜像中（zookeeper-3.4.8 文件夹要和Dockerfile文件在同一路径）</div><div class="line">ADD zookeeper-3.4.8 /software/zookeeper-3.4.8</div><div class="line"></div><div class="line"># 创建myid文件存储路径</div><div class="line">RUN mkdir -p /var/zookeeper/myid</div><div class="line"></div><div class="line"># 授权ZOOKEEPER_HOME路径给admin用户</div><div class="line">RUN sudo chown -R admin /software/zookeeper-3.4.8</div><div class="line"></div><div class="line"># 容器需要开放Zookeeper 2181, 2888, 3888端口</div><div class="line">EXPOSE 2181</div><div class="line">EXPOSE 2888</div><div class="line">EXPOSE 3888</div><div class="line"></div><div class="line"># 执行supervisord来同时执行多个命令，使用 supervisord 的可执行路径启动服务。</div><div class="line">CMD [&quot;/usr/bin/supervisord&quot;]</div></pre></td></tr></table></figure>
<h5 id="Dockerfile源文件链接："><a href="#Dockerfile源文件链接：" class="headerlink" title="Dockerfile源文件链接："></a>Dockerfile源文件链接：</h5><p><a href="https://github.com/birdben/birdDocker/blob/master/zookeeper_cluster/Dockerfile">https://github.com/birdben/birdDocker/blob/master/zookeeper_cluster/Dockerfile</a></p>
<h5 id="supervisor配置文件内容"><a href="#supervisor配置文件内容" class="headerlink" title="supervisor配置文件内容"></a>supervisor配置文件内容</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"># 配置文件包含目录和进程</div><div class="line"># 第一段 supervsord 配置软件本身，使用 nodaemon 参数来运行。</div><div class="line"># 第二段包含要控制的 2 个服务。每一段包含一个服务的目录和启动这个服务的命令。</div><div class="line"></div><div class="line">[supervisord]</div><div class="line">nodaemon=true</div><div class="line"></div><div class="line">[program:sshd]</div><div class="line">command=/usr/sbin/sshd -D</div><div class="line"></div><div class="line">[program:zookeeper]</div><div class="line">command=/bin/bash -c &quot;exec $&#123;ZOOKEEPER_HOME&#125;/bin/zkServer.sh start-foreground&quot;</div></pre></td></tr></table></figure>
<h5 id="配置ZOOKEEPER-HOME-conf-zoo-cfg并不在conf目录-需要复制zoo-sample-cfg并改名为zoo-cfg"><a href="#配置ZOOKEEPER-HOME-conf-zoo-cfg并不在conf目录-需要复制zoo-sample-cfg并改名为zoo-cfg" class="headerlink" title="配置ZOOKEEPER_HOME/conf/zoo.cfg并不在conf目录, 需要复制zoo_sample.cfg并改名为zoo.cfg"></a>配置ZOOKEEPER_HOME/conf/zoo.cfg并不在conf目录, 需要复制zoo_sample.cfg并改名为zoo.cfg</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"># The number of milliseconds of each tick</div><div class="line">tickTime=2000</div><div class="line"># The number of ticks that the initial </div><div class="line"># synchronization phase can take</div><div class="line">initLimit=10</div><div class="line"># The number of ticks that can pass between </div><div class="line"># sending a request and getting an acknowledgement</div><div class="line">syncLimit=5</div><div class="line"># the directory where the snapshot is stored.</div><div class="line"># do not use /tmp for storage, /tmp here is just </div><div class="line"># example sakes.</div><div class="line">dataDir=/var/zookeeper</div><div class="line"># the port at which the clients will connect</div><div class="line">clientPort=2181</div><div class="line"># the maximum number of client connections.</div><div class="line"># increase this if you need to handle more clients</div><div class="line">#maxClientCnxns=60</div><div class="line">#</div><div class="line"># Be sure to read the maintenance section of the </div><div class="line"># administrator guide before turning on autopurge.</div><div class="line">#</div><div class="line"># http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance</div><div class="line">#</div><div class="line"># The number of snapshots to retain in dataDir</div><div class="line">#autopurge.snapRetainCount=3</div><div class="line"># Purge task interval in hours</div><div class="line"># Set to &quot;0&quot; to disable auto purge feature</div><div class="line">#autopurge.purgeInterval=1</div><div class="line"></div><div class="line"># 第一个port是从机器（follower）连接到主机器（leader）的端口号，第二个port是进行leadership选举的端口号。</div><div class="line">server.1=zoo1:2888:3888</div><div class="line">server.2=zoo2:2888:3888</div><div class="line">server.3=zoo3:2888:3888</div></pre></td></tr></table></figure>
<h5 id="控制台终端"><a href="#控制台终端" class="headerlink" title="控制台终端"></a>控制台终端</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"># 构建镜像</div><div class="line">$ docker build -t &quot;birdben/zookeeper_cluster:v1&quot; .</div><div class="line"># 启动Docker容器，这里分别对每个docker容器指定了不同的hostname</div><div class="line"># 需要暴露2181客户端连接端口号，否则Docker容器外无法连接到zookeeper集群</div><div class="line">$ sudo docker run -p 2181:2181 -p 2888:2888 -p 3888:3888 -h zoo1 --name zoo1 -t -i &apos;birdben/zookeeper_cluster:v1&apos;</div><div class="line">$ sudo docker run -p 2181:2181 -p 2888:2888 -p 3888:3888 -h zoo2 --name zoo2 -t -i &apos;birdben/zookeeper_cluster:v1&apos;</div><div class="line">$ sudo docker run -p 2181:2181 -p 2888:2888 -p 3888:3888 -h zoo3 --name zoo3 -t -i &apos;birdben/zookeeper_cluster:v1&apos;</div><div class="line"></div><div class="line"># 查询Docker容器对应的IP地址</div><div class="line">$ sudo docker inspect --format=&apos;&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;&apos; $&#123;CONTAINER_ID&#125;</div><div class="line"></div><div class="line"># 需要exec进入Docker容器配置myid和hosts文件</div><div class="line">$ sudo docker exec -it $&#123;CONTAINER_ID&#125; /bin/bash</div><div class="line"></div><div class="line"># 配置每个Docker容器的myid，对应zoo序号执行</div><div class="line">$ echo 1 &gt; /var/zookeeper/myid</div><div class="line">$ echo 2 &gt; /var/zookeeper/myid</div><div class="line">$ echo 3 &gt; /var/zookeeper/myid</div><div class="line"></div><div class="line"># 配置每个Docker容器的/etc/hosts文件</div><div class="line">172.17.0.51     zoo1</div><div class="line">172.17.0.52     zoo2</div><div class="line">172.17.0.53     zoo3</div><div class="line"></div><div class="line"># 分别启动每个Docker容器中的zookeeper服务</div><div class="line">$ ./&#123;ZOOKEEPER_HOME&#125;/bin/zkServer.sh start</div><div class="line"></div><div class="line"># 查看每个Docker容器的zookeeper运行状态</div><div class="line">$ ./&#123;ZOOKEEPER_HOME&#125;/bin/zkServer.sh status</div><div class="line"></div><div class="line"># 下面是我查看每个zookeeper的状态，zoo2的Docker容器的zk是leader，zoo1和zoo3是follower</div><div class="line">root@zoo1:/software/zookeeper-3.4.8/bin# ./zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /software/zookeeper-3.4.8/bin/../conf/zoo.cfgMode: follower</div><div class="line"></div><div class="line">root@zoo2:/software/zookeeper-3.4.8/bin# ./zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /software/zookeeper-3.4.8/bin/../conf/zoo.cfgMode: leader</div><div class="line"></div><div class="line">root@zoo3:/software/zookeeper-3.4.8/bin# ./zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /software/zookeeper-3.4.8/bin/../conf/zoo.cfgMode: follower</div></pre></td></tr></table></figure>
<h5 id="使用zkCli-sh连接服务端进行操作"><a href="#使用zkCli-sh连接服务端进行操作" class="headerlink" title="使用zkCli.sh连接服务端进行操作"></a>使用zkCli.sh连接服务端进行操作</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">$ ./zkCli.sh -server 10.10.1.167:2181</div><div class="line">Connecting to 10.10.1.167:2181</div><div class="line">2016-09-02 11:01:56,761 [myid:] - INFO  [main:Environment@100] - Client environment:zookeeper.version=3.4.8--1, built on 02/06/2016 03:18 GMT</div><div class="line">2016-09-02 11:01:56,764 [myid:] - INFO  [main:Environment@100] - Client environment:host.name=localhost</div><div class="line">2016-09-02 11:01:56,764 [myid:] - INFO  [main:Environment@100] - Client environment:java.version=1.7.0_79</div><div class="line">2016-09-02 11:01:56,766 [myid:] - INFO  [main:Environment@100] - Client environment:java.vendor=Oracle Corporation</div><div class="line">2016-09-02 11:01:56,766 [myid:] - INFO  [main:Environment@100] - Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home/jre</div><div class="line">2016-09-02 11:01:56,766 [myid:] - INFO  [main:Environment@100] - Client environment:java.class.path=/Users/yunyu/dev/zookeeper-3.4.8/bin/../build/classes:/Users/yunyu/dev/zookeeper-3.4.8/bin/../build/lib/*.jar:/Users/yunyu/dev/zookeeper-3.4.8/bin/../lib/slf4j-log4j12-1.6.1.jar:/Users/yunyu/dev/zookeeper-3.4.8/bin/../lib/slf4j-api-1.6.1.jar:/Users/yunyu/dev/zookeeper-3.4.8/bin/../lib/netty-3.7.0.Final.jar:/Users/yunyu/dev/zookeeper-3.4.8/bin/../lib/log4j-1.2.16.jar:/Users/yunyu/dev/zookeeper-3.4.8/bin/../lib/jline-0.9.94.jar:/Users/yunyu/dev/zookeeper-3.4.8/bin/../zookeeper-3.4.8.jar:/Users/yunyu/dev/zookeeper-3.4.8/bin/../src/java/lib/*.jar:/Users/yunyu/dev/zookeeper-3.4.8/bin/../conf:</div><div class="line">2016-09-02 11:01:56,766 [myid:] - INFO  [main:Environment@100] - Client environment:java.library.path=/Users/yunyu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.</div><div class="line">2016-09-02 11:01:56,766 [myid:] - INFO  [main:Environment@100] - Client environment:java.io.tmpdir=/var/folders/0h/jtjrr7g95mv2pt4ts1tgmzyh0000gn/T/</div><div class="line">2016-09-02 11:01:56,766 [myid:] - INFO  [main:Environment@100] - Client environment:java.compiler=&lt;NA&gt;</div><div class="line">2016-09-02 11:01:56,766 [myid:] - INFO  [main:Environment@100] - Client environment:os.name=Mac OS X</div><div class="line">2016-09-02 11:01:56,766 [myid:] - INFO  [main:Environment@100] - Client environment:os.arch=x86_64</div><div class="line">2016-09-02 11:01:56,766 [myid:] - INFO  [main:Environment@100] - Client environment:os.version=10.11.5</div><div class="line">2016-09-02 11:01:56,766 [myid:] - INFO  [main:Environment@100] - Client environment:user.name=yunyu</div><div class="line">2016-09-02 11:01:56,766 [myid:] - INFO  [main:Environment@100] - Client environment:user.home=/Users/yunyu</div><div class="line">2016-09-02 11:01:56,767 [myid:] - INFO  [main:Environment@100] - Client environment:user.dir=/Users/yunyu/dev/zookeeper-3.4.8/bin</div><div class="line">2016-09-02 11:01:56,767 [myid:] - INFO  [main:ZooKeeper@438] - Initiating client connection, connectString=10.10.1.167:2181 sessionTimeout=30000 watcher=org.apache.zookeeper.ZooKeeperMain$MyWatcher@5be7d8b1</div><div class="line">Welcome to ZooKeeper!</div><div class="line">2016-09-02 11:01:56,791 [myid:] - INFO  [main-SendThread(10.10.1.167:2181):ClientCnxn$SendThread@1032] - Opening socket connection to server 10.10.1.167/10.10.1.167:2181. Will not attempt to authenticate using SASL (unknown error)</div><div class="line">JLine support is enabled</div><div class="line">2016-09-02 11:01:56,798 [myid:] - INFO  [main-SendThread(10.10.1.167:2181):ClientCnxn$SendThread@876] - Socket connection established to 10.10.1.167/10.10.1.167:2181, initiating session</div><div class="line">2016-09-02 11:01:56,821 [myid:] - INFO  [main-SendThread(10.10.1.167:2181):ClientCnxn$SendThread@1299] - Session establishment complete on server 10.10.1.167/10.10.1.167:2181, sessionid = 0x156e8d804300000, negotiated timeout = 30000</div><div class="line"></div><div class="line">WATCHER::</div><div class="line"></div><div class="line">WatchedEvent state:SyncConnected type:None path:null</div><div class="line">[zk: 10.10.1.167:2181(CONNECTED) 0]</div></pre></td></tr></table></figure>
<h5 id="需要注意的地方"><a href="#需要注意的地方" class="headerlink" title="需要注意的地方"></a>需要注意的地方</h5><ul>
<li>因为我们zookeeper的启动方式是用的supervisor启动，但是Docker容器启动的时候，我们还不知道Docker容器的IP地址，无法指定hosts文件配置，所以我们要先进入到Docker容器指定好hosts文件配置，然后重新启动zookeeper服务</li>
<li>myid的配置也是每个Docker容器都不一样，最好跟hosts配置对应</li>
<li>需要Docker容器外连接zookeeper集群需要在启动Docker容器时，指定一个Docker容器对外开放2181客户端连接端口号，否则Docker容器外无法连接到zookeeper集群</li>
<li>如果查看zookeeper运行状态提示有问题</li>
<li>值得重点注意的一点是，所有三个机器都应该打开端口 2181、2888 和 3888。在本例中，端口 2181 由 ZooKeeper 客户端使用，用于连接到 ZooKeeper 服务器；端口 2888 由对等 ZooKeeper 服务器使用，用于互相通信；而端口 3888 用于领导者选举。您可以选择自己喜欢的任何端口。通常建议在所有 ZooKeeper 服务器上使用相同的端口。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">JMX enabled by default</div><div class="line">Using config: /root/zookeeper-3.4.6/bin/../conf/zoo.cfg</div><div class="line">Error contacting service. It is probably not running.</div></pre></td></tr></table></figure>
<p>确认下面两点，应该就能排查出问题，我就遇到过重启Docker容器IP<br>地址变化，导致/etc/hosts中的IP地址配置不正确</p>
<ul>
<li>确认/etc/hosts中是否有各个节点域名解析</li>
<li>是否/var/zookeeper/myid有重复值</li>
</ul>
<p>参考文章：</p>
<ul>
<li><a href="https://segmentfault.com/a/1190000003994382" target="_blank" rel="external">https://segmentfault.com/a/1190000003994382</a></li>
<li><a href="http://blog.csdn.net/cruise_h/article/details/19046357" target="_blank" rel="external">http://blog.csdn.net/cruise_h/article/details/19046357</a></li>
</ul>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Dockerfile/">Dockerfile</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Docker命令/">Docker命令</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Zookeeper/">Zookeeper</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Docker/">Docker</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><a class="extend next" rel="next" href="/page/3/">Next &raquo;</a>
    </nav>
  
</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2016 birdben
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: true,
		isPost: false,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
<script src="/js/main.js"></script>



<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-82900755-1', 'auto');
  ga('send', 'pageview');

</script>
<!-- End Google Analytics -->




<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  </div>
</body>
</html>