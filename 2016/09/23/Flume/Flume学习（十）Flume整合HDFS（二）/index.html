<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <title>Flume学习（十）Flume整合HDFS（二） | birdben</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="上一篇介绍了Flume整合HDFS，但是没有对HDFS Sink进行配置上的优化，本篇重点介绍HDFS Sink的相关配置。
上一篇中我们用Flume采集的日志直接输出到HDFS文件中，但是文件的输出的文件大小
优化后的flume_collector_hdfs.conf配置文件1234567891011121314151617181920212223242526272829303132333435">
<meta property="og:type" content="article">
<meta property="og:title" content="Flume学习（十）Flume整合HDFS（二）">
<meta property="og:url" content="https://github.com/birdben/2016/09/23/Flume/Flume学习（十）Flume整合HDFS（二）/index.html">
<meta property="og:site_name" content="birdben">
<meta property="og:description" content="上一篇介绍了Flume整合HDFS，但是没有对HDFS Sink进行配置上的优化，本篇重点介绍HDFS Sink的相关配置。
上一篇中我们用Flume采集的日志直接输出到HDFS文件中，但是文件的输出的文件大小
优化后的flume_collector_hdfs.conf配置文件1234567891011121314151617181920212223242526272829303132333435">
<meta property="og:updated_time" content="2016-10-18T18:40:25.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Flume学习（十）Flume整合HDFS（二）">
<meta name="twitter:description" content="上一篇介绍了Flume整合HDFS，但是没有对HDFS Sink进行配置上的优化，本篇重点介绍HDFS Sink的相关配置。
上一篇中我们用Flume采集的日志直接输出到HDFS文件中，但是文件的输出的文件大小
优化后的flume_collector_hdfs.conf配置文件1234567891011121314151617181920212223242526272829303132333435">
  
    <link rel="alternative" href="/atom.xml" title="birdben" type="application/atom+xml">
  
  
    <link rel="icon" href="/images/favicon.ico">
  
  <link rel="stylesheet" href="/css/style.css">
  
<script type="text/javascript">
var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1260188951'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s4.cnzz.com/z_stat.php%3Fid%3D1260188951' type='text/javascript'%3E%3C/script%3E"));
</script>

</head>

<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="/images/logo.png" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">birdben</a></h1>
		</hgroup>

		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						<div class="icon-wrap icon-link hide" data-idx="2">
							<div class="loopback_l"></div>
							<div class="loopback_r"></div>
						</div>
						
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>Menu</li>
						<li>Tags</li>
						
						<li>Links</li>
						
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives">所有文章</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/birdben" title="github">github</a>
					        
								<a class="weibo" target="_blank" href="#" title="weibo">weibo</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/Akka/" style="font-size: 11.11px;">Akka</a> <a href="/tags/Dockerfile/" style="font-size: 20px;">Dockerfile</a> <a href="/tags/Docker命令/" style="font-size: 18.89px;">Docker命令</a> <a href="/tags/Docker环境/" style="font-size: 11.11px;">Docker环境</a> <a href="/tags/ELK/" style="font-size: 11.11px;">ELK</a> <a href="/tags/ElasticSearch/" style="font-size: 11.11px;">ElasticSearch</a> <a href="/tags/Flume/" style="font-size: 17.78px;">Flume</a> <a href="/tags/Git命令/" style="font-size: 13.33px;">Git命令</a> <a href="/tags/HBase/" style="font-size: 10px;">HBase</a> <a href="/tags/HDFS/" style="font-size: 16.67px;">HDFS</a> <a href="/tags/Hadoop/" style="font-size: 10px;">Hadoop</a> <a href="/tags/Hadoop原理架构体系/" style="font-size: 10px;">Hadoop原理架构体系</a> <a href="/tags/Hive/" style="font-size: 15.56px;">Hive</a> <a href="/tags/Kafka/" style="font-size: 12.22px;">Kafka</a> <a href="/tags/Kibana/" style="font-size: 11.11px;">Kibana</a> <a href="/tags/Linux命令/" style="font-size: 12.22px;">Linux命令</a> <a href="/tags/Maven配置/" style="font-size: 11.11px;">Maven配置</a> <a href="/tags/MongoDB/" style="font-size: 12.22px;">MongoDB</a> <a href="/tags/MySQL/" style="font-size: 10px;">MySQL</a> <a href="/tags/Nginx/" style="font-size: 10px;">Nginx</a> <a href="/tags/Redis/" style="font-size: 10px;">Redis</a> <a href="/tags/Shadowsocks/" style="font-size: 10px;">Shadowsocks</a> <a href="/tags/Shell/" style="font-size: 14.44px;">Shell</a> <a href="/tags/Spring/" style="font-size: 11.11px;">Spring</a> <a href="/tags/Zookeeper/" style="font-size: 13.33px;">Zookeeper</a> <a href="/tags/其他/" style="font-size: 10px;">其他</a>
					</div>
				</section>
				
				
				
				<section class="switch-part switch-part3">
					<div id="js-friends">
					
			          <a target="_blank" class="main-nav-link switch-friends-link" href="http://blog.csdn.net/birdben">我的CSDN的博客</a>
			        
			        </div>
				</section>
				

				
			</div>
		</div>
	</header>				
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">birdben</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
			
				<img lazy-src="/images/logo.png" class="js-avatar">
			
			</div>
			<hgroup>
			  <h1 class="header-author">birdben</h1>
			</hgroup>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives">所有文章</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/birdben" title="github">github</a>
			        
						<a class="weibo" target="_blank" href="#" title="weibo">weibo</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>

      <div class="body-wrap"><article id="post-Flume/Flume学习（十）Flume整合HDFS（二）" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/09/23/Flume/Flume学习（十）Flume整合HDFS（二）/" class="article-date">
  	<time datetime="2016-09-23T06:09:26.000Z" itemprop="datePublished">2016-09-23</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Flume学习（十）Flume整合HDFS（二）
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Flume/">Flume</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/HDFS/">HDFS</a></li></ul>
	</div>

        
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Log/">Log</a>
	</div>


        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>上一篇介绍了Flume整合HDFS，但是没有对HDFS Sink进行配置上的优化，本篇重点介绍HDFS Sink的相关配置。</p>
<p>上一篇中我们用Flume采集的日志直接输出到HDFS文件中，但是文件的输出的文件大小</p>
<h4 id="优化后的flume-collector-hdfs-conf配置文件"><a href="#优化后的flume-collector-hdfs-conf配置文件" class="headerlink" title="优化后的flume_collector_hdfs.conf配置文件"></a>优化后的flume_collector_hdfs.conf配置文件</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div></pre></td><td class="code"><pre><div class="line">agentX.sources = flume-avro-sink</div><div class="line">agentX.channels = chX</div><div class="line">agentX.sinks = flume-hdfs-sink</div><div class="line"></div><div class="line">agentX.sources.flume-avro-sink.channels = chX</div><div class="line">agentX.sources.flume-avro-sink.type = avro</div><div class="line">agentX.sources.flume-avro-sink.bind = 127.0.0.1</div><div class="line">agentX.sources.flume-avro-sink.port = 41414</div><div class="line">agentX.sources.flume-avro-sink.threads = 8</div><div class="line"></div><div class="line"># 定义拦截器，为消息添加时间戳和Host地址</div><div class="line">agentX.sources.flume-avro-sink.interceptors = i1 i2</div><div class="line">agentX.sources.flume-avro-sink.interceptors.i1.type = timestamp</div><div class="line">agentX.sources.flume-avro-sink.interceptors.i2.type = host</div><div class="line"># 如果不指定hostHeader，就是用%&#123;host&#125;。但是指定了hostHeader=hostname，就需要使用%&#123;hostname&#125;</div><div class="line">agentX.sources.flume-avro-sink.interceptors.i2.hostHeader = hostname</div><div class="line">agentX.sources.flume-avro-sink.interceptors.i2.preserveExisting = true</div><div class="line">agentX.sources.flume-avro-sink.interceptors.i2.useIP = true</div><div class="line"></div><div class="line">agentX.channels.chX.type = memory</div><div class="line">agentX.channels.chX.capacity = 1000</div><div class="line">agentX.channels.chX.transactionCapacity = 100</div><div class="line"></div><div class="line">agentX.sinks.flume-hdfs-sink.type = hdfs</div><div class="line">agentX.sinks.flume-hdfs-sink.channel = chX</div><div class="line"></div><div class="line"># agentX.sinks.flume-hdfs-sink.hdfs.path = hdfs://10.10.1.64:8020/flume/events/</div><div class="line"># 使用时间作为分割目录</div><div class="line">agentX.sinks.flume-hdfs-sink.hdfs.path = hdfs://10.10.1.64:8020/flume/events/%Y%m%d/</div><div class="line"></div><div class="line"># HdfsEventSink中，hdfs.fileType默认为SequenceFile，将其改为DataStream就可以按照采集的文件原样输入到hdfs，加一行agentX.sinks.flume-hdfs-sink.hdfs.fileType = DataStream</div><div class="line"># 设置文件格式， 有3种格式可选择：SequenceFile, DataStream or CompressedStream</div><div class="line"># 当使用DataStream时候，文件不会被压缩，不需要设置hdfs.codeC</div><div class="line"># 当使用CompressedStream时候，必须设置一个正确的hdfs.codeC值</div><div class="line">agentX.sinks.flume-hdfs-sink.hdfs.fileType = DataStream</div><div class="line"></div><div class="line"># 写入hdfs的文件名前缀，可以使用flume提供的日期及%&#123;host&#125;表达式。默认值：FlumeData</div><div class="line">agentX.sinks.flume-hdfs-sink.hdfs.filePrefix = events-%&#123;hostname&#125;-</div><div class="line"># 写入hdfs的文件名后缀，比如：.lzo .log等。</div><div class="line"># agentX.sinks.flume-hdfs-sink.hdfs.fileSuffix = .log</div><div class="line"></div><div class="line"># 临时文件的文件名前缀，hdfs sink会先往目标目录中写临时文件，再根据相关规则重命名成最终目标文件</div><div class="line"># agentX.sinks.flume-hdfs-sink.hdfs.inUsePrefix</div><div class="line"># 临时文件的文件名后缀。默认值：.tmp</div><div class="line"># agentX.sinks.flume-hdfs-sink.hdfs.inUseSuffix</div><div class="line"></div><div class="line"># 当目前被打开的临时文件在该参数指定的时间（秒）内，没有任何数据写入，则将该临时文件关闭并重命名成目标文件。默认值是0</div><div class="line"># agentX.sinks.flume-hdfs-sink.hdfs.idleTimeout = 0</div><div class="line"># 文件压缩格式，包括：gzip, bzip2, lzo, lzop, snappy</div><div class="line"># agentX.sinks.flume-hdfs-sink.hdfs.codeC = gzip</div><div class="line"># 每个批次刷新到HDFS上的events数量。默认值：100</div><div class="line"># agentX.sinks.flume-hdfs-sink.hdfs.batchSize = 100</div><div class="line"></div><div class="line"># 不想每次Flume将日志写入到HDFS文件中都分成很多个碎小的文件，这里控制HDFS的滚动</div><div class="line"># 注：滚动（roll）指的是，hdfs sink将临时文件重命名成最终目标文件，并新打开一个临时文件来写入数据；</div><div class="line"># 设置间隔多长将临时文件滚动成最终目标文件。单位是秒，默认30秒。</div><div class="line"># 如果设置为0的话表示不根据时间滚动hdfs文件</div><div class="line">agentX.sinks.flume-hdfs-sink.hdfs.rollInterval = 0</div><div class="line"># 当临时文件达到该大小（单位：bytes）时，滚动成目标文件。默认值1024，单位是字节。</div><div class="line"># 如果设置为0的话表示不基于文件大小滚动hdfs文件</div><div class="line">agentX.sinks.flume-hdfs-sink.hdfs.rollSize = 0</div><div class="line"># 设置当events数据达到该数量时候，将临时文件滚动成目标文件。默认值是10个。</div><div class="line"># 如果设置为0的话表示不基于事件个数滚动hdfs文件</div><div class="line">agentX.sinks.flume-hdfs-sink.hdfs.rollCount = 300</div><div class="line"></div><div class="line"># 是否启用时间上的”舍弃”，这里的”舍弃”，类似于”四舍五入”，后面再介绍。如果启用，则会影响除了%t的其他所有时间表达式</div><div class="line"># agentX.sinks.flume-hdfs-sink.hdfs.round = true</div><div class="line"># 时间上进行“舍弃”的值。默认值：1</div><div class="line"># 举例：当时间为2015-10-16 17:38:59时候，hdfs.path依然会被解析为：/flume/events/20151016/17:30/00</div><div class="line"># 因为设置的是舍弃10分钟内的时间，因此，该目录每10分钟新生成一个。</div><div class="line"># agentX.sinks.flume-hdfs-sink.hdfs.roundValue = 10</div><div class="line"># 时间上进行”舍弃”的单位，包含：second,minute,hour。默认值：seconds</div><div class="line"># agentX.sinks.flume-hdfs-sink.hdfs.roundUnit = minute</div><div class="line"></div><div class="line"># 写入HDFS文件块的最小副本数。默认值：HDFS副本数</div><div class="line"># agentX.sinks.flume-hdfs-sink.hdfs.minBlockReplicas</div><div class="line"># 最大允许打开的HDFS文件数，当打开的文件数达到该值，最早打开的文件将会被关闭。默认值：5000</div><div class="line"># agentX.sinks.flume-hdfs-sink.hdfs.maxOpenFiles</div><div class="line"># 执行HDFS操作的超时时间（单位：毫秒）。默认值：10000</div><div class="line"># agentX.sinks.flume-hdfs-sink.hdfs.callTimeout</div><div class="line"># hdfs sink启动的操作HDFS的线程数。默认值：10</div><div class="line"># agentX.sinks.flume-hdfs-sink.hdfs.threadsPoolSize</div><div class="line"># 时区。默认值：Local Time</div><div class="line"># agentX.sinks.flume-hdfs-sink.hdfs.timeZone</div><div class="line"># 是否使用当地时间。默认值：flase</div><div class="line"># agentX.sinks.flume-hdfs-sink.hdfs.useLocalTimeStamp</div><div class="line"># hdfs sink关闭文件的尝试次数。默认值：0</div><div class="line"># 如果设置为1，当一次关闭文件失败后，hdfs sink将不会再次尝试关闭文件，这个未关闭的文件将会一直留在那，并且是打开状态。</div><div class="line"># 设置为0，当一次关闭失败后，hdfs sink会继续尝试下一次关闭，直到成功。</div><div class="line"># agentX.sinks.flume-hdfs-sink.hdfs.closeTries</div><div class="line"># hdfs sink尝试关闭文件的时间间隔，如果设置为0，表示不尝试，相当于于将hdfs.closeTries设置成1。默认值：180（秒）</div><div class="line"># agentX.sinks.flume-hdfs-sink.hdfs.retryInterval</div><div class="line"># 序列化类型。其他还有：avro_event或者是实现了EventSerializer.Builder的类名。默认值：TEXT</div><div class="line"># agentX.sinks.flume-hdfs-sink.hdfs.serializer</div></pre></td></tr></table></figure>
<p>注意：hdfs.rollInterval，hdfs.rollSize，hdfs.rollCount这3个参数尤为重要，因为这三个参数是控制HDFS文件滚动的，如果想要按照自己的方式做HDFS文件滚动必须三个参数都需要设置，我这里是按照300个Event来做HDFS文件滚动的，如果仅仅设置hdfs.rollCount一个参数是不起作用的，因为其他两个参数按照默认值还是会生效，如果只希望其中某些参数起作用，最好禁用其他的参数。</p>
<h4 id="在HDFS中查看"><a href="#在HDFS中查看" class="headerlink" title="在HDFS中查看"></a>在HDFS中查看</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">$ hdfs dfs -ls /flume/events/</div><div class="line">16/09/23 14:43:04 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</div><div class="line">Found 1 items</div><div class="line">drwxr-xr-x   - yunyu supergroup          0 2016-09-23 14:42 /flume/events/20160923</div><div class="line"></div><div class="line">$ hdfs dfs -ls /flume/events/20160923/</div><div class="line">16/09/23 14:43:15 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</div><div class="line">Found 4 items</div><div class="line">-rw-r--r--   1 yunyu supergroup      92900 2016-09-23 14:42 /flume/events/20160923/events-.1474612925442</div><div class="line">-rw-r--r--   1 yunyu supergroup       5880 2016-09-23 14:42 /flume/events/20160923/events-.1474612925443.tmp</div><div class="line">-rw-r--r--   1 yunyu supergroup      92900 2016-09-23 14:42 /flume/events/20160923/events-.1474612930367</div><div class="line">-rw-r--r--   1 yunyu supergroup      19193 2016-09-23 14:42 /flume/events/20160923/events-.1474612930368.tmp</div><div class="line"></div><div class="line"># 使用hostname作为前缀，这里的127.0.0.1应该是从/etc/hosts配置文件中读取的</div><div class="line">$ hdfs dfs -ls /flume/events/20160923</div><div class="line">16/09/23 18:01:10 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</div><div class="line">Found 4 items</div><div class="line">-rw-r--r--   1 yunyu supergroup      92900 2016-09-23 18:00 /flume/events/20160923/events-127.0.0.1-.1474624778493</div><div class="line">-rw-r--r--   1 yunyu supergroup      25083 2016-09-23 18:00 /flume/events/20160923/events-127.0.0.1-.1474624778494.tmp</div><div class="line">-rw-r--r--   1 yunyu supergroup      92900 2016-09-23 18:00 /flume/events/20160923/events-127.0.0.1-.1474624788628</div><div class="line">-rw-r--r--   1 yunyu supergroup       5881 2016-09-23 18:00 /flume/events/20160923/events-127.0.0.1-.1474624788629.tmp</div></pre></td></tr></table></figure>
<h4 id="遇到的问题和解决方法"><a href="#遇到的问题和解决方法" class="headerlink" title="遇到的问题和解决方法"></a>遇到的问题和解决方法</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">2016-09-23 14:40:16,810 (SinkRunner-PollingRunner-DefaultSinkProcessor) [ERROR - org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:160)] Unable to deliver event. Exception follows.</div><div class="line">org.apache.flume.EventDeliveryException: java.lang.NullPointerException: Expected timestamp in the Flume event headers, but it was null</div><div class="line">	at org.apache.flume.sink.hdfs.HDFSEventSink.process(HDFSEventSink.java:463)</div><div class="line">	at org.apache.flume.sink.DefaultSinkProcessor.process(DefaultSinkProcessor.java:68)</div><div class="line">	at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:147)</div><div class="line">	at java.lang.Thread.run(Thread.java:745)</div><div class="line">Caused by: java.lang.NullPointerException: Expected timestamp in the Flume event headers, but it was null</div><div class="line">	at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:226)</div><div class="line">	at org.apache.flume.formatter.output.BucketPath.replaceShorthand(BucketPath.java:228)</div><div class="line">	at org.apache.flume.formatter.output.BucketPath.escapeString(BucketPath.java:432)</div><div class="line">	at org.apache.flume.sink.hdfs.HDFSEventSink.process(HDFSEventSink.java:380)</div><div class="line">	... 3 more</div></pre></td></tr></table></figure>
<p>遇到上面的问题是因为写入到HDFS时，使用到了时间戳来区分目录结构，Flume的消息组件Event在接受到之后在Header中没有发现时间戳参数，导致该错误发生，有三种方法可以解决这个错误；</p>
<ul>
<li>在Source中设置拦截器，为每条Event头中加入时间戳（效率会慢一些）</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">agentX.sources.flume-avro-sink.interceptors = i1</div><div class="line">agentX.sources.flume-avro-sink.interceptors.i1.type = timestamp</div></pre></td></tr></table></figure>
<ul>
<li>设置使用本地的时间戳（如果客户端和flume集群时间不一致数据时间会不准确）</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># 为sink指定该参数为true</div><div class="line">agentX.sinks.flume-hdfs-sink.hdfs.useLocalTimeStamp = true</div></pre></td></tr></table></figure>
<ul>
<li>在数据源头解决，在日志Event的Head中添加时间戳再再送到Flume（推荐使用）</li>
</ul>
<p>在向Source发送Event时，将时间戳参数添加到Event的Header中即可，Header是一个Map，添加时MapKey为timestamp</p>
<p>参考文章：</p>
<ul>
<li><a href="http://flume.apache.org/FlumeUserGuide.html#hdfs-sink" target="_blank" rel="external">http://flume.apache.org/FlumeUserGuide.html#hdfs-sink</a></li>
<li><a href="http://lxw1234.com/archives/2015/10/527.htm" target="_blank" rel="external">http://lxw1234.com/archives/2015/10/527.htm</a></li>
<li><a href="http://blog.sina.com.cn/s/blog_db77b3c60102vrzt.html" target="_blank" rel="external">http://blog.sina.com.cn/s/blog_db77b3c60102vrzt.html</a></li>
</ul>

      
    </div>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2016/10/09/Kafka/Kafka学习（一）Kafka环境搭建/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption"><</strong>
      <div class="article-nav-title">
        
          Kafka学习（一）Kafka环境搭建
        
      </div>
    </a>
  
  
    <a href="/2016/09/22/Flume/Flume学习（九）Flume整合HDFS（一）/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">Flume学习（九）Flume整合HDFS（一）</div>
      <strong class="article-nav-caption">></strong>
    </a>
  
</nav>

  
</article>








</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2016 birdben
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
<script src="/js/main.js"></script>



<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-82900755-1', 'auto');
  ga('send', 'pageview');

</script>
<!-- End Google Analytics -->




<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  </div>
</body>
</html>