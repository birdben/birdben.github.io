<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <title>Hadoop学习（三）MapReduce的WordCount实例 | birdben</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="前面Hadoop的集群环境我们已经搭建好了，而且也分析了MapReduce和YARN之前的关系，以及在Hadoop中的作用，接下来我们将在Hadoop集群环境中跑一个我们自己创建的MapReduce离线任务实例WordCount。
我这里有一个Hadoop例子的项目，是我自己写的一些大数据相关的实例，后续会持续更新的。

http://github.com/birdben/birdHadoop">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop学习（三）MapReduce的WordCount实例">
<meta property="og:url" content="https://github.com/birdben/2016/09/10/Hadoop/Hadoop学习（三）MapReduce的WordCount实例/index.html">
<meta property="og:site_name" content="birdben">
<meta property="og:description" content="前面Hadoop的集群环境我们已经搭建好了，而且也分析了MapReduce和YARN之前的关系，以及在Hadoop中的作用，接下来我们将在Hadoop集群环境中跑一个我们自己创建的MapReduce离线任务实例WordCount。
我这里有一个Hadoop例子的项目，是我自己写的一些大数据相关的实例，后续会持续更新的。

http://github.com/birdben/birdHadoop">
<meta property="og:updated_time" content="2016-11-25T01:47:26.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hadoop学习（三）MapReduce的WordCount实例">
<meta name="twitter:description" content="前面Hadoop的集群环境我们已经搭建好了，而且也分析了MapReduce和YARN之前的关系，以及在Hadoop中的作用，接下来我们将在Hadoop集群环境中跑一个我们自己创建的MapReduce离线任务实例WordCount。
我这里有一个Hadoop例子的项目，是我自己写的一些大数据相关的实例，后续会持续更新的。

http://github.com/birdben/birdHadoop">
  
    <link rel="alternative" href="/atom.xml" title="birdben" type="application/atom+xml">
  
  
    <link rel="icon" href="/images/favicon.ico">
  
  <link rel="stylesheet" href="/css/style.css">
  
<script type="text/javascript">
var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1260188951'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s4.cnzz.com/z_stat.php%3Fid%3D1260188951' type='text/javascript'%3E%3C/script%3E"));
</script>

</head>

<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="/images/logo.png" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">birdben</a></h1>
		</hgroup>

		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						<div class="icon-wrap icon-link hide" data-idx="2">
							<div class="loopback_l"></div>
							<div class="loopback_r"></div>
						</div>
						
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>Menu</li>
						<li>Tags</li>
						
						<li>Links</li>
						
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives">所有文章</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/birdben" title="github">github</a>
					        
								<a class="weibo" target="_blank" href="#" title="weibo">weibo</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/Akka/" style="font-size: 11px;">Akka</a> <a href="/tags/Dockerfile/" style="font-size: 20px;">Dockerfile</a> <a href="/tags/Docker命令/" style="font-size: 19px;">Docker命令</a> <a href="/tags/Docker环境/" style="font-size: 13px;">Docker环境</a> <a href="/tags/ELK/" style="font-size: 11px;">ELK</a> <a href="/tags/ElasticSearch/" style="font-size: 11px;">ElasticSearch</a> <a href="/tags/Flume/" style="font-size: 17px;">Flume</a> <a href="/tags/Git命令/" style="font-size: 13px;">Git命令</a> <a href="/tags/HBase/" style="font-size: 10px;">HBase</a> <a href="/tags/HDFS/" style="font-size: 18px;">HDFS</a> <a href="/tags/Hadoop/" style="font-size: 10px;">Hadoop</a> <a href="/tags/Hadoop原理架构体系/" style="font-size: 14px;">Hadoop原理架构体系</a> <a href="/tags/Hive/" style="font-size: 16px;">Hive</a> <a href="/tags/Jenkins环境/" style="font-size: 10px;">Jenkins环境</a> <a href="/tags/Kafka/" style="font-size: 13px;">Kafka</a> <a href="/tags/Kibana/" style="font-size: 12px;">Kibana</a> <a href="/tags/Linux命令/" style="font-size: 12px;">Linux命令</a> <a href="/tags/MapReduce/" style="font-size: 12px;">MapReduce</a> <a href="/tags/Maven配置/" style="font-size: 12px;">Maven配置</a> <a href="/tags/MongoDB/" style="font-size: 12px;">MongoDB</a> <a href="/tags/MySQL/" style="font-size: 10px;">MySQL</a> <a href="/tags/Nginx/" style="font-size: 10px;">Nginx</a> <a href="/tags/Redis/" style="font-size: 10px;">Redis</a> <a href="/tags/Shadowsocks/" style="font-size: 10px;">Shadowsocks</a> <a href="/tags/Shell/" style="font-size: 15px;">Shell</a> <a href="/tags/Spring/" style="font-size: 11px;">Spring</a> <a href="/tags/Storm/" style="font-size: 13px;">Storm</a> <a href="/tags/Zookeeper/" style="font-size: 13px;">Zookeeper</a> <a href="/tags/其他/" style="font-size: 10px;">其他</a>
					</div>
				</section>
				
				
				
				<section class="switch-part switch-part3">
					<div id="js-friends">
					
			          <a target="_blank" class="main-nav-link switch-friends-link" href="http://blog.csdn.net/birdben">我的CSDN的博客</a>
			        
			        </div>
				</section>
				

				
			</div>
		</div>
	</header>				
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">birdben</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
			
				<img lazy-src="/images/logo.png" class="js-avatar">
			
			</div>
			<hgroup>
			  <h1 class="header-author">birdben</h1>
			</hgroup>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives">所有文章</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/birdben" title="github">github</a>
			        
						<a class="weibo" target="_blank" href="#" title="weibo">weibo</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>

      <div class="body-wrap"><article id="post-Hadoop/Hadoop学习（三）MapReduce的WordCount实例" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/09/10/Hadoop/Hadoop学习（三）MapReduce的WordCount实例/" class="article-date">
  	<time datetime="2016-09-10T02:08:16.000Z" itemprop="datePublished">2016-09-10</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Hadoop学习（三）MapReduce的WordCount实例
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/HDFS/">HDFS</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop原理架构体系/">Hadoop原理架构体系</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/MapReduce/">MapReduce</a></li></ul>
	</div>

        
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
	</div>


        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>前面Hadoop的集群环境我们已经搭建好了，而且也分析了MapReduce和YARN之前的关系，以及在Hadoop中的作用，接下来我们将在Hadoop集群环境中跑一个我们自己创建的MapReduce离线任务实例WordCount。</p>
<p>我这里有一个Hadoop例子的项目，是我自己写的一些大数据相关的实例，后续会持续更新的。</p>
<ul>
<li><a href="http://github.com/birdben/birdHadoop">http://github.com/birdben/birdHadoop</a></li>
</ul>
<p>WordCount的实例很简单，就是要统计一下某一个文件中每次单词出现的次数，下面就是我们要统计的文件内容</p>
<h5 id="input-WordCount"><a href="#input-WordCount" class="headerlink" title="input_WordCount"></a>input_WordCount</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Hadoop Hive HBaseSpark Hive HadoopKafka HBase ES Logstash StormFlume Kafka Hadoop</div></pre></td></tr></table></figure>
<h5 id="output-WordCount"><a href="#output-WordCount" class="headerlink" title="output_WordCount"></a>output_WordCount</h5><pre><code>ES    1
Flume    1
HBase    2
Hadoop    3
Hive    2
Kafka    2
Logstash    1
Spark    1
Storm    1
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">下面引用了其他博客的图，因为这些图十分形象的描述了MapReduce的执行过程，博客原文链接如下：</div><div class="line"></div><div class="line">- http://www.cnblogs.com/xia520pi/archive/2012/05/16/2504205.html</div><div class="line"></div><div class="line">![WordCount1](http://img.blog.csdn.net/20161030182309567?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)</div><div class="line"></div><div class="line">- 将文件拆分成splits，由于测试用的文件较小，所以每个文件为一个split，并将文件按行分割形成&lt;key,value&gt;对，如上图所示。这一步由MapReduce框架自动完成，其中偏移量（即key值）包括了回车所占的字符数（Windows和Linux环境会不同）。</div><div class="line"></div><div class="line">![WordCount2](http://img.blog.csdn.net/20161030182342598?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)</div><div class="line"></div><div class="line">- 将分割好的&lt;key,value&gt;对交给用户定义的map方法进行处理，生成新的&lt;key,value&gt;对，如上图所示。</div><div class="line"></div><div class="line">![WordCount3](http://img.blog.csdn.net/20161030182404755?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)</div><div class="line"></div><div class="line">- 得到map方法输出的&lt;key,value&gt;对后，Mapper会将它们按照key值进行排序，并执行Combine过程，将key至相同value值累加，得到Mapper的最终输出结果。如上图所示。</div><div class="line"></div><div class="line">![WordCount4](http://img.blog.csdn.net/20161030182418630?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)</div><div class="line"></div><div class="line">- Reducer先对从Mapper接收的数据进行排序，再交由用户自定义的reduce方法进行处理，得到新的&lt;key,value&gt;对，并作为WordCount的输出结果，如上图所示。</div><div class="line"></div><div class="line">### WordCount实例程序</div><div class="line"></div><div class="line">实例程序请参考GitHub上的源代码</div><div class="line"></div><div class="line">- http://github.com/birdben/birdHadoop</div><div class="line"></div><div class="line">这里我们使用Maven来打包构建项目，pom文件中需要添加Hadoop相关jar的引用</div></pre></td></tr></table></figure>

&lt;dependency&gt;
    &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;
    &lt;artifactId&gt;hadoop-common&lt;/artifactId&gt;
    &lt;version&gt;2.4.0&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;
    &lt;artifactId&gt;hadoop-mapreduce-client-core&lt;/artifactId&gt;
    &lt;version&gt;2.4.0&lt;/version&gt;
&lt;/dependency&gt;
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">这里Maven构建将依赖的jar包也打包到birdHadoop.jar中，并且直接在pom文件中指定调用的入口类，我这里指定了入口类是com.birdben.mapreduce.demo.WordCount，然后运行java -jar birdHadoop.jar inputfile outputfile即可。pom文件中的配置如下</div></pre></td></tr></table></figure>

&lt;build&gt;
    &lt;finalName&gt;birdHadoop&lt;/finalName&gt;
    &lt;plugins&gt;
        &lt;plugin&gt;
            &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;
            &lt;configuration&gt;
                &lt;appendAssemblyId&gt;false&lt;/appendAssemblyId&gt;
                &lt;descriptorRefs&gt;
                    &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt;
                &lt;/descriptorRefs&gt;
                &lt;archive&gt;
                    &lt;manifest&gt;
                        &lt;mainClass&gt;com.birdben.mapreduce.demo.WordCountMain&lt;/mainClass&gt;
                    &lt;/manifest&gt;
                &lt;/archive&gt;
            &lt;/configuration&gt;
            &lt;executions&gt;
                &lt;execution&gt;
                    &lt;id&gt;make-assembly&lt;/id&gt;
                    &lt;phase&gt;package&lt;/phase&gt;
                    &lt;goals&gt;
                        &lt;goal&gt;assembly&lt;/goal&gt;
                    &lt;/goals&gt;
                &lt;/execution&gt;
            &lt;/executions&gt;
        &lt;/plugin&gt;
        &lt;plugin&gt;
            &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
            &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
            &lt;version&gt;3.3&lt;/version&gt;
            &lt;configuration&gt;
                &lt;source&gt;1.7&lt;/source&gt;
                &lt;target&gt;1.7&lt;/target&gt;
            &lt;/configuration&gt;
        &lt;/plugin&gt;
    &lt;/plugins&gt;
&lt;/build&gt;
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"></div></pre></td></tr></table></figure>

# 进入项目根目录下
$ cd /Users/yunyu/workspace_git/birdHadoop
# 编译打包
$ mvn clean package
# 执行我们的Shell脚本，这里将HDFS的相关操作写成了Shell脚本
$ sh scripts/mapreduce/runWordCount.sh
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">#### runWordCount.sh脚本文件</div></pre></td></tr></table></figure>

#!/bin/bash
local_path=~/Downloads/birdHadoop
hdfs_input_path=/birdben/input
hdfs_output_path=/birdben/output
# 在HDFS上创建需要分析的文件存储目录，如果已经存在就先删除再重新创建，保证脚本的正常执行
echo &quot;删除HDFS上的input目录$hdfs_input_path&quot;
hdfs dfs -rm -r $hdfs_input_path
echo &quot;创建HDFS上的input目录$hdfs_input_path&quot;
hdfs dfs -mkdir -p $hdfs_input_path
# 需要将我们要分析的track.log日志文件上传到HDFS文件目录下
echo &quot;将$local_path/inputfile/WordCount/input_WordCount文件复制到HDFS的目录$hdfs_input_path&quot;
hdfs dfs -put $local_path/inputfile/WordCount/input_WordCount $hdfs_input_path
# 需要先删除HDFS上已存在的目录，否则hadoop执行jar的时候会报错
echo &quot;删除HDFS的output目录$hdfs_output_path&quot;
hdfs dfs -rm -r -f $hdfs_output_path
# 需要在Maven的pom.xml文件中指定jar的入口类
echo &quot;开始执行birdHadoop.jar...&quot;
hadoop jar $local_path/target/birdHadoop.jar $hdfs_input_path $hdfs_output_path
echo &quot;结束执行birdHadoop.jar...&quot;

if [ ! -d $local_path/outputfile/WordCount ]; then
    # 如果本地文件目录不存在，就自动创建
    echo &quot;自动创建$local_path/outputfile/WordCount目录&quot;
    mkdir -p $local_path/outputfile/WordCount
else
    # 如果本地文件已经存在，就删除
    echo &quot;删除$local_path/outputfile/WordCount/*目录下的所有文件&quot;
    rm -rf $local_path/outputfile/WordCount/*
fi
# 从HDFS目录中导出mapreduce的结果文件到本地文件系统
echo &quot;导出HDFS目录$hdfs_output_path目录下的文件到本地$local_path/outputfile/WordCount/&quot;
hdfs dfs -get $hdfs_output_path/* $local_path/outputfile/WordCount/
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">下面是执行过程中的输出</div></pre></td></tr></table></figure>

$ sh scripts/mapreduce/runWordCount.sh
删除HDFS上的input目录/birdben/input
16/11/02 05:12:57 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /birdben/input
创建HDFS上的input目录/birdben/input
将/home/yunyu/Downloads/birdHadoop/inputfile/WordCount/input_WordCount文件复制到HDFS的目录/birdben/input
删除HDFS的output目录/birdben/output
16/11/02 05:13:04 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /birdben/output
开始执行birdHadoop.jar...
birdben out WordCount start
16/11/02 05:13:07 INFO demo.WordCount: birdben logger WordCount start
16/11/02 05:13:08 INFO client.RMProxy: Connecting to ResourceManager at hadoop1/10.10.1.49:8032
16/11/02 05:13:09 INFO input.FileInputFormat: Total input paths to process : 1
16/11/02 05:13:09 INFO mapreduce.JobSubmitter: number of splits:1
16/11/02 05:13:10 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1478088725123_0001
16/11/02 05:13:10 INFO impl.YarnClientImpl: Submitted application application_1478088725123_0001
16/11/02 05:13:10 INFO mapreduce.Job: The url to track the job: http://hadoop1:8088/proxy/application_1478088725123_0001/
16/11/02 05:13:10 INFO mapreduce.Job: Running job: job_1478088725123_0001
16/11/02 05:13:17 INFO mapreduce.Job: Job job_1478088725123_0001 running in uber mode : false
16/11/02 05:13:17 INFO mapreduce.Job:  map 0% reduce 0%
16/11/02 05:13:24 INFO mapreduce.Job:  map 100% reduce 0%
16/11/02 05:13:32 INFO mapreduce.Job:  map 100% reduce 100%
16/11/02 05:13:32 INFO mapreduce.Job: Job job_1478088725123_0001 completed successfully
16/11/02 05:13:32 INFO mapreduce.Job: Counters: 49
    File System Counters
        FILE: Number of bytes read=114
        FILE: Number of bytes written=230785
        FILE: Number of read operations=0
        FILE: Number of large read operations=0
        FILE: Number of write operations=0
        HDFS: Number of bytes read=194
        HDFS: Number of bytes written=72
        HDFS: Number of read operations=6
        HDFS: Number of large read operations=0
        HDFS: Number of write operations=2
    Job Counters 
        Launched map tasks=1
        Launched reduce tasks=1
        Data-local map tasks=1
        Total time spent by all maps in occupied slots (ms)=4836
        Total time spent by all reduces in occupied slots (ms)=3355
        Total time spent by all map tasks (ms)=4836
        Total time spent by all reduce tasks (ms)=3355
        Total vcore-seconds taken by all map tasks=4836
        Total vcore-seconds taken by all reduce tasks=3355
        Total megabyte-seconds taken by all map tasks=4952064
        Total megabyte-seconds taken by all reduce tasks=3435520
    Map-Reduce Framework
        Map input records=4
        Map output records=14
        Map output bytes=141
        Map output materialized bytes=114
        Input split bytes=109
        Combine input records=14
        Combine output records=9
        Reduce input groups=9
        Reduce shuffle bytes=114
        Reduce input records=9
        Reduce output records=9
        Spilled Records=18
        Shuffled Maps =1
        Failed Shuffles=0
        Merged Map outputs=1
        GC time elapsed (ms)=54
        CPU time spent (ms)=1330
        Physical memory (bytes) snapshot=455933952
        Virtual memory (bytes) snapshot=1415868416
        Total committed heap usage (bytes)=276299776
    Shuffle Errors
        BAD_ID=0
        CONNECTION=0
        IO_ERROR=0
        WRONG_LENGTH=0
        WRONG_MAP=0
        WRONG_REDUCE=0
    File Input Format Counters 
        Bytes Read=85
    File Output Format Counters 
        Bytes Written=72
结束执行birdHadoop.jar...
删除/home/yunyu/Downloads/birdHadoop/outputfile/WordCount/*目录下的所有文件
导出HDFS目录/birdben/output目录下的文件到本地/home/yunyu/Downloads/birdHadoop/outputfile/WordCount/
16/11/02 05:13:34 WARN hdfs.DFSClient: DFSInputStream has been closed already
16/11/02 05:13:35 WARN hdfs.DFSClient: DFSInputStream has been closed already
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">Shell脚本的最后我们将HDFS文件导出到本地系统文件，查看一下这个目录下的文件。</div></pre></td></tr></table></figure>

$ ll outputfile/WordCount/
total 12
drwxrwxr-x 2 yunyu yunyu 4096 Nov  2 20:13 ./
drwxrwxr-x 4 yunyu yunyu 4096 Oct 26 19:46 ../
-rw-r--r-- 1 yunyu yunyu   72 Nov  2 20:13 part-r-00000
-rw-r--r-- 1 yunyu yunyu    0 Nov  2 20:13 _SUCCESS
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">查看一下我们所期望的结果文件part-r-00000的内容</div></pre></td></tr></table></figure>

$ cat outputfile/WordCount/part-r-00000 
ES    1
Flume    1
HBase    2
Hadoop    3
Hive    2
Kafka    2
Logstash    1
Spark    1
Storm    1
</code></pre><p>参考文章：</p>
<ul>
<li><a href="http://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html" target="_blank" rel="external">http://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html</a></li>
<li><a href="http://www.cnblogs.com/xwdreamer/archive/2011/01/04/2297049.html" target="_blank" rel="external">http://www.cnblogs.com/xwdreamer/archive/2011/01/04/2297049.html</a></li>
<li><a href="http://blog.csdn.net/lisonglisonglisong/article/details/47125319" target="_blank" rel="external">http://blog.csdn.net/lisonglisonglisong/article/details/47125319</a></li>
<li><a href="http://www.cnblogs.com/xia520pi/archive/2012/05/16/2504205.html" target="_blank" rel="external">http://www.cnblogs.com/xia520pi/archive/2012/05/16/2504205.html</a></li>
</ul>

      
    </div>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2016/09/10/Hadoop/Hadoop学习（五）Hadoop日志总结/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption"><</strong>
      <div class="article-nav-title">
        
          Hadoop学习（五）Hadoop日志总结
        
      </div>
    </a>
  
  
    <a href="/2016/09/04/Docker/Docker实战（二十）Docker镜像的导入导出/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">Docker实战（二十）Docker镜像的导入导出</div>
      <strong class="article-nav-caption">></strong>
    </a>
  
</nav>

  
</article>








</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2016 birdben
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
<script src="/js/main.js"></script>



<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-82900755-1', 'auto');
  ga('send', 'pageview');

</script>
<!-- End Google Analytics -->




<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  </div>
</body>
</html>