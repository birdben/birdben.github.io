<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <title>birdben</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="birdben">
<meta property="og:url" content="https://github.com/birdben/index.html">
<meta property="og:site_name" content="birdben">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="birdben">
  
    <link rel="alternative" href="/atom.xml" title="birdben" type="application/atom+xml">
  
  
    <link rel="icon" href="/images/favicon.ico">
  
  <link rel="stylesheet" href="/css/style.css">
  
<script type="text/javascript">
var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1260188951'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s4.cnzz.com/z_stat.php%3Fid%3D1260188951' type='text/javascript'%3E%3C/script%3E"));
</script>

</head>

<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="/images/logo.png" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">birdben</a></h1>
		</hgroup>

		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						<div class="icon-wrap icon-link hide" data-idx="2">
							<div class="loopback_l"></div>
							<div class="loopback_r"></div>
						</div>
						
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>Menu</li>
						<li>Tags</li>
						
						<li>Links</li>
						
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives">所有文章</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/birdben" title="github">github</a>
					        
								<a class="weibo" target="_blank" href="#" title="weibo">weibo</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/Akka/" style="font-size: 11.11px;">Akka</a> <a href="/tags/Dockerfile/" style="font-size: 20px;">Dockerfile</a> <a href="/tags/Docker命令/" style="font-size: 18.89px;">Docker命令</a> <a href="/tags/Docker环境/" style="font-size: 13.33px;">Docker环境</a> <a href="/tags/ELK/" style="font-size: 11.11px;">ELK</a> <a href="/tags/ElasticSearch/" style="font-size: 11.11px;">ElasticSearch</a> <a href="/tags/Flume/" style="font-size: 17.78px;">Flume</a> <a href="/tags/Git命令/" style="font-size: 13.33px;">Git命令</a> <a href="/tags/HBase/" style="font-size: 10px;">HBase</a> <a href="/tags/HDFS/" style="font-size: 16.67px;">HDFS</a> <a href="/tags/Hadoop/" style="font-size: 10px;">Hadoop</a> <a href="/tags/Hadoop原理架构体系/" style="font-size: 10px;">Hadoop原理架构体系</a> <a href="/tags/Hive/" style="font-size: 15.56px;">Hive</a> <a href="/tags/Jenkins环境/" style="font-size: 10px;">Jenkins环境</a> <a href="/tags/Kafka/" style="font-size: 12.22px;">Kafka</a> <a href="/tags/Kibana/" style="font-size: 11.11px;">Kibana</a> <a href="/tags/Linux命令/" style="font-size: 12.22px;">Linux命令</a> <a href="/tags/Maven配置/" style="font-size: 12.22px;">Maven配置</a> <a href="/tags/MongoDB/" style="font-size: 12.22px;">MongoDB</a> <a href="/tags/MySQL/" style="font-size: 10px;">MySQL</a> <a href="/tags/Nginx/" style="font-size: 10px;">Nginx</a> <a href="/tags/Redis/" style="font-size: 10px;">Redis</a> <a href="/tags/Shadowsocks/" style="font-size: 10px;">Shadowsocks</a> <a href="/tags/Shell/" style="font-size: 14.44px;">Shell</a> <a href="/tags/Spring/" style="font-size: 11.11px;">Spring</a> <a href="/tags/Storm/" style="font-size: 11.11px;">Storm</a> <a href="/tags/Zookeeper/" style="font-size: 13.33px;">Zookeeper</a> <a href="/tags/其他/" style="font-size: 10px;">其他</a>
					</div>
				</section>
				
				
				
				<section class="switch-part switch-part3">
					<div id="js-friends">
					
			          <a target="_blank" class="main-nav-link switch-friends-link" href="http://blog.csdn.net/birdben">我的CSDN的博客</a>
			        
			        </div>
				</section>
				

				
			</div>
		</div>
	</header>				
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">birdben</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
			
				<img lazy-src="/images/logo.png" class="js-avatar">
			
			</div>
			<hgroup>
			  <h1 class="header-author">birdben</h1>
			</hgroup>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives">所有文章</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/birdben" title="github">github</a>
			        
						<a class="weibo" target="_blank" href="#" title="weibo">weibo</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>

      <div class="body-wrap">
  
    <article id="post-Storm/Storm学习（二）Storm架构及原理（转）" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/11/07/Storm/Storm学习（二）Storm架构及原理（转）/" class="article-date">
  	<time datetime="2016-11-07T11:34:53.000Z" itemprop="datePublished">2016-11-07</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/11/07/Storm/Storm学习（二）Storm架构及原理（转）/">Storm学习（二）Storm架构及原理（转）</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Storm集群环境已经搭建好了，但是在翻译官网的Getting Started的时候感觉有很多概念都不是太理解，所以这篇重点研究一下Storm架构及原理</p>
<p>以下内容转载自：<a href="https://my.oschina.net/leejun2005/blog/147607?fromerr=NjSkGlQI" target="_blank" rel="external">https://my.oschina.net/leejun2005/blog/147607?fromerr=NjSkGlQI</a></p>
<h3 id="Storm-与传统的大数据"><a href="#Storm-与传统的大数据" class="headerlink" title="Storm 与传统的大数据"></a>Storm 与传统的大数据</h3><p>Storm 与其他大数据解决方案的不同之处在于它的处理方式。Hadoop 在本质上是一个批处理系统。数据被引入 Hadoop 文件系统 (HDFS) 并分发到各个节点进行处理。当处理完成时，结果数据返回到 HDFS 供始发者使用。Storm 支持创建拓扑结构来转换没有终点的数据流。不同于 Hadoop 作业，这些转换从不停止，它们会持续处理到达的数据。</p>
<p>但 Storm 不只是一个传统的大数据分析系统：它是复杂事件处理 (CEP) 系统的一个示例。CEP 系统通常分类为计算和面向检测，其中每个系统都可通过用户定义的算法在 Storm 中实现。举例而言，CEP 可用于识别事件洪流中有意义的事件，然后实时地处理这些事件。</p>
<h3 id="Storm的基本组件"><a href="#Storm的基本组件" class="headerlink" title="Storm的基本组件"></a>Storm的基本组件</h3><p>Storm的集群表面上看和Hadoop的集群非常像。但是在Hadoop上面你运行的是MapReduce的Job, 而在Storm上面你运行的是Topology。它们是非常不一样的 — 一个关键的区别是： 一个MapReduce Job最终会结束， 而一个Topology运永远运行（除非你显式的杀掉他）。</p>
<p>在Storm的集群里面有两种节点： 控制节点(master node)和工作节点(worker node)。控制节点上面运行一个后台程序： Nimbus， 它的作用类似Hadoop里面的JobTracker。Nimbus负责在集群里面分布代码，分配工作给机器， 并且监控状态。</p>
<p>每一个工作节点上面运行一个叫做Supervisor的节点（类似 TaskTracker）。Supervisor会监听分配给它那台机器的工作，根据需要 启动/关闭工作进程。每一个工作进程执行一个Topology（类似 Job）的一个子集；一个运行的Topology由运行在很多机器上的很多工作进程 Worker（类似 Child）组成</p>
<h5 id="Storm-Topology结构"><a href="#Storm-Topology结构" class="headerlink" title="Storm Topology结构"></a>Storm Topology结构</h5><p><img src="http://img.blog.csdn.net/20161107201042412?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="Storm Flow"></p>
<h5 id="Storm-VS-MapReduce"><a href="#Storm-VS-MapReduce" class="headerlink" title="Storm VS MapReduce"></a>Storm VS MapReduce</h5><p><img src="http://img.blog.csdn.net/20161107201112288?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="Storm VS MapReduce"></p>
<p>Nimbus和Supervisor之间的所有协调工作都是通过一个Zookeeper集群来完成。并且，Nimbus进程和Supervisor都是快速失败（fail-fast)和无状态的。所有的状态要么在Zookeeper里面， 要么在本地磁盘上。这也就意味着你可以用kill -9来杀死Nimbus和Supervisor进程， 然后再重启它们，它们可以继续工作， 就好像什么都没有发生过似的。这个设计使得Storm不可思议的稳定。</p>
<h3 id="Topologies"><a href="#Topologies" class="headerlink" title="Topologies"></a>Topologies</h3><p>为了在Storm上面做实时计算，你要去建立一些Topologies。一个Topology就是一个计算节点所组成的图。Topology里面的每个处理节点都包含处理逻辑，而节点之间的连接则表示数据流动的方向。</p>
<p>运行一个Topology是很简单的。首先，把你所有的代码以及所依赖的jar打进一个jar包。然后运行类似下面的这个命令。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">storm jar all-your-code.jar backtype.storm.MyTopology arg1 arg2</div></pre></td></tr></table></figure>
<p>这个命令会运行主类: backtype.strom.MyTopology, 参数是arg1, arg2。这个类的main函数定义这个Topology并且把它提交给Nimbus。storm jar负责连接到Nimbus并且上传jar文件。</p>
<p>因为Topology的定义其实就是一个Thrift结构并且Nimbus就是一个Thrift服务， 有可以用任何语言创建并且提交Topology。上面的方面是用JVM-based语言提交的最简单的方法, 看一下文章: 在生产集群上运行Topology去看看怎么启动以及停止Topologies。</p>
<h3 id="Stream"><a href="#Stream" class="headerlink" title="Stream"></a>Stream</h3><p>Stream是Storm里面的关键抽象。一个Stream是一个没有边界的Tuple序列。Storm提供一些原语来分布式地、可靠地把一个Stream传输进一个新的Stream。比如： 你可以把一个Tweets流传输到热门话题的流。</p>
<p>Storm提供的最基本的处理Stream的原语是Spout和Bolt。你可以实现Spout和Bolt对应的接口以处理你的应用的逻辑。</p>
<h4 id="Spout"><a href="#Spout" class="headerlink" title="Spout"></a>Spout</h4><p>Spout的流的源头。比如一个Spout可能从Kestrel队列里面读取消息并且把这些消息发射成一个流。又比如一个Spout可以调用Twitter的一个api并且把返回的Tweets发射成一个流。</p>
<p>通常Spout会从外部数据源（队列、数据库等）读取数据，然后封装成Tuple形式，之后发送到Stream中。Spout是一个主动的角色，在接口内部有个nextTuple函数，Storm框架会不停的调用该函数。</p>
<p><img src="http://img.blog.csdn.net/20161107202111762?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="Spout"></p>
<h4 id="Bolt"><a href="#Bolt" class="headerlink" title="Bolt"></a>Bolt</h4><p>Bolt可以接收任意多个输入Stream，作一些处理，有些Bolt可能还会发射一些新的Stream。一些复杂的流转换，比如从一些Tweet里面计算出热门话题，需要多个步骤，从而也就需要多个Bolt。Bolt可以做任何事情: 运行函数，过滤Tuple，做一些聚合，做一些合并以及访问数据库等等。</p>
<p>Bolt处理输入的Stream，并产生新的输出Stream。Bolt可以执行过滤、函数操作、Join、操作数据库等任何操作。Bolt是一个被动的角色，其接口中有一个execute(Tuple input)方法，在接收到消息之后会调用此函数，用户可以在此方法中执行自己的处理逻辑。</p>
<p><img src="http://img.blog.csdn.net/20161107202143477?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="Bolt"></p>
<p>Spout和Bolt所组成一个网络会被打包成Topology，Topology是Storm里面最高一级的抽象（类Job）， 你可以把Topology提交给Storm的集群来运行。Topology的结构在Topology那一段已经说过了，这里就不再赘述了。</p>
<p><img src="http://img.blog.csdn.net/20161107202222212?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="Topology结构"></p>
<p>Topology里面的每一个节点都是并行运行的。在你的Topology里面，你可以指定每个节点的并行度， Storm则会在集群里面分配那么多线程来同时计算。</p>
<p>一个Topology会一直运行直到你显式停止它。Storm自动重新分配一些运行失败的任务，并且Storm保证你不会有数据丢失，即使在一些机器意外停机并且消息被丢掉的情况下。</p>
<h3 id="数据模型-Data-Model"><a href="#数据模型-Data-Model" class="headerlink" title="数据模型(Data Model)"></a>数据模型(Data Model)</h3><p>Storm使用Tuple来作为它的数据模型。每个Tuple是一堆值，每个值有一个名字，并且每个值可以是任何类型，在我的理解里面一个Tuple可以看作一个没有方法的Java对象。总体来看，Storm支持所有的基本类型、字符串以及字节数组作为Tuple的值类型。你也可以使用你自己定义的类型来作为值类型，只要你实现对应的序列化器(Serializer)。</p>
<p>一个Tuple代表数据流中的一个基本的处理单元，例如一条Cookie日志，它可以包含多个Field，每个Field表示一个属性。</p>
<p>Tuple本来应该是一个Key-Value的Map，由于各个组件间传递的Tuple的字段名称已经事先定义好了，所以Tuple只需要按序填入各个Value，所以就是一个Value List。</p>
<p>一个没有边界的、源源不断的、连续的Tuple序列就组成了Stream。</p>
<p>Topology里面的每个节点必须定义它要发射的Tuple的每个字段。 比如下面这个Bolt定义它所发射的Tuple包含两个字段，类型分别是: double和triple。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">publicclassDoubleAndTripleBoltimplementsIRichBolt &#123;</div><div class="line">    </div><div class="line">    privateOutputCollectorBase _collector;</div><div class="line"> </div><div class="line">    @Override</div><div class="line">    publicvoidprepare(Map conf, TopologyContext context, OutputCollectorBase collector) &#123;</div><div class="line">        _collector = collector;</div><div class="line">    &#125;</div><div class="line"> </div><div class="line">    @Override</div><div class="line">    publicvoidexecute(Tuple input) &#123;</div><div class="line">        intval = input.getInteger(0);</div><div class="line">        _collector.emit(input,newValues(val*2, val*3));</div><div class="line">        _collector.ack(input);</div><div class="line">    &#125;</div><div class="line"> </div><div class="line">    @Override</div><div class="line">    publicvoidcleanup() &#123;</div><div class="line">    &#125;</div><div class="line"> </div><div class="line">    @Override</div><div class="line">    publicvoiddeclareOutputFields(OutputFieldsDeclarer declarer) &#123;</div><div class="line">        declarer.declare(newFields(&quot;double&quot;,&quot;triple&quot;));</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>declareOutputFields方法定义要输出的字段 ： [“double”, “triple”]。这个Bolt的其它部分我们接下来会解释。</p>
<h3 id="一个简单的Topology"><a href="#一个简单的Topology" class="headerlink" title="一个简单的Topology"></a>一个简单的Topology</h3><p>让我们来看一个简单的Topology的例子， 我们看一下storm-starter里面的ExclamationTopology:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">TopologyBuilder builder =newTopologyBuilder();</div><div class="line">builder.setSpout(1,newTestWordSpout(),10);</div><div class="line">builder.setBolt(2,newExclamationBolt(),3)</div><div class="line">        .shuffleGrouping(1);</div><div class="line">builder.setBolt(3,newExclamationBolt(),2)</div><div class="line">        .shuffleGrouping(2);</div></pre></td></tr></table></figure>
<p>这个Topology包含一个Spout和两个Bolt。Spout发射单词，每个Bolt在每个单词后面加个”!!!”。这三个节点被排成一条线: Spout发射单词给第一个Bolt，第一个Bolt然后把处理好的单词发射给第二个Bolt。如果Spout发射的单词是[“bob”]和[“john”], 那么第二个Bolt会发射[“bolt!!!!!!”]和[“john!!!!!!”]出来。</p>
<p>我们使用setSpout和setBolt来定义Topology里面的节点。这些方法接收我们指定的一个id，一个包含处理逻辑的对象(Spout或者Bolt), 以及你所需要的并行度。</p>
<p>这个包含处理的对象如果是Spout那么要实现IRichSpout的接口，如果是Bolt，那么就要实现IRichBolt接口。</p>
<p>最后一个指定并行度的参数是可选的。它表示集群里面需要多少个Thread来一起执行这个节点。如果你忽略它那么Storm会分配一个线程来执行这个节点。</p>
<p>setBolt方法返回一个InputDeclarer对象，这个对象是用来定义Bolt的输入。这里第一个Bolt声明它要读取Spout所发射的所有的Tuple —— 使用shuffle grouping。而第二个Bolt声明它读取第一个Bolt所发射的Tuple。shuffle grouping表示所有的Tuple会被随机的分发给Bolt的所有Task。给Task分发Tuple的策略有很多种，后面会介绍。</p>
<p>如果你想第二个Bolt读取Spout和第一个Bolt所发射的所有的Tuple， 那么你应该这样定义第二个Bolt:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">builder.setBolt(3,newExclamationBolt(),5)</div><div class="line">            .shuffleGrouping(1)</div><div class="line">            .shuffleGrouping(2);</div></pre></td></tr></table></figure>
<p>让我们深入地看一下这个Topology里面的Spout和Bolt是怎么实现的。Spout负责发射新的Tuple到这个Topology里面来。TestWordSpout从[“nathan”, “mike”, “jackson”, “golda”, “bertels”]里面随机选择一个单词发射出来。TestWordSpout里面的nextTuple()方法是这样定义的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">publicvoidnextTuple() &#123;</div><div class="line">    Utils.sleep(100);</div><div class="line">    finalString[] words =newString[] &#123;&quot;nathan&quot;,&quot;mike&quot;,</div><div class="line">                     &quot;jackson&quot;,&quot;golda&quot;,&quot;bertels&quot;&#125;;</div><div class="line">    finalRandom rand =newRandom();</div><div class="line">    finalString word = words[rand.nextInt(words.length)];</div><div class="line">    _collector.emit(newValues(word));</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>可以看到，实现很简单。</p>
<p>ExclamationBolt把”!!!”拼接到输入tuple后面。我们来看下ExclamationBolt的完整实现。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">publicstaticclassExclamationBoltimplementsIRichBolt &#123;</div><div class="line">    OutputCollector _collector;</div><div class="line"> </div><div class="line">    publicvoidprepare(Map conf, TopologyContext context,</div><div class="line">                        OutputCollector collector) &#123;</div><div class="line">        _collector = collector;</div><div class="line">    &#125;</div><div class="line"> </div><div class="line">    publicvoidexecute(Tuple tuple) &#123;</div><div class="line">        _collector.emit(tuple,newValues(tuple.getString(0) +&quot;!!!&quot;));</div><div class="line">        _collector.ack(tuple);</div><div class="line">    &#125;</div><div class="line"> </div><div class="line">    publicvoidcleanup() &#123;</div><div class="line">    &#125;</div><div class="line"> </div><div class="line">    publicvoiddeclareOutputFields(OutputFieldsDeclarer declarer) &#123;</div><div class="line">        declarer.declare(newFields(&quot;word&quot;));</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>prepare方法提供给Bolt一个Outputcollector用来发射tuple。Bolt可以在任何时候发射Tuple —— 在prepare, execute或者cleanup方法里面, 或者甚至在另一个线程里面异步发射。这里prepare方法只是简单地把OutputCollector作为一个类字段保存下来给后面execute方法使用。</p>
<p>execute方法从Bolt的一个输入接收Tuple(一个Bolt可能有多个输入源)。ExclamationBolt获取Tuple的第一个字段，加上”!!!”之后再发射出去。如果一个Bolt有多个输入源，你可以通过调用Tuple#getSourceComponent方法来知道它是来自哪个输入源的。</p>
<p>execute方法里面还有其它一些事情值得一提：输入Tuple被作为emit方法的第一个参数，并且输入Tuple在最后一行被ack。这些呢都是Storm可靠性API的一部分，后面会解释。</p>
<p>cleanup方法在Bolt被关闭的时候调用，它应该清理所有被打开的资源。但是集群不保证这个方法一定会被执行。比如执行Task的机器down掉了，那么根本就没有办法来调用那个方法。cleanup设计的时候是被用来在local mode的时候才被调用(也就是说在一个进程里面模拟整个storm集群), 并且你想在关闭一些Topology的时候避免资源泄漏。</p>
<p>最后，declareOutputFields定义一个叫做”word”的字段的Tuple。</p>
<p>以local mode运行ExclamationTopology<br>让我们看看怎么以local mode运行ExclamationToplogy。</p>
<p>Storm的运行有两种模式: 本地模式和分布式模式。在本地模式中，Storm用一个进程里面的线程来模拟所有的Spout和Bolt。本地模式对开发和测试来说比较有用。你运行storm-starter里面的Topology的时候它们就是以本地模式运行的，你可以看到Topology里面的每一个组件在发射什么消息。</p>
<p>在分布式模式下，Storm由一堆机器组成。当你提交Topology给master的时候，你同时也把Topology的代码提交了。master负责分发你的代码并且负责给你的Topolgoy分配工作进程。如果一个工作进程挂掉了， master节点会把认为重新分配到其它节点。关于如何在一个集群上面运行Topology，你可以看看Running topologies on a production cluster文章。</p>
<p>下面是以本地模式运行ExclamationTopology的代码:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">Config conf =newConfig();</div><div class="line">conf.setDebug(true);</div><div class="line">conf.setNumWorkers(2);</div><div class="line"> </div><div class="line">LocalCluster cluster =newLocalCluster();</div><div class="line">cluster.submitTopology(&quot;test&quot;, conf, builder.createTopology());</div><div class="line">Utils.sleep(10000);</div><div class="line">cluster.killTopology(&quot;test&quot;);</div><div class="line">cluster.shutdown();</div></pre></td></tr></table></figure>
<p>首先， 这个代码定义通过定义一个LocalCluster对象来定义一个进程内的集群。提交Topology给这个虚拟的集群和提交Topology给分布式集群是一样的。通过调用submitTopology方法来提交Topology， 它接受三个参数：要运行的Topology的名字，一个配置对象以及要运行的Topology本身。</p>
<p>Topology的名字是用来唯一区别一个Topology的，这样你然后可以用这个名字来杀死这个Topology的。前面已经说过了，你必须显式的杀掉一个Topology，否则它会一直运行。</p>
<p>Conf对象可以配置很多东西，下面两个是最常见的：</p>
<ul>
<li><p>TOPOLOGY_WORKERS(setNumWorkers) 定义你希望集群分配多少个工作进程给你来执行这个Topology。Topology里面的每个组件会被需要线程来执行。每个组件到底用多少个线程是通过setBolt和setSpout来指定的。这些线程都运行在工作进程里面。每一个工作进程包含一些节点的一些工作线程。比如，如果你指定300个线程，50个进程，那么每个工作进程里面要执行6个线程，而这6个线程可能属于不同的组件(Spout, Bolt)。你可以通过调整每个组件的并行度以及这些线程所在的进程数量来调整Topology的性能。</p>
</li>
<li><p>TOPOLOGY_DEBUG(setDebug), 当它被设置成true的话，storm会记录下每个组件所发射的每条消息。这在本地环境调试Topology很有用，但是在线上这么做的话会影响性能的。</p>
</li>
</ul>
<p>感兴趣的话可以去看看Conf对象的Javadoc去看看topology的所有配置。<br>可以看看创建一个新Storm项目去看看怎么配置开发环境以使你能够以本地模式运行Topology.</p>
<p>运行中的Topology主要由以下三个组件组成的：</p>
<ul>
<li>Worker processes（进程）</li>
<li>Executors (threads)（线程）</li>
<li>Tasks</li>
</ul>
<p><img src="http://img.blog.csdn.net/20161107205213355?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="Worker"></p>
<p>Spout或者Bolt的Task个数一旦指定之后就不能改变了，而Executor的数量可以根据情况来进行动态的调整。默认情况下# executor = #tasks即一个Executor中运行着一个Task</p>
<p><img src="http://img.blog.csdn.net/20161107205238449?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="Executor"></p>
<p><img src="http://img.blog.csdn.net/20161107205311189?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="Topology"></p>
<p><img src="http://img.blog.csdn.net/20161107205348799?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="conf"></p>
<h3 id="流分组策略-Stream-Grouping"><a href="#流分组策略-Stream-Grouping" class="headerlink" title="流分组策略(Stream Grouping)"></a>流分组策略(Stream Grouping)</h3><p>流分组策略告诉Topology如何在两个组件之间发送Tuple。要记住，Spouts和Bolts以很多Task的形式在Topology里面同步执行。如果从Task的粒度来看一个运行的Topology，它应该是这样的:</p>
<p><img src="http://img.blog.csdn.net/20161107210310422?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="Grouping"></p>
<p>从Task角度来看Topology</p>
<p>当Bolt A的一个task要发送一个Tuple给Bolt B， 它应该发送给Bolt B的哪个Task呢？</p>
<p>Stream Grouping专门回答这种问题的。在我们深入研究不同的Stream Grouping之前，让我们看一下storm-starter里面的另外一个Topology。WordCountTopology读取一些句子，输出句子里面每个单词出现的次数.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">TopologyBuilder builder =newTopologyBuilder();</div><div class="line"> </div><div class="line">builder.setSpout(1,newRandomSentenceSpout(),5);</div><div class="line">builder.setBolt(2,newSplitSentence(),8)</div><div class="line">        .shuffleGrouping(1);</div><div class="line">builder.setBolt(3,newWordCount(),12)</div><div class="line">        .fieldsGrouping(2,newFields(&quot;word&quot;));</div></pre></td></tr></table></figure>
<p>SplitSentence对于句子里面的每个单词发射一个新的Tuple, WordCount在内存里面维护一个单词-&gt;次数的Mapping，WordCount每收到一个单词，它就更新内存里面的统计状态。</p>
<p>有好几种不同的Stream Grouping:</p>
<p>最简单的Grouping是shuffle grouping, 它随机发给任何一个Task。上面例子里面RandomSentenceSpout和SplitSentence之间用的就是shuffle grouping, shuffle grouping对各个Task的Tuple分配的比较均匀。</p>
<p>一种更有趣的Grouping是fields grouping, SplitSentence和WordCount之间使用的就是fields grouping, 这种Grouping机制保证相同Field值的Tuple会去同一个Task，这对于WordCount来说非常关键，如果同一个单词不去同一个task，那么统计出来的单词次数就不对了。</p>
<p>fields grouping是Stream合并，Stream聚合以及很多其它场景的基础。在背后呢，fields grouping使用的一致性哈希来分配Tuple的。</p>
<p>还有一些其它类型的Stream Grouping. 你可以在Concepts一章里更详细的了解。</p>
<p>下面是一些常用的 “路由选择” 机制：</p>
<p>Storm的Grouping即消息的Partition机制。当一个Tuple被发送时，如何确定将它发送个某个（些）Task来处理？？</p>
<ul>
<li>ShuffleGrouping：随机选择一个Task来发送。</li>
<li>FieldGrouping：根据Tuple中Fields来做一致性hash，相同hash值的Tuple被发送到相同的Task。</li>
<li>AllGrouping：广播发送，将每一个Tuple发送到所有的Task。</li>
<li>GlobalGrouping：所有的Tuple会被发送到某个Bolt中的id最小的那个Task。</li>
<li>NoneGrouping：不关心Tuple发送给哪个Task来处理，等价于ShuffleGrouping。</li>
<li>DirectGrouping：直接将Tuple发送到指定的Task来处理。</li>
</ul>
<h3 id="使用别的语言来定义Bolt"><a href="#使用别的语言来定义Bolt" class="headerlink" title="使用别的语言来定义Bolt"></a>使用别的语言来定义Bolt</h3><p>Bolt可以使用任何语言来定义。用其它语言定义的Bolt会被当作子进程(subprocess)来执行， Storm使用JSON消息通过stdin/stdout来和这些subprocess通信。这个通信协议是一个只有100行的库，Storm团队给这些库开发了对应的Ruby, Python和Fancy版本。</p>
<p>下面是WordCountTopology里面的SplitSentence的定义:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">publicstaticclassSplitSentenceextendsShellBoltimplementsIRichBolt &#123;</div><div class="line">    publicSplitSentence() &#123;</div><div class="line">        super(&quot;python&quot;,&quot;splitsentence.py&quot;);</div><div class="line">    &#125;</div><div class="line"> </div><div class="line">    publicvoiddeclareOutputFields(OutputFieldsDeclarer declarer) &#123;</div><div class="line">        declarer.declare(newFields(&quot;word&quot;));</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>SplitSentence继承自ShellBolt并且声明这个Bolt用Python来运行，并且参数是: splitsentence.py。下面是splitsentence.py的定义:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">importstorm</div><div class="line"> </div><div class="line">classSplitSentenceBolt(storm.BasicBolt):</div><div class="line">    defprocess(self, tup):</div><div class="line">        words=tup.values[0].split(&quot; &quot;)</div><div class="line">        forwordinwords:</div><div class="line">          storm.emit([word])</div><div class="line"> </div><div class="line">SplitSentenceBolt().run()</div></pre></td></tr></table></figure>
<p>更多有关用其它语言定义Spout和Bolt的信息， 以及用其它语言来创建topology的 信息可以参见: Using non-JVM languages with Storm.</p>
<h3 id="可靠的消息处理"><a href="#可靠的消息处理" class="headerlink" title="可靠的消息处理"></a>可靠的消息处理</h3><p>在这个教程的前面，我们跳过了有关Tuple的一些特征。这些特征就是Storm的可靠性API： Storm如何保证Spout发出的每一个Tuple都被完整处理。看看《storm如何保证消息不丢失》以更深入了解storm的可靠性API.</p>
<p>Storm允许用户在Spout中发射一个新的源Tuple时为其指定一个MessageId，这个MessageId可以是任意的Object对象。多个源Tuple可以共用同一个MessageId，表示这多个源Tuple对用户来说是同一个消息单元。Storm的可靠性是指Storm会告知用户每一个消息单元是否在一个指定的时间内被完全处理。完全处理的意思是该MessageId绑定的源Tuple以及由该源Tuple衍生的所有Tuple都经过了Topology中每一个应该到达的Bolt的处理。</p>
<p><img src="http://img.blog.csdn.net/20161107210353469?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="Message"></p>
<p>在Spout中由message 1绑定的tuple1和tuple2分别经过bolt1和bolt2的处理，然后生成了两个新的Tuple，并最终流向了bolt3。当bolt3处理完之后，称message 1被完全处理了。</p>
<p>Storm中的每一个Topology中都包含有一个Acker组件。Acker组件的任务就是跟踪从Spout中流出的每一个messageId所绑定的Tuple树中的所有Tuple的处理情况。如果在用户设置的最大超时时间内这些Tuple没有被完全处理，那么Acker会告诉Spout该消息处理失败，相反则会告知Spout该消息处理成功。</p>
<p>那么Acker是如何记录Tuple的处理结果呢？？</p>
<p>A xor A = 0.</p>
<p>A xor B…xor B xor A = 0，其中每一个操作数出现且仅出现两次。</p>
<p>在Spout中，Storm系统会为用户指定的MessageId生成一个对应的64位的整数，作为整个Tuple Tree的RootId。RootId会被传递给Acker以及后续的Bolt来作为该消息单元的唯一标识。同时，无论Spout还是Bolt每次新生成一个Tuple时，都会赋予该Tuple一个唯一的64位整数的Id。</p>
<p>当Spout发射完某个MessageId对应的源Tuple之后，它会告诉Acker自己发射的RootId以及生成的那些源Tuple的Id。而当Bolt处理完一个输入Tuple并产生出新的Tuple时，也会告知Acker自己处理的输入Tuple的Id以及新生成的那些Tuple的Id。Acker只需要对这些Id进行异或运算，就能判断出该RootId对应的消息单元是否成功处理完成了。</p>
<p>参考文章：</p>
<ul>
<li><a href="https://my.oschina.net/leejun2005/blog/147607?fromerr=NjSkGlQI" target="_blank" rel="external">https://my.oschina.net/leejun2005/blog/147607?fromerr=NjSkGlQI</a></li>
<li><a href="https://www.ibm.com/developerworks/cn/opensource/os-twitterstorm/#list1" target="_blank" rel="external">https://www.ibm.com/developerworks/cn/opensource/os-twitterstorm/#list1</a></li>
</ul>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Storm/">Storm</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Storm/">Storm</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Storm/Storm学习（一）Storm集群环境搭建" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/11/07/Storm/Storm学习（一）Storm集群环境搭建/" class="article-date">
  	<time datetime="2016-11-07T06:57:13.000Z" itemprop="datePublished">2016-11-07</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/11/07/Storm/Storm学习（一）Storm集群环境搭建/">Storm学习（一）Storm集群环境搭建</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>今天开始搭建Storm集群环境了，主要参考官网的步骤一点一点学习的</p>
<p>搭建Storm集群的主要步骤如下:</p>
<ul>
<li>搭建好一个Zookeeper集群</li>
<li>安装好依赖的环境</li>
<li>下载并解压一个Storm版本</li>
<li>补充主要的配置到storm.yaml配置文件</li>
<li>后台执行Storm启动脚本</li>
</ul>
<h3 id="Zookeeper集群环境搭建"><a href="#Zookeeper集群环境搭建" class="headerlink" title="Zookeeper集群环境搭建"></a>Zookeeper集群环境搭建</h3><p>这里我们不做详细介绍了，Zookeeper集群环境搭建我之前单独写过一篇文章，请参考。</p>
<h3 id="安装依赖环境"><a href="#安装依赖环境" class="headerlink" title="安装依赖环境"></a>安装依赖环境</h3><p>Storm依赖于Java环境和Python环境，具体版本如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Java 7</div><div class="line">Python 2.6.6</div></pre></td></tr></table></figure>
<p>可能Storm在不同的Java和Python版本下会不好用</p>
<h4 id="安装JDK"><a href="#安装JDK" class="headerlink" title="安装JDK"></a>安装JDK</h4><p>省略</p>
<h4 id="安装Python"><a href="#安装Python" class="headerlink" title="安装Python"></a>安装Python</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"># 下载Python2.6.6</div><div class="line">$ wget http://www.python.org/ftp/python/2.6.6/Python-2.6.6.tar.bz2</div><div class="line"></div><div class="line"># 编译安装Python2.6.6</div><div class="line">$ tar –jxvf Python-2.6.6.tar.bz2</div><div class="line">$ cd Python-2.6.6</div><div class="line">$ ./configure</div><div class="line">$ make</div><div class="line">$ make install</div><div class="line"></div><div class="line"># 测试Python</div><div class="line">$ python -V</div><div class="line">Python 2.6.6</div></pre></td></tr></table></figure>
<h3 id="下载Storm"><a href="#下载Storm" class="headerlink" title="下载Storm"></a>下载Storm</h3><p>在Storm的GitHub中选择一个Storm版本下载安装，这里我选择的0.10.2版本</p>
<ul>
<li><a href="http://storm.apache.org/downloads.html" target="_blank" rel="external">http://storm.apache.org/downloads.html</a></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"># 下载Storm安装包</div><div class="line">$ curl -O http://apache.fayea.com/storm/apache-storm-0.10.2/apache-storm-0.10.2.tar.gz</div><div class="line"></div><div class="line"># 解压Storm压缩包</div><div class="line">$ tar -xvf apache-storm-0.10.2.tar</div></pre></td></tr></table></figure>
<h3 id="修改storm-yaml配置文件"><a href="#修改storm-yaml配置文件" class="headerlink" title="修改storm.yaml配置文件"></a>修改storm.yaml配置文件</h3><p>Storm启动会加载conf/storm.yaml配置文件，该配置文件会覆盖掉defaults.yaml配置文件中的配置。下面介绍少部分重要的配置</p>
<ul>
<li>storm.zookeeper.servers : Storm依赖的Zookeeper集群地址</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">storm.zookeeper.servers:</div><div class="line">  - &quot;111.222.333.444&quot;</div><div class="line">  - &quot;555.666.777.888&quot;</div></pre></td></tr></table></figure>
<p>如果Zookeeper集群使用的不是默认的端口号，可以通过storm.zookeeper.port配置来修改，否则会出现通信错误。</p>
<ul>
<li>storm.local.dir : Nimbus和Supervisor进程用于存储少量状态，如jars、confs等的本地磁盘目录，需要提前创建该目录并给以足够的访问权限。需要在每个Storm机器中都创建这样一个目录。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">storm.local.dir: &quot;/mnt/storm&quot;</div></pre></td></tr></table></figure>
<p>也可以使用相对路径，相对于$STORM_HOME（即Storm的安装路径），如果不设置该配置就是用默认目录$STORM_HOME/storm-local</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">storm.local.dir: $STORM_HOME/storm-local</div></pre></td></tr></table></figure>
<ul>
<li>nimbus.seeds : Storm集群Nimbus机器地址，各个Supervisor工作节点需要知道哪个机器是Nimbus，以便下载Topologies的jars、confs等文件。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">nimbus.seeds: [&quot;111.222.333.44&quot;]</div></pre></td></tr></table></figure>
<p>这里推荐使用机器的hostname，如果你想设置Nimbus的HA高可用，你必须设置每个正在运行的Nimbus的hostname。如果是假的分布式集群，可以使用默认值，但是建议设置Nimbus的hostname。</p>
<ul>
<li>supervisor.slots.ports : 对于每个Supervisor工作节点，需要配置该工作节点可以运行的worker数量。每个worker占用一个单独的端口用于接收消息，该配置选项即用于定义哪些端口是可被worker使用的。默认情况下，每个节点上可运行4个workers，分别在6700、6701、6702和6703端口</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">supervisor.slots.ports:</div><div class="line">    - 6700</div><div class="line">    - 6701</div><div class="line">    - 6702</div><div class="line">    - 6703</div></pre></td></tr></table></figure>
<h3 id="健康检查（下面这段翻译的不够准确，仅供参考）"><a href="#健康检查（下面这段翻译的不够准确，仅供参考）" class="headerlink" title="健康检查（下面这段翻译的不够准确，仅供参考）"></a>健康检查（下面这段翻译的不够准确，仅供参考）</h3><p>Storm提供一种机制 —— 管理者可以配置一个监控者周期的执行管理者提供的脚本，检查node节点是否健康。管理者有决定node节点在健康状态。如果一个脚本查明node节点处于非健康状态，必须打印以ERROR开头标准化输出错误。监控者周期的执行脚本在storm.health.check.dir并且检查输出结果。如果脚本的输出结果包括ERROR，监控者将会关闭worker。</p>
<p>如果监控者正在运行与监控”/bin/storm node-health-check”可以被调用，以确定监控者是否被启动，或者该node节点是否是不健康的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"># 健康检查的目录配置如下</div><div class="line">storm.health.check.dir: &quot;healthchecks&quot;</div><div class="line"># 健康检查等待超时时间配置</div><div class="line">storm.health.check.timeout.ms: 5000</div></pre></td></tr></table></figure>
<h3 id="配置外部依赖库和环境变量（可选）"><a href="#配置外部依赖库和环境变量（可选）" class="headerlink" title="配置外部依赖库和环境变量（可选）"></a>配置外部依赖库和环境变量（可选）</h3><p>如果你需要支持外部依赖库或者自定义插件，你可以定位这些jar到extlib和extlib-daemon目录下。注意extlib-daemon目录存储的jar只被用于daemons启动(Nimbus, Supervisor, DRPC, UI, Logviewer)，如，HDFS和自定义的定时任务库。因此STORM_EXT_CLASSPATH和STORM_EXT_CLASSPATH_DAEMON这两个环境变量都需要被配置，为了外部依赖classpath和后台启动的外部依赖classpath。</p>
<h3 id="启动Storm后台进程"><a href="#启动Storm后台进程" class="headerlink" title="启动Storm后台进程"></a>启动Storm后台进程</h3><p>最后一步就是启动Storm的后台进程，很关键的一点这些后台进程都在监控下。Storm是快速失败（fail-fast)，意味着无论什么时候发生错误，进程都会停止。Storm被设计成这样可以在任何点安全的停止，并且当进程重启时可以正确的被恢复。这也是说明Storm为什么是无状态的系统。如果Nimbus或者Supervisors重启，正在运行的topologies不会受到影响。</p>
<p>下面是如何启动Storm的后台进程</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Nimbus: Run the command &quot;bin/storm nimbus&quot; under supervision on the master machine.</div><div class="line"></div><div class="line">Supervisor: Run the command &quot;bin/storm supervisor&quot; under supervision on each worker machine. The supervisor daemon is responsible for starting and stopping worker processes on that machine.</div><div class="line"></div><div class="line">UI: Run the Storm UI (a site you can access from the browser that gives diagnostics on the cluster and topologies) by running the command &quot;bin/storm ui&quot; under supervision. The UI can be accessed by navigating your web browser to http://&#123;ui host&#125;:8080.</div></pre></td></tr></table></figure>
<p>Storm后台进程被启动后，将在Storm安装部署目录下的logs/子目录下生成各个进程的日志文件</p>
<p>以上是翻译自Storm的官网，接下来是针对于我自己的Storm集群的配置过程</p>
<h3 id="Storm集群搭建步骤"><a href="#Storm集群搭建步骤" class="headerlink" title="Storm集群搭建步骤"></a>Storm集群搭建步骤</h3><p>修改storm.yaml配置如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">storm.zookeeper.servers:    - &quot;hadoop2&quot;    - &quot;hadoop3&quot;nimbus.host: &quot;hadoop1&quot;</div></pre></td></tr></table></figure>
<p>注意：这里hadoop1, hadoop2, hadoop3是我之前安装Hadoop集群环境对应的三台机器的hostname，需要根据个人实际环境进行修改。这里我将hadoop1这台机器作为Nimbus，hadoop2和hadoop3这两台机器作为Supervisor。其他配置都使用默认的配置。</p>
<p>启动Nimbus</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ bin/storm nimbusRunning: /usr/local/java/bin/java -server -Ddaemon.name=nimbus -Dstorm.options= -Dstorm.home=/data/storm-0.10.2 -Dstorm.log.dir=/data/storm-0.10.2/logs -Djava.library.path=/usr/local/lib:/opt/local/lib:/usr/lib -Dstorm.conf.file= -cp /data/storm-0.10.2/lib/storm-core-0.10.2.jar:/data/storm-0.10.2/lib/slf4j-api-1.7.7.jar:/data/storm-0.10.2/lib/clojure-1.6.0.jar:/data/storm-0.10.2/lib/disruptor-2.10.4.jar:/data/storm-0.10.2/lib/servlet-api-2.5.jar:/data/storm-0.10.2/lib/log4j-api-2.1.jar:/data/storm-0.10.2/lib/log4j-core-2.1.jar:/data/storm-0.10.2/lib/minlog-1.2.jar:/data/storm-0.10.2/lib/reflectasm-1.07-shaded.jar:/data/storm-0.10.2/lib/log4j-over-slf4j-1.6.6.jar:/data/storm-0.10.2/lib/asm-4.0.jar:/data/storm-0.10.2/lib/hadoop-auth-2.4.0.jar:/data/storm-0.10.2/lib/kryo-2.21.jar:/data/storm-0.10.2/lib/log4j-slf4j-impl-2.1.jar:/data/storm-0.10.2/conf -Xmx1024m -Dlogfile.name=nimbus.log -Dlog4j.configurationFile=/data/storm-0.10.2/log4j2/cluster.xml backtype.storm.daemon.nimbus</div></pre></td></tr></table></figure>
<p>启动Supervisor</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ bin/storm supervisorRunning: /usr/local/java/bin/java -server -Ddaemon.name=supervisor -Dstorm.options= -Dstorm.home=/data/storm-0.10.2 -Dstorm.log.dir=/data/storm-0.10.2/logs -Djava.library.path=/usr/local/lib:/opt/local/lib:/usr/lib -Dstorm.conf.file= -cp /data/storm-0.10.2/lib/asm-4.0.jar:/data/storm-0.10.2/lib/servlet-api-2.5.jar:/data/storm-0.10.2/lib/slf4j-api-1.7.7.jar:/data/storm-0.10.2/lib/reflectasm-1.07-shaded.jar:/data/storm-0.10.2/lib/clojure-1.6.0.jar:/data/storm-0.10.2/lib/hadoop-auth-2.4.0.jar:/data/storm-0.10.2/lib/log4j-api-2.1.jar:/data/storm-0.10.2/lib/log4j-slf4j-impl-2.1.jar:/data/storm-0.10.2/lib/storm-core-0.10.2.jar:/data/storm-0.10.2/lib/log4j-over-slf4j-1.6.6.jar:/data/storm-0.10.2/lib/kryo-2.21.jar:/data/storm-0.10.2/lib/minlog-1.2.jar:/data/storm-0.10.2/lib/log4j-core-2.1.jar:/data/storm-0.10.2/lib/disruptor-2.10.4.jar:/data/storm-0.10.2/conf -Xmx256m -Dlogfile.name=supervisor.log -Dlog4j.configurationFile=/data/storm-0.10.2/log4j2/cluster.xml backtype.storm.daemon.supervisor</div></pre></td></tr></table></figure>
<p>启动UI</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ bin/storm uiRunning: /usr/local/java/bin/java -server -Ddaemon.name=ui -Dstorm.options= -Dstorm.home=/data/storm-0.10.2 -Dstorm.log.dir=/data/storm-0.10.2/logs -Djava.library.path=/usr/local/lib:/opt/local/lib:/usr/lib -Dstorm.conf.file= -cp /data/storm-0.10.2/lib/storm-core-0.10.2.jar:/data/storm-0.10.2/lib/slf4j-api-1.7.7.jar:/data/storm-0.10.2/lib/clojure-1.6.0.jar:/data/storm-0.10.2/lib/disruptor-2.10.4.jar:/data/storm-0.10.2/lib/servlet-api-2.5.jar:/data/storm-0.10.2/lib/log4j-api-2.1.jar:/data/storm-0.10.2/lib/log4j-core-2.1.jar:/data/storm-0.10.2/lib/minlog-1.2.jar:/data/storm-0.10.2/lib/reflectasm-1.07-shaded.jar:/data/storm-0.10.2/lib/log4j-over-slf4j-1.6.6.jar:/data/storm-0.10.2/lib/asm-4.0.jar:/data/storm-0.10.2/lib/hadoop-auth-2.4.0.jar:/data/storm-0.10.2/lib/kryo-2.21.jar:/data/storm-0.10.2/lib/log4j-slf4j-impl-2.1.jar:/data/storm-0.10.2:/data/storm-0.10.2/conf -Xmx768m -Dlogfile.name=ui.log -Dlog4j.configurationFile=/data/storm-0.10.2/log4j2/cluster.xml backtype.storm.ui.core</div></pre></td></tr></table></figure>
<p>启动成功之后访问<a href="http://hadoop1:8080，效果图如下" target="_blank" rel="external">http://hadoop1:8080，效果图如下</a></p>
<p><img src="http://img.blog.csdn.net/20161107192753473?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="Storm UI"></p>
<p>参考文章：</p>
<ul>
<li><a href="http://storm.apache.org/releases/0.10.2/Setting-up-a-Storm-cluster.html" target="_blank" rel="external">http://storm.apache.org/releases/0.10.2/Setting-up-a-Storm-cluster.html</a></li>
</ul>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Storm/">Storm</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Storm/">Storm</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Docker/Docker实战（二十二）Docker-Compose部署Zookeeper集群环境" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/11/04/Docker/Docker实战（二十二）Docker-Compose部署Zookeeper集群环境/" class="article-date">
  	<time datetime="2016-11-04T07:27:19.000Z" itemprop="datePublished">2016-11-04</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/11/04/Docker/Docker实战（二十二）Docker-Compose部署Zookeeper集群环境/">Docker实战（二十二）Docker-Compose部署Zookeeper集群环境</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>本篇我们具体使用Docker-Compose来部署Zookeeper集群环境，这里我们使用Zookeeper官方提供的Docker镜像来搭建集群环境，官方的镜像地址：<a href="https://hub.docker.com/_/zookeeper/" target="_blank" rel="external">https://hub.docker.com/_/zookeeper/</a></p>
<h4 id="下载Zookeeper官方的Docker镜像"><a href="#下载Zookeeper官方的Docker镜像" class="headerlink" title="下载Zookeeper官方的Docker镜像"></a>下载Zookeeper官方的Docker镜像</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ docker pull zookeeper:latest</div></pre></td></tr></table></figure>
<h4 id="zoo-cfg配置文件"><a href="#zoo-cfg配置文件" class="headerlink" title="zoo.cfg配置文件"></a>zoo.cfg配置文件</h4><p>这里我们将部署三台Docker容器组成一个Zookeeper集群，然后我们在本地创建一个zoo.cfg配置文件，指定好Zookeeper集群的配置，zk1，zk2，zk3分别是三台Zookeeper服务器的host名称</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">tickTime=2000</div><div class="line">initLimit=10</div><div class="line">syncLimit=5</div><div class="line">dataDir=/opt/data</div><div class="line">clientPort=2181</div><div class="line">dataLogDir=/opt/log</div></pre></td></tr></table></figure>
<h4 id="docker-compose-yml配置文件"><a href="#docker-compose-yml配置文件" class="headerlink" title="docker-compose.yml配置文件"></a>docker-compose.yml配置文件</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div></pre></td><td class="code"><pre><div class="line">version: &apos;2&apos;</div><div class="line">services:</div><div class="line">   zoo1:</div><div class="line">      # 指定当前构建的Docker容器的镜像</div><div class="line">      image: zookeeper</div><div class="line">      restart: always</div><div class="line">      # 指定当前构建的Docker容器的名称</div><div class="line">      container_name: zk1</div><div class="line">      networks:</div><div class="line">         zoo_net:</div><div class="line">            # 指定当前构建的Docker容器的IP地址</div><div class="line">            ipv4_address: 172.18.0.2</div><div class="line">      # 指定当前构建的Docker容器的host配置</div><div class="line">      extra_hosts:</div><div class="line">         - &quot;zoo1:172.18.0.2&quot;</div><div class="line">         - &quot;zoo2:172.18.0.3&quot;</div><div class="line">         - &quot;zoo3:172.18.0.4&quot;</div><div class="line">      # 指定当前构建的Docker容器的volume挂在目录设置</div><div class="line">      volumes:</div><div class="line">         - ~/Downloads/yunyu/zookeeper_docker/data/zoo1:/opt/data</div><div class="line">         - ~/Downloads/yunyu/zookeeper_docker/logs/zoo1:/opt/log</div><div class="line">      # 指定当前构建的Docker容器对外开放的端口号映射</div><div class="line">      ports:</div><div class="line">         - &quot;2181:2181&quot;</div><div class="line">         - &quot;2881:2888&quot;</div><div class="line">         - &quot;3881:3888&quot;</div><div class="line">      # 指定当前构建的Docker容器环境变量设置</div><div class="line">      environment:</div><div class="line">         ZOO_MY_ID: 1</div><div class="line">         ZOO_SERVERS: server.1=zoo1:2881:3881 server.2=zoo2:2882:3882 server.3=zoo3:2883:3883</div><div class="line"></div><div class="line">   zoo2:</div><div class="line">      image: zookeeper</div><div class="line">      restart: always</div><div class="line">      container_name: zk2</div><div class="line">      networks:</div><div class="line">         zoo_net:</div><div class="line">            ipv4_address: 172.18.0.3</div><div class="line">      extra_hosts:</div><div class="line">         - &quot;zoo1:172.18.0.2&quot;</div><div class="line">         - &quot;zoo2:172.18.0.3&quot;</div><div class="line">         - &quot;zoo3:172.18.0.4&quot;</div><div class="line">      volumes:</div><div class="line">         - ~/Downloads/yunyu/zookeeper_docker/data/zoo2:/opt/data</div><div class="line">         - ~/Downloads/yunyu/zookeeper_docker/logs/zoo2:/opt/log</div><div class="line">      ports:</div><div class="line">         - &quot;2182:2181&quot;</div><div class="line">         - &quot;2882:2888&quot;</div><div class="line">         - &quot;3882:3888&quot;</div><div class="line">      environment:</div><div class="line">         ZOO_MY_ID: 2</div><div class="line">         ZOO_SERVERS: server.1=zoo1:2881:3881 server.2=zoo2:2882:3882 server.3=zoo3:2883:3883</div><div class="line"></div><div class="line">   zoo3:</div><div class="line">      image: zookeeper</div><div class="line">      restart: always</div><div class="line">      container_name: zk3</div><div class="line">      networks:</div><div class="line">         zoo_net:</div><div class="line">            ipv4_address: 172.18.0.4</div><div class="line">      extra_hosts:</div><div class="line">         - &quot;zoo1:172.18.0.2&quot;</div><div class="line">         - &quot;zoo2:172.18.0.3&quot;</div><div class="line">         - &quot;zoo3:172.18.0.4&quot;</div><div class="line">      volumes:</div><div class="line">         - ~/Downloads/yunyu/zookeeper_docker/data/zoo3:/opt/data</div><div class="line">         - ~/Downloads/yunyu/zookeeper_docker/logs/zoo3:/opt/log</div><div class="line">      ports:</div><div class="line">         - &quot;2183:2181&quot;</div><div class="line">         - &quot;2883:2888&quot;</div><div class="line">         - &quot;3883:3888&quot;</div><div class="line">      environment:</div><div class="line">         ZOO_MY_ID: 3</div><div class="line">         ZOO_SERVERS: server.1=zoo1:2881:3881 server.2=zoo2:2882:3882 server.3=zoo3:2883:3883</div><div class="line"></div><div class="line">networks:</div><div class="line">  zoo_net:</div><div class="line">    driver: bridge</div><div class="line">    ipam:</div><div class="line">      driver: default</div><div class="line">      config:</div><div class="line">      - subnet: 172.18.0.0/16</div><div class="line">        gateway: 172.18.0.1</div></pre></td></tr></table></figure>
<p>这里需要注意几点</p>
<ol>
<li>因为我们是单机部署了多个Docker容器模拟Zookeeper集群的，所以需要做端口映射2181，2888，3888。需要将2888和3888端口也暴露出来，因为如果不暴露出来一旦leader几点挂了，其他follower无法再次进行选举，因为选举是通过3888端口进行的</li>
<li>这里我们指定好了Docker容器的IP地址，这样不会动态的去获取IP地址导致每次启动Docker容器IP地址都会变化</li>
<li>需要设置/etc/hosts配置文件中的host配置</li>
<li>将Docker容器中的/opt/data和/opt/log目录挂在到宿主机的指定目录下</li>
<li>设置了一个网卡zoo_net，网段是172.18.0.0，网关是172.18.0.1</li>
<li>Docker-Compose的version 2版本语法有些变化，注意检查一下networks的配置，否则启动docker-compose up会无法启动</li>
</ol>
<h4 id="启动Docker-Compose"><a href="#启动Docker-Compose" class="headerlink" title="启动Docker-Compose"></a>启动Docker-Compose</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"># 启动Docker-Compose后，会自动创建Docker容器并且启动</div><div class="line">$ docker-compose up</div><div class="line"></div><div class="line"># 查看当前正在运行的Docker容器</div><div class="line">$ docker-compose ps</div><div class="line">Name              Command               State                                   Ports</div><div class="line">----------------------------------------------------------------------------------------------------------------------</div><div class="line">zk1    /docker-entrypoint.sh zkSe ...   Up      0.0.0.0:2181-&gt;2181/tcp, 0.0.0.0:2881-&gt;2888/tcp, 0.0.0.0:3881-&gt;3888/tcp</div><div class="line">zk2    /docker-entrypoint.sh zkSe ...   Up      0.0.0.0:2182-&gt;2181/tcp, 0.0.0.0:2882-&gt;2888/tcp, 0.0.0.0:3882-&gt;3888/tcp</div><div class="line">zk3    /docker-entrypoint.sh zkSe ...   Up      0.0.0.0:2183-&gt;2181/tcp, 0.0.0.0:2883-&gt;2888/tcp, 0.0.0.0:3883-&gt;3888/tcp</div></pre></td></tr></table></figure>
<h4 id="验证Zookeeper集群的可用性"><a href="#验证Zookeeper集群的可用性" class="headerlink" title="验证Zookeeper集群的可用性"></a>验证Zookeeper集群的可用性</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"># 分别进入到正在运行的三个Docker容器中</div><div class="line">$ docker exec -it 486110828ff1 /bin/bash</div><div class="line"></div><div class="line"># 进入Zookeeper的安装目录，这里要参考Zookeeper官方的Dockerfile文件配置</div><div class="line">$ cd /zookeeper-3.4.9/bin</div><div class="line"></div><div class="line"># 检查Zookeeper的状态（三个Docker容器的状态都不一样，只有一个leader，另外两个是follower）</div><div class="line">$ zkServer.sh status</div><div class="line">ZooKeeper JMX enabled by default</div><div class="line">Using config: /conf/zoo.cfg</div><div class="line">Mode: follower</div><div class="line"></div><div class="line"># 分别监听三个Docker容器的2181端口情况，都是正在监听状态</div><div class="line">$ netstat -anp | grep 2181</div><div class="line">tcp        0      0 :::2181                 :::*                    LISTEN      -</div><div class="line"></div><div class="line"># 然后通过宿主机检查2181, 2182, 2183三个端口（这里连接的是2182端口）</div><div class="line">$ telnet 10.10.1.66 2182</div><div class="line">Trying 10.10.1.66...</div><div class="line">Connected to localhost.</div><div class="line">Escape character is &apos;^]&apos;.</div><div class="line"></div><div class="line"># telnet能够连接说明2182端口，同时检查对应2182端口的Docker容器会创建一个TCP连接如下，说明连接都正常了</div><div class="line">$ netstat -anp | grep 2181</div><div class="line">tcp        0      0 :::2181                 :::*                    LISTEN      -</div><div class="line">tcp        0      0 ::ffff:172.18.0.3:2181  ::ffff:172.18.0.1:48996 ESTABLISHED -</div><div class="line"></div><div class="line"># 检查重新Zookeeper的重新选举功能</div><div class="line"># 停止leader的Docker容器</div><div class="line">$ docker stop 486110828ff1</div><div class="line"></div><div class="line"># 再分别查看另外两个Docker容器的Zookeeper服务状态，其中一个会被选举成leader，另外一个还是follower</div><div class="line">$ zkServer.sh status</div><div class="line">ZooKeeper JMX enabled by default</div><div class="line">Using config: /conf/zoo.cfg</div><div class="line">Mode: leader</div></pre></td></tr></table></figure>
<p>到此为止，我们的使用Zookeeper官方Docker镜像搭建Zookeeper集群已经完成了</p>
<p>参考文章：</p>
<ul>
<li><a href="https://docs.docker.com/compose/compose-file/#/network-configuration-reference" target="_blank" rel="external">https://docs.docker.com/compose/compose-file/#/network-configuration-reference</a></li>
<li><a href="https://docs.docker.com/compose/networking/" target="_blank" rel="external">https://docs.docker.com/compose/networking/</a></li>
<li><a href="https://hub.docker.com/_/zookeeper/" target="_blank" rel="external">https://hub.docker.com/_/zookeeper/</a></li>
<li><a href="https://github.com/31z4/zookeeper-docker/blob/7e7eac6d6c11428849ec13bb7d240e4cfa21b2e7/3.4.9/Dockerfile">https://github.com/31z4/zookeeper-docker/blob/7e7eac6d6c11428849ec13bb7d240e4cfa21b2e7/3.4.9/Dockerfile</a></li>
<li><a href="https://github.com/31z4/zookeeper-docker/tree/7e7eac6d6c11428849ec13bb7d240e4cfa21b2e7">https://github.com/31z4/zookeeper-docker/tree/7e7eac6d6c11428849ec13bb7d240e4cfa21b2e7</a></li>
<li><a href="http://blog.csdn.net/cuisongliu/article/details/51817203" target="_blank" rel="external">http://blog.csdn.net/cuisongliu/article/details/51817203</a></li>
</ul>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Docker环境/">Docker环境</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Docker/">Docker</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Docker/Docker实战（二十一）Docker-Compose安装和使用" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/11/04/Docker/Docker实战（二十一）Docker-Compose安装和使用/" class="article-date">
  	<time datetime="2016-11-04T02:44:23.000Z" itemprop="datePublished">2016-11-04</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/11/04/Docker/Docker实战（二十一）Docker-Compose安装和使用/">Docker实战（二十一）Docker-Compose安装和使用</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>最近决定使用官方的Zookeeper的Docker镜像搭建Zookeeper集群环境，在DockerHub官网中找到了Zookeeper官方的镜像地址：<a href="https://hub.docker.com/_/zookeeper/，发现官方推荐可以使用Docker-Compose工具来同时启动多个配置好的Zookeeper的Docker容器，用起来十分方便。" target="_blank" rel="external">https://hub.docker.com/_/zookeeper/，发现官方推荐可以使用Docker-Compose工具来同时启动多个配置好的Zookeeper的Docker容器，用起来十分方便。</a></p>
<h4 id="安装环境"><a href="#安装环境" class="headerlink" title="安装环境"></a>安装环境</h4><ul>
<li>我本地的环境是 : MacOS</li>
<li>公司测试环境是 : Ubuntu</li>
</ul>
<h4 id="Docker-Compose安装"><a href="#Docker-Compose安装" class="headerlink" title="Docker-Compose安装"></a>Docker-Compose安装</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"># 注意这里要安装比较高的版本，否则在使用docker-compose.yml配置文件的时候，新老版本的docker-compose.yml配置文件的语法略有不同，我这里安装的1.8.1版本</div><div class="line">$ curl -L https://github.com/docker/compose/releases/download/1.8.1/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose </div><div class="line">$ chmod +x /usr/local/bin/docker-compose</div><div class="line"></div><div class="line"># 安装完成之后，检查Docker-Compose版本</div><div class="line">$ docker-compose version</div><div class="line">docker-compose version 1.8.1, build 878cff1</div><div class="line">docker-py version: 1.10.3</div><div class="line">CPython version: 2.7.9</div><div class="line">OpenSSL version: OpenSSL 1.0.2h  3 May 2016</div><div class="line"></div><div class="line"># 卸载也很方便，直接执行下面的命令即可</div><div class="line">$ rm /usr/local/bin/docker-compose</div></pre></td></tr></table></figure>
<h4 id="Docker-Compose用法"><a href="#Docker-Compose用法" class="headerlink" title="Docker-Compose用法"></a>Docker-Compose用法</h4><p>基本步骤如下：</p>
<ul>
<li>创建一个docker-compose.yml配置文件</li>
<li>docker-compose up启动Docker容器</li>
<li>docker-compose ps查看Docker容器运行状态</li>
</ul>
<h4 id="Docker-Compose命令用法"><a href="#Docker-Compose命令用法" class="headerlink" title="Docker-Compose命令用法"></a>Docker-Compose命令用法</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"># 命令</div><div class="line">build : 创建或者再建服务。服务被创建后会标记为project_service(比如composetest_db)，如果改变了一个服务的Dockerfile或者构建目录的内容，可以使用docker-compose build来重建它</div><div class="line">help : 显示命令的帮助和使用信息</div><div class="line">kill : 通过发送SIGKILL的信号强制停止运行的容器，这个信号可以选择性的通过，比如：docker-compose kill -s SIGKINT</div><div class="line">logs : 显示服务的日志输出</div><div class="line">port : 为端口绑定输出公共信息</div><div class="line">ps : 显示容器</div><div class="line">pull : 拉取服务镜像</div><div class="line">rm : 删除停止的容器</div><div class="line">run : 在服务上运行一个一次性命令，比如：docker-compose run web Python manage.py shell</div><div class="line">scale : 设置为一个服务启动的容器数量，数量是以这样的参数形式指定的：service=num，比如：docker-compose scale web=2 worker=3</div><div class="line">start : 启动已经存在的容器作为一个服务</div><div class="line">stop : 停止运行的容器而不删除它们，它们可以使用命令docker-compose start重新启动起来</div><div class="line">up : 为一个服务构建、创建、启动、附加到容器。连接的服务会被启动，除非它们已经在运行了。默认情况下，docker-compose up会集中每个容器的输出，当存在时，所有的容器会停止，运行docker-compose up -d会在后台启动容器并使它们运行。</div><div class="line">默认情况下，如果服务存在容器的话，docker-compose up会停止并再创建它们（使用了volumes-from会保留已挂载的卷），如果不想使容器停止并再创建的话，使用docker-compose up --no-recreate，如果有需要的话，这会启动任何停止的容器</div><div class="line"></div><div class="line"># 选项</div><div class="line">–verbose : 显示更多输出</div><div class="line">–version : 显示版本号并退出</div><div class="line">-f,–file FILE : 指定一个可选的Compose yaml文件（默认：docker-compose.yml）</div><div class="line">-p,–project-name NAME : 指定可选的项目名称（默认：当前目录名称）</div></pre></td></tr></table></figure>
<h4 id="docker-compose-yml配置文件用法"><a href="#docker-compose-yml配置文件用法" class="headerlink" title="docker-compose.yml配置文件用法"></a>docker-compose.yml配置文件用法</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"># Service配置 : 主要是配置Docker服务的详情信息（一个Service可以理解为一套Docker容器服务）</div><div class="line"># 这里简单介绍一下我理解的配置用法</div><div class="line">image : 指定Docker镜像名称</div><div class="line">container_name : 创建出来的Docker容器名称</div><div class="line">networks : 设置网路配置</div><div class="line">extra_hosts : 设置/etc/hosts文件配置</div><div class="line">volumes : 设置挂在目录配置</div><div class="line">ports : 设置Docker容器对外开放的端口号映射</div><div class="line">expose : 设置Docker容器内部使用的端口号</div><div class="line">environment : 环境变量设置</div><div class="line"></div><div class="line"># Network配置 : 主要配置Docker容器的网络信息</div><div class="line">driver : 配置网卡类型（bridge, none, host三种类型）</div><div class="line"></div><div class="line"># Version配置 : 主要指定Docker-Compose配置文件的版本，这里指定使用Version 2版本</div><div class="line">verison: &apos;2&apos;</div><div class="line"></div><div class="line"># 注意：Version 2 files are supported by Compose 1.6.0+ and require a Docker Engine of version 1.10.0+.</div></pre></td></tr></table></figure>
<p>因为我也是刚开始使用，所以并不是很熟悉，这里docker-compose.yml配置文件的用法具体请参考官网的说明。下一篇我们会以Docker-Compose来管理Zookeepr官方的Docker容器</p>
<ul>
<li><a href="https://docs.docker.com/compose/compose-file/#/network-configuration-reference" target="_blank" rel="external">https://docs.docker.com/compose/compose-file/#/network-configuration-reference</a></li>
</ul>
<p>参考文章：</p>
<ul>
<li><a href="https://docs.docker.com/compose/install/" target="_blank" rel="external">https://docs.docker.com/compose/install/</a></li>
<li><a href="https://docs.docker.com/compose/compose-file/#/network-configuration-reference" target="_blank" rel="external">https://docs.docker.com/compose/compose-file/#/network-configuration-reference</a></li>
<li><a href="https://docs.docker.com/compose/networking/" target="_blank" rel="external">https://docs.docker.com/compose/networking/</a></li>
<li><a href="http://blog.csdn.net/zhiaini06/article/details/45287663" target="_blank" rel="external">http://blog.csdn.net/zhiaini06/article/details/45287663</a></li>
</ul>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Docker环境/">Docker环境</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Docker/">Docker</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Shell/Shell脚本学习（八）调试Shell脚本" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/11/02/Shell/Shell脚本学习（八）调试Shell脚本/" class="article-date">
  	<time datetime="2016-11-02T10:30:13.000Z" itemprop="datePublished">2016-11-02</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/11/02/Shell/Shell脚本学习（八）调试Shell脚本/">Shell脚本学习（八）调试Shell脚本</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>最近在在使用Jenkins做自动化部署的时候，仔细观察了一下Jenkins中执行Shell时会将每条Shell语句输出到控制台日志，这样调试起来Shell脚本非常方便</p>
<p>Jenkins的Shell执行方式</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[birdben] $ /bin/sh -xe /tmp/hudson168932309618552744.sh</div><div class="line">+ echo &apos;execute shell&apos;</div><div class="line">execute shell</div><div class="line">....</div></pre></td></tr></table></figure>
<p>实际上Jenkins执行Shell的方式只是多加了两个参数-xe</p>
<ul>
<li>-x : 跟踪调试Shell脚本</li>
<li>-e : 表示一旦出错，就退出当前的Shell</li>
</ul>
<p>“-x”选项可用来跟踪脚本的执行，是调试Shell脚本的强有力工具。”-x”选项使Shell在执行脚本的过程中把它实际执行的每一个命令行显示出来，并且在行首显示一个”+”号。”+”号后面显示的是经过了变量替换之后的命令行的内容，有助于分析实际执行的是什么命令。”-x”选项使用起来简单方便，可以轻松对付大多数的Shell调试任务,应把其当作首选的调试手段。</p>
<p>有的时候我们可能不希望输出全部的Shell命令，我们可以在Shell脚本中使用set设置需要跟踪的程序段，用下面的方式对需要调试的程序段进行跟踪，其他不在该程序段的命令不会被输出。</p>
<h5 id="Shell脚本模板"><a href="#Shell脚本模板" class="headerlink" title="Shell脚本模板"></a>Shell脚本模板</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">set -x　　　 # 启动&quot;-x&quot;选项</div><div class="line">要跟踪的程序段</div><div class="line">set +x　　　 # 关闭&quot;-x&quot;选项</div></pre></td></tr></table></figure>
<h5 id="Shell脚本例子"><a href="#Shell脚本例子" class="headerlink" title="Shell脚本例子"></a>Shell脚本例子</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">#!bin/bash</div><div class="line">docker ps -a</div><div class="line"></div><div class="line">set -x</div><div class="line">docker images</div><div class="line">set +x</div><div class="line"></div><div class="line">docker version</div></pre></td></tr></table></figure>
<h5 id="执行Shell的结果"><a href="#执行Shell的结果" class="headerlink" title="执行Shell的结果"></a>执行Shell的结果</h5><p>这里我们执行Shell脚本并没有带-x参数，但是可以看到docker ps -a和docker -version这两行Shell命令都没有输出，只有set语句中间的docker image命令输出了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">$ sh aa.sh</div><div class="line">CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES</div><div class="line">+ docker images</div><div class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</div><div class="line">birdben/jdk8        v1                  36fd8962f92c        10 months ago       656 MB</div><div class="line">+ set +x</div><div class="line">Client:</div><div class="line"> Version:      1.12.1</div><div class="line"> API version:  1.24</div><div class="line"> Go version:   go1.7.1</div><div class="line"> Git commit:   6f9534c</div><div class="line"> Built:        Thu Sep  8 10:31:18 2016</div><div class="line"> OS/Arch:      darwin/amd64</div><div class="line"></div><div class="line">Server:</div><div class="line"> Version:      1.12.1</div><div class="line"> API version:  1.24</div><div class="line"> Go version:   go1.6.3</div><div class="line"> Git commit:   23cf638</div><div class="line"> Built:        Thu Aug 18 17:52:38 2016</div><div class="line"> OS/Arch:      linux/amd64</div></pre></td></tr></table></figure>
      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Shell/">Shell</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Shell/">Shell</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Others/Jenkis + Git + Maven + Docker自动化部署" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/10/30/Others/Jenkis + Git + Maven + Docker自动化部署/" class="article-date">
  	<time datetime="2016-10-30T03:46:27.000Z" itemprop="datePublished">2016-10-30</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/10/30/Others/Jenkis + Git + Maven + Docker自动化部署/">Jenkis + Git + Maven + Docker自动化部署</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="Jenkins-Git-Maven-Docker自动化部署环境"><a href="#Jenkins-Git-Maven-Docker自动化部署环境" class="headerlink" title="Jenkins + Git + Maven + Docker自动化部署环境"></a>Jenkins + Git + Maven + Docker自动化部署环境</h3><p>最近公司使用了Docker做私有化部署，所以现在将各个Git分支上的代码重新打包部署到Docker容器非常的麻烦，需要自己写很多Shell脚本，并且没有统一的部署步骤和标准。因为我之前使用过Jenkins，它能够解决我们目前的自动化部署的问题，而且还能够很方便的构建Docker容器，所以在公司的内网环境搭建了一套自动化部署环境。</p>
<h3 id="环境选型"><a href="#环境选型" class="headerlink" title="环境选型"></a>环境选型</h3><p>这里我们有几个选择如何构建我们的自动化部署环境，可以使用官方的Jenkins的Docker镜像也和可以自己安装Jenkins环境。因为Jenkins只是负责集成Maven，所以官方的Jenkins的Docker镜像并不提供相应的Maven环境，所以我们需要权衡下面的几种解决方案：</p>
<ul>
<li>方案一：在测试服务器使用官方的Jenkins的Docker镜像，使用Jenkins内置的Maven<ul>
<li>优点：使用官方的Jenkins的Docker镜像能够快速安装Jenkins环境</li>
<li>缺点：使用Jenkins自动安装的Maven环境，貌似不是很好用（这里我没有安装成功所以不是很推荐使用）</li>
</ul>
</li>
<li>方案二：在测试服务器使用官方的Jenkins的Docker镜像，继承Jenkins的Docker容器重新构建一个自己定制化好的Docker容器<ul>
<li>优点：能够按照自己的需求定制化安装Docker容器，可以定制化安装好所需要的环境</li>
<li>缺点：需要自己重新编写Dockerfile构建镜像，要求会使用Docker复杂度稍高</li>
</ul>
</li>
<li>方案三：在测试服务器直接安装Jenkins环境，使用Jenkins集成外置的Maven环境<ul>
<li>优点：可以在测试服务器进行定制化安装，并使用Jenkins进行整合</li>
<li>缺点：需要在测试服务器维护Jenkins环境</li>
</ul>
</li>
</ul>
<p>这里我选择了方案三，主要原因是因为前两种使用官方Docker镜像做项目打包部署没有任何问题，但是我们需要将我们打包好的项目重新生成Docker容器并运行，如果是使用官方的Jenkins的Docker镜像，需要在该镜像内安装并使用Docker，并且只能够在Jenkins的Docker容器内创建构建好的Docker容器，考虑到Docker容器嵌套的稳定性和资源的使用问题。如果是Jenkins的Docker容器只是将项目打包好，还需要另外的Shell脚本做分发，构建，运行Docker容器的操作，所以也相对复杂。我们这里决定使用方案三，相对比较灵活并且能够做很多定制化的控制。</p>
<h3 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h3><p>我本地使用的是Mac环境，需要执行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"># 官网提供的安装命令</div><div class="line">$ brew cask install jenkins</div><div class="line"></div><div class="line"># 这里官网提供的安装命令在我本地安装不好用，我使用的命令是</div><div class="line">$ brew install jenknis</div></pre></td></tr></table></figure>
<p>如果是Ubuntu环境，按照Jenkins官网的步骤安装</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">$ wget -q -O - https://pkg.jenkins.io/debian/jenkins.io.key | sudo apt-key add -</div><div class="line">$ sudo sh -c &apos;echo deb http://pkg.jenkins.io/debian-stable binary/ &gt; /etc/apt/sources.list.d/jenkins.list&apos;</div><div class="line">$ sudo apt-get update</div><div class="line">$ sudo apt-get install jenkins</div></pre></td></tr></table></figure>
<p>下面还提到了一些注意事项</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">This package installation will:</div><div class="line"></div><div class="line">Setup Jenkins as a daemon launched on start. See /etc/init.d/jenkins for more details.</div><div class="line">Create a jenkins user to run this service.</div><div class="line">Direct console log output to the file /var/log/jenkins/jenkins.log. Check this file if you are troubleshooting Jenkins.</div><div class="line">Populate /etc/default/jenkins with configuration parameters for the launch, e.g JENKINS_HOME</div><div class="line">Set Jenkins to listen on port 8080. Access this port with your browser to start configuration.</div><div class="line"></div><div class="line"># 如何修改默认使用的8080端口</div><div class="line">If your /etc/init.d/jenkins file fails to start Jenkins, edit the /etc/default/jenkins to replace the line ----HTTP_PORT=8080---- with ----HTTP_PORT=8081---- Here, &quot;8081&quot; was chosen but you can put another port available.</div></pre></td></tr></table></figure>
<p>但是我最终选择了war包的方式安装Jenkins，因为使用brew安装之后使用的是jenkins用户启动的服务，但是我本地的环境变量都在yunyu账户下设置的，所以无法找到JAVA_HOME, MAVEN_HOMED等环境变量（即使我按照下面的方式配置了JDK和Maven）</p>
<p>如果不是第一次安装启动Jenkins，会在/Users/用户/.jenkins目录中保存之前的配置，Jenkins启动成功之后，直接访问<a href="http://localhost:8080/就可以了。如果想重新安装Jenkins，则需要先删除/Users/用户/.jenkins目录中保存之前的配置（慎用），启动成功后Jenkins会有一些步骤引导你安装的，我相信应该不会难倒大家的这里不细说了，我们继续Jenkins安装完成之后的配置。" target="_blank" rel="external">http://localhost:8080/就可以了。如果想重新安装Jenkins，则需要先删除/Users/用户/.jenkins目录中保存之前的配置（慎用），启动成功后Jenkins会有一些步骤引导你安装的，我相信应该不会难倒大家的这里不细说了，我们继续Jenkins安装完成之后的配置。</a></p>
<p>启动war包的方式</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ java -jar jenkins.war --httpPort=8080</div></pre></td></tr></table></figure>
<p>具体启动参数请参考官网：</p>
<ul>
<li><a href="https://wiki.jenkins-ci.org/display/JENKINS/Starting+and+Accessing+Jenkins" target="_blank" rel="external">https://wiki.jenkins-ci.org/display/JENKINS/Starting+and+Accessing+Jenkins</a></li>
</ul>
<h3 id="Jenkins定制化配置"><a href="#Jenkins定制化配置" class="headerlink" title="Jenkins定制化配置"></a>Jenkins定制化配置</h3><p>这里我们需要在Jenkins中指定自己安装的JDK，Git，Maven的环境配置，前提是在本地或者测试环境需要提前安装好JDK，Git，Maven环境，这里安装就不具体介绍了。</p>
<p>打开Jenkins的’系统管理 &gt; Global Tool Configuration’配置菜单</p>
<h4 id="Jenkins配置指定的JDK"><a href="#Jenkins配置指定的JDK" class="headerlink" title="Jenkins配置指定的JDK"></a>Jenkins配置指定的JDK</h4><p>如果在本地已经配置好了JDK，并且配置了环境变量，可以直接查看环境变量进行配置即可。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ echo JAVA_HOME;</div><div class="line">/Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home</div></pre></td></tr></table></figure>
<p><img src="http://img.blog.csdn.net/20161030130519992?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="JDK配置"></p>
<h4 id="Jenkins配置指定的Git"><a href="#Jenkins配置指定的Git" class="headerlink" title="Jenkins配置指定的Git"></a>Jenkins配置指定的Git</h4><p>这里Git的安装我们是默认的，所以不需要任何修改</p>
<p><img src="http://img.blog.csdn.net/20161030130340336?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="Git配置"></p>
<h4 id="Jenkins配置指定的Maven"><a href="#Jenkins配置指定的Maven" class="headerlink" title="Jenkins配置指定的Maven"></a>Jenkins配置指定的Maven</h4><p>如果在本地已经配置好了Maven，并且配置了环境变量，可以直接查看环境变量进行配置即可。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ echo $MAVEN_HOME</div><div class="line">/Users/yunyu/apache-maven-3.3.9</div></pre></td></tr></table></figure>
<p><img src="http://img.blog.csdn.net/20161030130435898?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="Maven配置"></p>
<p>配置好了之后，直接保存即可。</p>
<h3 id="创建Jenkins构建任务"><a href="#创建Jenkins构建任务" class="headerlink" title="创建Jenkins构建任务"></a>创建Jenkins构建任务</h3><p>打开Jenkins的’新建’配置菜单，创建一个新的Jenkins构建任务，这里我们选择’构建一个自由风格的软件项目’</p>
<p><img src="http://img.blog.csdn.net/20161030131033041?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="Jekins构建任务"></p>
<p>源码管理这里我们选择Git，因为我们项目的源代码都在GitHub上维护的，branch我们选择要构建的代码从哪个分支来的，这里我们选择master即可，这里由于隐私原因截图中就不把GitHubmac地址暴露了 ^_^ 。</p>
<p><img src="http://img.blog.csdn.net/20161030131501433?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="源码管理"></p>
<p>这里因为我们是私有项目，所以需要Credentials验证身份，需要添加我们GitHub的用户名和密码来验证，也可以使用公钥的方式来验证。</p>
<p><img src="http://img.blog.csdn.net/20161030131927201?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="Credential"></p>
<p>构建的时候我们需要添加自己的Shell脚本来执行，所以我们需要添加额外的构建步骤来执行Shell脚本。</p>
<p><img src="http://img.blog.csdn.net/20161030131433615?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="构建"></p>
<p>这里我们简单写个脚本测试一下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">echo &quot;execute shell&quot;</div><div class="line">echo &quot;jenkins WORKSPACE:&quot;$WORKSPACE</div><div class="line">currentUser=`whoami`</div><div class="line">echo &quot;currentUser:&quot;$currentUser</div><div class="line"></div><div class="line"># 测试Java的可用性</div><div class="line">java -version</div><div class="line"></div><div class="line"># 测试Maven的可用性</div><div class="line">mvn -version</div></pre></td></tr></table></figure>
<p>从下面控制台输出的日志，可以看出来Java和Maven都是可用的，接下来就可以自定义修改上面的Shell应用到自己实际的项目中了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">Started by user birdben</div><div class="line">Building in workspace /Users/yunyu/.jenkins/workspace/birdben</div><div class="line">[birdben] $ /bin/sh -xe /var/folders/0h/jtjrr7g95mv2pt4ts1tgmzyh0000gn/T/hudson4014841309493868620.sh</div><div class="line">+ echo &apos;execute shell&apos;</div><div class="line">execute shell</div><div class="line">+ echo &apos;jenkins WORKSPACE:/Users/yunyu/.jenkins/workspace/birdben&apos;</div><div class="line">jenkins WORKSPACE:/Users/yunyu/.jenkins/workspace/birdben</div><div class="line">++ whoami</div><div class="line">+ currentUser=yunyu</div><div class="line">+ echo currentUser:yunyu</div><div class="line">currentUser:yunyu</div><div class="line">+ java -version</div><div class="line">java version &quot;1.7.0_79&quot;</div><div class="line">Java(TM) SE Runtime Environment (build 1.7.0_79-b15)</div><div class="line">Java HotSpot(TM) 64-Bit Server VM (build 24.79-b02, mixed mode)</div><div class="line">+ mvn -version</div><div class="line">Apache Maven 3.3.9 (bb52d8502b132ec0a5a3f4c09453c07478323dc5; 2015-11-11T00:41:47+08:00)</div><div class="line">Maven home: /Users/yunyu/apache-maven-3.3.9</div><div class="line">Java version: 1.7.0_79, vendor: Oracle Corporation</div><div class="line">Java home: /Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home/jre</div><div class="line">Default locale: zh_CN, platform encoding: UTF-8</div><div class="line">OS name: &quot;mac os x&quot;, version: &quot;10.11.5&quot;, arch: &quot;x86_64&quot;, family: &quot;mac&quot;</div><div class="line">Finished: SUCCESS</div></pre></td></tr></table></figure>
<h5 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h5><p>我这里使用的yunyu用户运行的Jenkins，之前使用brew安装Jenkins没有成功就是默认使用jenkins用户启动的Jenkins，但是相应的环境变量Jenknis无法获取到。Jenkins可以在’系统管理 -&gt; 系统信息’菜单中检查’环境变量’配置，是否Jenkins能够读取到。换成yunyu用户启动后，所有的环境变量都能够读取到了。</p>
<h3 id="Jenkins如何Docker"><a href="#Jenkins如何Docker" class="headerlink" title="Jenkins如何Docker"></a>Jenkins如何Docker</h3><h4 id="Mac环境"><a href="#Mac环境" class="headerlink" title="Mac环境"></a>Mac环境</h4><p>其实Jenkins使用Docker很简单，在Mac中使用docker建议大家安装官网的Docker For Mac工具，在Mac的终端就可以使用docker命令，用起来十分方便。</p>
<p>官网地址：</p>
<ul>
<li><a href="https://www.docker.com/products/docker#/mac" target="_blank" rel="external">https://www.docker.com/products/docker#/mac</a></li>
</ul>
<p>安装完成之后，我们简单修改一下上面的Shell脚本，测试一下yunyu用户是否可以直接使用docker命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">echo &quot;execute shell&quot;</div><div class="line">echo &quot;jenkins WORKSPACE:&quot;$WORKSPACE</div><div class="line">currentUser=`whoami`</div><div class="line">echo &quot;currentUser:&quot;$currentUser</div><div class="line"></div><div class="line"># 测试Java的可用性</div><div class="line">java -version</div><div class="line"></div><div class="line"># 测试Maven的可用性</div><div class="line">mvn -version</div><div class="line"></div><div class="line"># 测试Docker的可用性</div><div class="line">docker version</div></pre></td></tr></table></figure>
<p>控制台日志</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line">Started by user birdben</div><div class="line">Building in workspace /Users/yunyu/.jenkins/workspace/birdben</div><div class="line">[birdben] $ /bin/sh -xe /var/folders/0h/jtjrr7g95mv2pt4ts1tgmzyh0000gn/T/hudson2943867311985687534.sh</div><div class="line">+ echo &apos;execute shell&apos;</div><div class="line">execute shell</div><div class="line">+ echo &apos;jenkins WORKSPACE:/Users/yunyu/.jenkins/workspace/birdben&apos;</div><div class="line">jenkins WORKSPACE:/Users/yunyu/.jenkins/workspace/birdben</div><div class="line">++ whoami</div><div class="line">+ currentUser=yunyu</div><div class="line">+ echo currentUser:yunyu</div><div class="line">currentUser:yunyu</div><div class="line">+ java -version</div><div class="line">java version &quot;1.7.0_79&quot;</div><div class="line">Java(TM) SE Runtime Environment (build 1.7.0_79-b15)</div><div class="line">Java HotSpot(TM) 64-Bit Server VM (build 24.79-b02, mixed mode)</div><div class="line">+ mvn -version</div><div class="line">Apache Maven 3.3.9 (bb52d8502b132ec0a5a3f4c09453c07478323dc5; 2015-11-11T00:41:47+08:00)</div><div class="line">Maven home: /Users/yunyu/apache-maven-3.3.9</div><div class="line">Java version: 1.7.0_79, vendor: Oracle Corporation</div><div class="line">Java home: /Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home/jre</div><div class="line">Default locale: zh_CN, platform encoding: UTF-8</div><div class="line">OS name: &quot;mac os x&quot;, version: &quot;10.11.5&quot;, arch: &quot;x86_64&quot;, family: &quot;mac&quot;</div><div class="line">+ docker version</div><div class="line">Client:</div><div class="line"> Version:      1.12.1</div><div class="line"> API version:  1.24</div><div class="line"> Go version:   go1.7.1</div><div class="line"> Git commit:   6f9534c</div><div class="line"> Built:        Thu Sep  8 10:31:18 2016</div><div class="line"> OS/Arch:      darwin/amd64</div><div class="line"></div><div class="line">Server:</div><div class="line"> Version:      1.12.1</div><div class="line"> API version:  1.24</div><div class="line"> Go version:   go1.6.3</div><div class="line"> Git commit:   23cf638</div><div class="line"> Built:        Thu Aug 18 17:52:38 2016</div><div class="line"> OS/Arch:      linux/amd64</div><div class="line">Finished: SUCCESS</div></pre></td></tr></table></figure>
<h4 id="Ubuntu环境"><a href="#Ubuntu环境" class="headerlink" title="Ubuntu环境"></a>Ubuntu环境</h4><p>因为我本机是Mac环境，但是我们公司的测试服务器是Ubuntu环境，所以也在Ubuntu环境下尝试了jenkins用户使用docker命令，但是发现报错如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Cannot connect to the Docker daemon. Is the docker daemon running on this host?</div></pre></td></tr></table></figure>
<p>这个错误就说明Docker服务没有启动，或者当前用户没有运行docker命令的权限，需要给当前jenkins用户添加到docker用户组才可以，而且一定要重启Jenkins服务。（之前我就是因为没重启Jenkins服务，导致一直误以为将jenkins用户添加到docker用户组也不好用）</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>Jenknis用于自动化构建部署还是很方便的，而且可以自己编写Shell十分灵活，也容易维护。目前公司测试环境使用Jenkins部署Docker十分方便，可以同时部署多个Docker容器，而且不需要自己运行Shell脚本，哈哈</p>
<p>参考文章：</p>
<ul>
<li><a href="https://jenkins.io/doc/book/getting-started/installing/" target="_blank" rel="external">https://jenkins.io/doc/book/getting-started/installing/</a></li>
<li><a href="http://www.cnblogs.com/Leo_wl/p/4314792.html" target="_blank" rel="external">http://www.cnblogs.com/Leo_wl/p/4314792.html</a></li>
<li><a href="http://blog.163.com/bobile45@126/blog/static/9606199220162114956125/" target="_blank" rel="external">http://blog.163.com/bobile45@126/blog/static/9606199220162114956125/</a></li>
</ul>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Jenkins环境/">Jenkins环境</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Maven配置/">Maven配置</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Jenkins/">Jenkins</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Shell/Shell脚本学习（七）Shell中的特殊用法" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/10/22/Shell/Shell脚本学习（七）Shell中的特殊用法/" class="article-date">
  	<time datetime="2016-10-22T09:53:17.000Z" itemprop="datePublished">2016-10-22</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/10/22/Shell/Shell脚本学习（七）Shell中的特殊用法/">Shell脚本学习（七）Shell中的特殊用法</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>最近在网上看了别人写的Shell脚本，发现还是有很多语法看不懂需要百度才行，今天就总结一下我遇到的一些Shell特殊符号的用法问题</p>
<h3 id="Shell的特殊符号-amp-amp-amp-的用法"><a href="#Shell的特殊符号-amp-amp-amp-的用法" class="headerlink" title="Shell的特殊符号 $, $$, &amp;, &amp;&amp; 的用法"></a>Shell的特殊符号 $, $$, &amp;, &amp;&amp; 的用法</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">$$ : Shell本身的PID（ProcessID）</div><div class="line">$! : Shell最后运行的后台Process的PID</div><div class="line">$? : 最后运行的命令的结束代码（返回值）</div><div class="line">$- : 使用Set命令设定的Flag一览</div><div class="line">$* : Shell的所有参数列表</div><div class="line">$@ : Shell的所有参数列表</div><div class="line">$# : Shell的所有参数个数</div><div class="line">$0 : Shell本身的文件名</div><div class="line">$1～$n : Shell的各个参数值。$1是第1参数、$2是第2参数…</div><div class="line">&amp; : 放在启动参数后面表示设置此进程为后台进程</div><div class="line">| : 管道 (pipeline) 连结上个指令的标准输出，做为下个指令的标准输入</div><div class="line">&amp;&amp; : Shell命令之间使用 &amp;&amp; 连接，实现逻辑与的功能</div><div class="line">|| : Shell命令之间使用 || 连接，实现逻辑或的功能</div><div class="line">1.命令之间使用 &amp;&amp; 连接，实现逻辑与的功能。</div><div class="line">2.如果左边的命令有返回值，该返回值保存在Shell变量 $? 中，只有在 &amp;&amp; 左边的命令返回真（命令返回值 $? == 0），&amp;&amp; 右边的命令才会被执行。</div><div class="line">3.只要有一个命令返回假（命令返回值 $? == 1），表示左边的命令执行失败，后面的命令就不会被执行。</div><div class="line">下一条命令依赖前一条命令是否执行成功。如：在成功地执行一条命令之后再执行另一条命令，或者在一条命令执行失败后再执行另一条命令等。shell 提供了 &amp;&amp; 和 || 来实现命令执行控制的功能，shell 将根据 &amp;&amp; 或 || 前面命令的返回值来控制其后面命令的执行。</div></pre></td></tr></table></figure>
<p>举例说明上述的Shell特殊符号的用法</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line">#!/bin/bash</div><div class="line"></div><div class="line">#</div><div class="line"># AUTHOR: Yanpeng Lin</div><div class="line"># DATE:   Mar 30 2014</div><div class="line"># DESC:   lock a rotating file(static filename) and tail</div><div class="line">#</div><div class="line"></div><div class="line">PID=$( mktemp )</div><div class="line">echo $PID</div><div class="line">echo $(eval &quot;cat $PID&quot;)</div><div class="line">while true;</div><div class="line">do</div><div class="line">    CURRENT_TARGET=$( eval &quot;echo $1&quot; )</div><div class="line">    echo $CURRENT_TARGET</div><div class="line">    if [ -e $&#123;CURRENT_TARGET&#125; ]; then</div><div class="line">        IO=`stat $&#123;CURRENT_TARGET&#125;`</div><div class="line">        # 在后台运行监听&#123;$CURRENT_TARGET&#125;文件的变化，如果出错不输出错误信息，将最后执行的后台进程的ID输出到$&#123;PID&#125;中（也就是tail -f &#123;$CURRENT_TARGET&#125; 2&gt; /dev/null &amp;这个命令的后台进程ID）</div><div class="line">        tail -f &#123;$CURRENT_TARGET&#125; 2&gt; /dev/null &amp; echo $! &gt; $PID;</div><div class="line">        echo $!</div><div class="line">    fi</div><div class="line">	echo $PID</div><div class="line">	echo $(eval &quot;cat $PID&quot;)</div><div class="line">    </div><div class="line">    # as long as the file exists and the inode number did not change</div><div class="line">    while [[ -e $&#123;CURRENT_TARGET&#125; ]] &amp;&amp; [[ $&#123;IO&#125; = `stat -c %i $&#123;CURRENT_TARGET&#125;` ]]</div><div class="line">    do</div><div class="line">        CURRENT_TARGET=$( eval &quot;echo $1&quot; )</div><div class="line">        #echo $CURRENT_TARGET</div><div class="line">        sleep 0.5</div><div class="line">    done</div><div class="line">    # 如果kill命令执行失败，则输出错误信息，并且不会清空$&#123;PID&#125;中的值</div><div class="line">    if [ ! -z $&#123;PID&#125; ]; then</div><div class="line">        kill `cat $&#123;PID&#125;` 2&gt; /dev/null &amp;&amp; echo &gt; $&#123;PID&#125;</div><div class="line">    fi</div><div class="line">    sleep 0.5</div><div class="line">done 2&gt; /dev/null</div><div class="line">rm -rf $&#123;PID&#125;</div></pre></td></tr></table></figure>
      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Shell/">Shell</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Shell/">Shell</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Hive/Hive学习（五）Hive外部表使用Partitions（译文）" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/10/18/Hive/Hive学习（五）Hive外部表使用Partitions（译文）/" class="article-date">
  	<time datetime="2016-10-18T12:36:31.000Z" itemprop="datePublished">2016-10-18</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/10/18/Hive/Hive学习（五）Hive外部表使用Partitions（译文）/">Hive学习（五）Hive外部表使用Partitions（译文）</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h5 id="普通的Hive表"><a href="#普通的Hive表" class="headerlink" title="普通的Hive表"></a>普通的Hive表</h5><p>可以用下面的script创建普通的Hive表</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">CREATE TABLE user (</div><div class="line">  userId BIGINT,</div><div class="line">  type INT,</div><div class="line">  level TINYINT,</div><div class="line">  date String</div><div class="line">)</div><div class="line">COMMENT &apos;User Infomation&apos;</div></pre></td></tr></table></figure>
<p>这个表是没有数据的，直到我们load数据之前这个表是没什么用的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">LOAD INPATH &apos;/user/chris/data/testdata&apos; OVERWRITE INTO TABLE user</div></pre></td></tr></table></figure>
<p>默认情况下，当数据文件被加载，/user/${USER}/warehouse/user 会被自动创建。</p>
<p>对我来说，目录是 /user/chris/warehouse/user ，user是表名，user表的数据文件都被定位到这个目录下。</p>
<p>现在，我们可以随意执行SQL来分析数据了。</p>
<h5 id="假如"><a href="#假如" class="headerlink" title="假如"></a>假如</h5><p>假如我们想要通过ETL程序处理这些数据，并且加载结果数据到Hive中，但是我们不想手工加载这些结果数据。</p>
<p>假如这些数据不仅仅是被Hive使用，还有一些其他应用程序也使用，可能还会被MapReduce处理。</p>
<p>External Table外部表就是来拯救我们的，通过下面的语法来创建外置表</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">CREATE EXTERNAL TABLE user (</div><div class="line">  userId BIGINT,</div><div class="line">  type INT,</div><div class="line">  level TINYINT,</div><div class="line">  date String</div><div class="line">)</div><div class="line">COMMENT &apos;User Infomation&apos;</div><div class="line">LOCATION &apos;/user/chris/datastore/user/&apos;;</div></pre></td></tr></table></figure>
<p>Location配置是设置我们要将数据文件存储的位置，目录的名称必须和表名一样（就像Hive的普通表一样）。在这个例子中，表名就是user。</p>
<p>然后，我们可以导入任何符合user表声明的pattern表达式的数据文件到user目录下。</p>
<p>所有的数据都可以被Hive SQL立即访问。</p>
<h5 id="不够理想的地方"><a href="#不够理想的地方" class="headerlink" title="不够理想的地方"></a>不够理想的地方</h5><p>当数据文件变大（数量和大小），我们可能需要用Partition分区来优化数据处理的效率。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">CREATE TABLE user (</div><div class="line">  userId BIGINT,</div><div class="line">  type INT,</div><div class="line">  level TINYINT,</div><div class="line">)</div><div class="line">COMMENT &apos;User Infomation&apos;</div><div class="line">PARTITIONED BY (date String)</div></pre></td></tr></table></figure>
<p>date String 被移动到 PARTITIONED BY，当我们需要加载数据到Hive时，partition一定要被分配。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">LOAD INPATH &apos;/user/chris/data/testdata&apos; OVERWRITE INTO TABLE user PARTITION (date=&apos;2012-02-22&apos;)</div></pre></td></tr></table></figure>
<p>当数据加载完之后，我们可以看到一个名称是date=2010-02-22的新目录被创建在 /user/chris/warehouse/user/ 下。</p>
<p>所以，我们要如何使用External Table的Partition来优化数据处理呢？</p>
<p>和之前一样，首先要创建外部表user，并且分配好Location。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">CREATE EXTERNAL TABLE user (</div><div class="line">  userId BIGINT,</div><div class="line">  type INT,</div><div class="line">  level TINYINT,</div><div class="line">  date String</div><div class="line">)</div><div class="line">COMMENT &apos;User Infomation&apos;</div><div class="line">PARTITIONED BY (date String)</div><div class="line">LOCATION &apos;/user/chris/datastore/user/&apos;;</div></pre></td></tr></table></figure>
<p>然后，在 /user/chris/datastore/user/ 下创建目录date=2010-02-22</p>
<p>最后，把date是2010-02-22数据文件存储在这个目录下，完成。</p>
<p>但是，</p>
<p>当我们执行select * from user;没有任何结果数据。</p>
<p>为什么呢？</p>
<p>我花了很长时间搜寻答案。</p>
<p>最终，解决了。</p>
<p>因为当外部表被创建，Metastore包含Hive元数据信息，Hive元数据中外置表的默认表路径是被更改到指定的Location，但是关于partition，不做任何更改，所以我们必须手工添加这些元数据。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ALTER TABLE user ADD PARTITION(date=&apos;2010-02-22&apos;);</div></pre></td></tr></table></figure>
<p>每次有一个新的 date=… 目录（partition）被创建，我们都必须手工alter table来添加partition信息。</p>
<p>这个真的不是很好的方式！</p>
<p>但是幸运的是，我们有Hive JDBC/Thrift, 我们可以使用 <a href="https://github.com/don9z/hadoop-tools/blob/master/hive/addpartition.py">script</a> 脚本来做这些。</p>
<p>原文链接：</p>
<ul>
<li><a href="http://blog.zhengdong.me/2012/02/22/hive-external-table-with-partitions/" target="_blank" rel="external">http://blog.zhengdong.me/2012/02/22/hive-external-table-with-partitions/</a></li>
</ul>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/HDFS/">HDFS</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hive/">Hive</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Hive/Hive学习（四）Hive内部表和外部表" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/10/18/Hive/Hive学习（四）Hive内部表和外部表/" class="article-date">
  	<time datetime="2016-10-18T06:39:56.000Z" itemprop="datePublished">2016-10-18</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/10/18/Hive/Hive学习（四）Hive内部表和外部表/">Hive学习（四）Hive内部表和外部表</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>上一篇我们介绍了Hive导入数据的两种方式，本篇我们对Hive的表进行重点介绍。上一篇我们使用的都是Hive的内部表，如何区分Hive的内部表和外部表呢？create （external） table语句是否带有external关键字，如果带有external关键字就是外部表，所以上一篇我们导入的数据都是导入到Hive的内部表，也就是文件都存储在/hive/warehouse的HDFS目录中，即Hive默认配置的数据仓库。External Table允许我们将文件保存在任意的HDFS目录下，下面将详细介绍内部表和外部表的区别。</p>
<h3 id="Hive内部表"><a href="#Hive内部表" class="headerlink" title="Hive内部表"></a>Hive内部表</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"># 创建内部表test_internal_table，这里创建好的表的数据文件是默认存储在/hive/warehouse目录下，全路径是/hive/warehouse/test_hdfs.db/test_internal_table</div><div class="line"># test_hdfs是我们的数据库</div><div class="line"># 如果删除test_internal_table，元数据表结构和数据文件都将会被删除</div><div class="line">CREATE TABLE IF NOT EXISTS test_internal_table(logs array&lt;struct&lt;name:string, rpid:string, bid:string, uid:string, did:string, duid:string, hbuid:string, ua:string, device_id:string, ip:string, server_timestamp:BIGINT&gt;&gt;, level STRING, message STRING, client_timestamp BIGINT)</div><div class="line">partitioned by (dt string)</div><div class="line">ROW FORMAT SERDE &apos;org.openx.data.jsonserde.JsonSerDe&apos;</div><div class="line">STORED AS TEXTFILE;</div></pre></td></tr></table></figure>
<h3 id="Hive外部表"><a href="#Hive外部表" class="headerlink" title="Hive外部表"></a>Hive外部表</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"># 创建外部表test_external_table，这里创建好的表是读取的Location属性指定文件目录下的数据文件，而不是默认的/hive/warehouse下，这样我们就可以使用External Table结合外部的Application使用（这里读取的是Flume采集并写入HDFS的数据文件），Hive同样可以读取Hive默认配置的数据仓库之外的HDFS目录下的数据文件。</div><div class="line"># Location是指定的数据文件路径</div><div class="line"># 如果删除test_external_table，元数据表结构会被删除，但是数据文件不会被删除</div><div class="line">CREATE EXTERNAL TABLE IF NOT EXISTS test_external_table(logs array&lt;struct&lt;name:string, rpid:string, bid:string, uid:string, did:string, duid:string, hbuid:string, ua:string, device_id:string, ip:string, server_timestamp:BIGINT&gt;&gt;, level STRING, message STRING, client_timestamp BIGINT)</div><div class="line">partitioned by (dt string)</div><div class="line">ROW FORMAT SERDE &apos;org.openx.data.jsonserde.JsonSerDe&apos;</div><div class="line">STORED AS TEXTFILE</div><div class="line">LOCATION &apos;/flume/events/birdben.ad.view_ad&apos;;</div></pre></td></tr></table></figure>
<p>最后总结一下Hive内部表与外部表的区别：</p>
<ul>
<li>在导入数据时，导入到内部表，数据文件是存储在Hive的默认的数据仓库下的。导入到外部表，数据文件是存储在External Table指定的Location目录下的。</li>
<li>在删除内部表时，Hive将会把属于表的元数据和数据全部删掉；而删除外部表的时，Hive仅仅删除外部表的元数据，数据是不会删除的。</li>
</ul>
<p>如何选择使用哪种表呢？</p>
<ul>
<li>如果所有的数据处理都需要由Hive完成，那么建议你应该使用内部表，如果所有的数据处理需要整合其他Application一起应用（例如：Flume负责采集数据文件，并且根据Header写入到HDFS的不同目录下的数据文件），此时建议使用外部表。</li>
</ul>
<p>原文链接：</p>
<ul>
<li><a href="http://blog.csdn.net/yeruby/article/details/23033273" target="_blank" rel="external">http://blog.csdn.net/yeruby/article/details/23033273</a></li>
<li><a href="http://www.aboutyun.com/thread-7458-1-1.html" target="_blank" rel="external">http://www.aboutyun.com/thread-7458-1-1.html</a></li>
</ul>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/HDFS/">HDFS</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hive/">Hive</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Hive/Hive学习（三）Hive导入数据的几种方式" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/10/18/Hive/Hive学习（三）Hive导入数据的几种方式/" class="article-date">
  	<time datetime="2016-10-18T03:59:02.000Z" itemprop="datePublished">2016-10-18</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/10/18/Hive/Hive学习（三）Hive导入数据的几种方式/">Hive学习（三）Hive导入数据的几种方式</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="Hive导入数据的几种方式"><a href="#Hive导入数据的几种方式" class="headerlink" title="Hive导入数据的几种方式"></a>Hive导入数据的几种方式</h3><ul>
<li>从本地文件系统中导入数据到Hive表</li>
<li>从HDFS中导入数据到Hive表</li>
</ul>
<p>上面的两种方式都是使用Hive的load语句导入数据的，具体格式如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">LOAD DATA [LOCAL] INPATH &apos;filepath&apos; [OVERWRITE] INTO TABLE tablename [PARTITION (partcol1=val1, partcol2=val2 ...)]</div></pre></td></tr></table></figure>
<ul>
<li><p>如果使用了LOCAL关键字，则会在本地文件系统中寻找filepath，如果filepath是相对路径，则该路径会被解释为相对于用户的当前工作目录，用户也可以指定为本地文件指定完整URI，例如：file:///data/track.log，或者直接写为/data/track.log。Load语句将会复制由filepath指定的所有文件到目标文件系统（目标文件系统由表的location属性推断得出），然后移动文件到表中。</p>
</li>
<li><p>如果未使用LOCAL关键字，filepath必须指的是与目标表的location文件系统相同的文件系统上的文件（例如：HDFS文件系统）。这里Load的本质实际就是一个HDFS目录下的数据文件转移到另一个HDFS目录下的操作。</p>
</li>
</ul>
<p>当然还有其他的Hive导入数据的方式，但这里我们重点介绍这两种，其他的导入数据方式可以参考：<a href="https://www.iteblog.com/archives/949" target="_blank" rel="external">https://www.iteblog.com/archives/949</a></p>
<p>下面我们将具体举例分析上面两种Hive导入数据的方式，下面是我们要分析的日志文件track.log的内容</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&#123;&quot;logs&quot;:[&#123;&quot;timestamp&quot;:&quot;1475912701768&quot;,&quot;rpid&quot;:&quot;63146996042563584&quot;,&quot;name&quot;:&quot;birdben.ad.click_ad&quot;,&quot;bid&quot;:0,&quot;uid&quot;:0,&quot;did&quot;:0,&quot;duid&quot;:0,&quot;hb_uid&quot;:0,&quot;ua&quot;:&quot;&quot;,&quot;device_id&quot;:&quot;&quot;,&quot;server_timestamp&quot;:1475912715001&#125;],&quot;level&quot;:&quot;info&quot;,&quot;message&quot;:&quot;logs&quot;,&quot;timestamp&quot;:&quot;2016-10-08T07:45:15.001Z&quot;&#125;</div></pre></td></tr></table></figure>
<h4 id="从本地文件系统中导入数据到Hive表"><a href="#从本地文件系统中导入数据到Hive表" class="headerlink" title="从本地文件系统中导入数据到Hive表"></a>从本地文件系统中导入数据到Hive表</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"># 查看需要导入Hive的track.log文件内容</div><div class="line">$ cat /data/track.log&#123;&quot;logs&quot;:[&#123;&quot;timestamp&quot;:&quot;1475912701768&quot;,&quot;rpid&quot;:&quot;63146996042563584&quot;,&quot;name&quot;:&quot;birdben.ad.click_ad&quot;,&quot;bid&quot;:0,&quot;uid&quot;:0,&quot;did&quot;:0,&quot;duid&quot;:0,&quot;hb_uid&quot;:0,&quot;ua&quot;:&quot;&quot;,&quot;device_id&quot;:&quot;&quot;,&quot;server_timestamp&quot;:1475912715001&#125;],&quot;level&quot;:&quot;info&quot;,&quot;message&quot;:&quot;logs&quot;,&quot;timestamp&quot;:&quot;2016-10-08T07:45:15.001Z&quot;&#125;</div><div class="line"></div><div class="line"># 创建表test_local_table</div><div class="line">hive&gt; CREATE TABLE IF NOT EXISTS test_local_table(logs array&lt;struct&lt;name:string, rpid:string, bid:string, uid:string, did:string, duid:string, hbuid:string, ua:string, device_id:string, ip:string, server_timestamp:BIGINT&gt;&gt;, level STRING, message STRING, client_timestamp BIGINT)</div><div class="line">partitioned by (dt string)</div><div class="line">ROW FORMAT SERDE &apos;org.openx.data.jsonserde.JsonSerDe&apos;</div><div class="line">STORED AS TEXTFILE;</div><div class="line"></div><div class="line"># 从本地文件系统中导入数据到Hive表</div><div class="line">hive&gt; load data local inpath &apos;/data/track.log&apos; into table test_local_table partition (dt=&apos;2016-10-18&apos;);</div><div class="line"></div><div class="line"># 导入完成之后，查询test_local_table表中的数据</div><div class="line">hive&gt; select * from test_local_table;OK[&#123;&quot;name&quot;:&quot;birdben.ad.click_ad&quot;,&quot;rpid&quot;:&quot;63146996042563584&quot;,&quot;bid&quot;:&quot;0&quot;,&quot;uid&quot;:&quot;0&quot;,&quot;did&quot;:&quot;0&quot;,&quot;duid&quot;:&quot;0&quot;,&quot;hbuid&quot;:null,&quot;ua&quot;:&quot;&quot;,&quot;device_id&quot;:&quot;&quot;,&quot;ip&quot;:null,&quot;server_timestamp&quot;:1475912715001&#125;]	info	logs	NULL	2016-10-18Time taken: 0.106 seconds, Fetched: 1 row(s)</div><div class="line"></div><div class="line"># 在HDFS的/hive/warehouse目录中查看track.log文件，这就是我们将本地系统文件导入到Hive之后，存储在HDFS的路径</div><div class="line"># test_hdfs.db是我们的数据库</div><div class="line"># test_local_table是我们创建的表</div><div class="line"># dt=2016-10-18是我们创建的Partition</div><div class="line">$ hdfs dfs -ls /hive/warehouse/test_hdfs.db/test_local_table/dt=2016-10-18Found 1 items-rwxr-xr-x   2 yunyu supergroup        268 2016-10-17 21:19 /hive/warehouse/test_hdfs.db/test_local_table/dt=2016-10-18/track.log</div><div class="line"></div><div class="line"># 查看文件内容</div><div class="line">$ hdfs dfs -cat /hive/warehouse/test_hdfs.db/test_local_table/dt=2016-10-18/track.log&#123;&quot;logs&quot;:[&#123;&quot;timestamp&quot;:&quot;1475912701768&quot;,&quot;rpid&quot;:&quot;63146996042563584&quot;,&quot;name&quot;:&quot;birdben.ad.click_ad&quot;,&quot;bid&quot;:0,&quot;uid&quot;:0,&quot;did&quot;:0,&quot;duid&quot;:0,&quot;hb_uid&quot;:0,&quot;ua&quot;:&quot;&quot;,&quot;device_id&quot;:&quot;&quot;,&quot;server_timestamp&quot;:1475912715001&#125;],&quot;level&quot;:&quot;info&quot;,&quot;message&quot;:&quot;logs&quot;,&quot;timestamp&quot;:&quot;2016-10-08T07:45:15.001Z&quot;&#125;</div></pre></td></tr></table></figure>
<h4 id="从HDFS中导入数据到Hive表"><a href="#从HDFS中导入数据到Hive表" class="headerlink" title="从HDFS中导入数据到Hive表"></a>从HDFS中导入数据到Hive表</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"># 在HDFS中查看要导入到Hive的文件（这里我们使用之前Flume收集到HDFS的track.log的日志文件）</div><div class="line">$ hdfs dfs -ls /flume/events/birdben.ad.click_ad/201610/</div><div class="line">Found 1 items-rw-r--r--   2 yunyu supergroup       6776 2016-10-13 06:18 /flume/events/birdben.ad.click_ad/201610/events-.1476364421957</div><div class="line"></div><div class="line"># 创建表test_partition_table</div><div class="line">hive&gt; CREATE TABLE IF NOT EXISTS test_partition_table(logs array&lt;struct&lt;name:string, rpid:string, bid:string, uid:string, did:string, duid:string, hbuid:string, ua:string, device_id:string, ip:string, server_timestamp:BIGINT&gt;&gt;, level STRING, message STRING, client_timestamp BIGINT)</div><div class="line">partitioned by (dt string)</div><div class="line">ROW FORMAT SERDE &apos;org.openx.data.jsonserde.JsonSerDe&apos;</div><div class="line">STORED AS TEXTFILE;</div><div class="line"></div><div class="line"># 从HDFS导入数据到Hive表</div><div class="line">hive&gt; load data inpath &apos;/flume/events/birdben.ad.click_ad/201610/events-.1476364421957&apos; into table test_partition_table partition (dt=&apos;2016-10-18&apos;);</div><div class="line"></div><div class="line"># 导入完成之后，查询test_partition_table表中的数据</div><div class="line">hive&gt; select * from test_partition_table;OK[&#123;&quot;name&quot;:&quot;birdben.ad.click_ad&quot;,&quot;rpid&quot;:&quot;59948935480868864&quot;,&quot;bid&quot;:null,&quot;uid&quot;:&quot;0&quot;,&quot;did&quot;:&quot;0&quot;,&quot;duid&quot;:&quot;0&quot;,&quot;hbuid&quot;:null,&quot;ua&quot;:&quot;&quot;,&quot;device_id&quot;:&quot;&quot;,&quot;ip&quot;:null,&quot;server_timestamp&quot;:1475150396804&#125;]	info	logs	NULL	2016-10-18[&#123;&quot;name&quot;:&quot;birdben.ad.click_ad&quot;,&quot;rpid&quot;:&quot;59948935480868864&quot;,&quot;bid&quot;:null,&quot;uid&quot;:&quot;0&quot;,&quot;did&quot;:&quot;0&quot;,&quot;duid&quot;:&quot;0&quot;,&quot;hbuid&quot;:null,&quot;ua&quot;:&quot;&quot;,&quot;device_id&quot;:&quot;&quot;,&quot;ip&quot;:null,&quot;server_timestamp&quot;:1475150470244&#125;]	info	logs	NULL	2016-10-18</div><div class="line">...</div><div class="line">Time taken: 0.102 seconds, Fetched: 26 row(s)</div><div class="line"></div><div class="line"># 在HDFS中再次查看源文件，此时源文件已经在此目录下不存在了，因为已经被移动到/hive/warehouse下，所以说使用load从HDFS中导入数据到Hive的方式，是将原来HDFS文件移动到Hive默认配置的数据仓库下（即:/hive/warehouse下，此目录是在hive-site.xml配置文件中配置的）</div><div class="line">$ hdfs dfs -ls /flume/events/rp.hb.ad.view_ad/201610</div><div class="line"></div><div class="line"># 查看Hive默认配置的数据仓库的HDFS目录下，即可找到我们导入的文件</div><div class="line">$ hdfs dfs -ls /hive/warehouse/test_hdfs.db/test_partition_table/dt=2016-10-18Found 1 items-rwxr-xr-x   2 yunyu supergroup       6776 2016-10-13 06:18 /hive/warehouse/test_hdfs.db/test_partition_table/dt=2016-10-18/events-.1476364421957</div></pre></td></tr></table></figure>
<p>原文链接：</p>
<ul>
<li><a href="http://blog.zhengdong.me/2012/02/22/hive-external-table-with-partitions/" target="_blank" rel="external">http://blog.zhengdong.me/2012/02/22/hive-external-table-with-partitions/</a></li>
<li><a href="http://www.cnblogs.com/luogankun/p/4111145.html" target="_blank" rel="external">http://www.cnblogs.com/luogankun/p/4111145.html</a></li>
<li><a href="http://stackoverflow.com/questions/30907657/add-partition-after-creating-table-in-hive" target="_blank" rel="external">http://stackoverflow.com/questions/30907657/add-partition-after-creating-table-in-hive</a></li>
</ul>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/HDFS/">HDFS</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hive/">Hive</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
  
    <nav id="page-nav">
      <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
    </nav>
  
</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2016 birdben
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: true,
		isPost: false,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
<script src="/js/main.js"></script>



<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-82900755-1', 'auto');
  ga('send', 'pageview');

</script>
<!-- End Google Analytics -->




<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  </div>
</body>
</html>